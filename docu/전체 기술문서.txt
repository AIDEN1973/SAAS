📘 디어쌤 Multi-Tenant SaaS 플랫폼 — 기술문서

Monorepo + Supabase + PostgreSQL + 멀티테넌트 + KST 운영 표준

⚠️ 중요: Phase별 구현 가이드라인

이 문서는 최종 목표(20,000~30,000+ 테넌트)를 기준으로 작성되었으나, 실제 구현은 Phase별로 점진적으로 진행해야 합니다.

Phase 1 (MVP, 100~300 테넌트) - 필수 기능만:
- ✅ 기본 멀티테넌트 (RLS + tenant_id)
- ✅ 기본 인증/권한
- ✅ 기본 결제/알림뱅킹 (단일 Provider)
- ✅ 기본 Analytics (간단한 집계, Supabase Edge Function 사용)
- ✅ 지역 기반 통계 (기본 기능: 지역순위, 지역 평균 대비 비교, 기본 히트맵)
- ✅ AI 분석 기능 (기본 인사이트: 상담일지 요약, 출결 이상 탐지, 기본 리포트)
- ✅ 기본 Public Gateway
- ✅ 기본 Custom Domain (수동 관리)
- ✅ 기본 모니터링
- ❌ 제외: Hot Tenant 샤딩, Multi-Region DR, PII AEAD 암호화, KMS 키 회전, 외부 검색 엔진

Phase 2 (1~3k 테넌트) - 확장성 기능:
- ✅ Analytics 외부 워커 (Lambda/Workers)
- ✅ Edge Function Role 분리
- ✅ Custom Domain 자동화
- ✅ 고급 캐시 무효화
- ✅ PII 마스킹 강화
- ✅ 지역 기반 통계 고급 기능 (고급 히트맵, 다중 지역 비교, AI 인사이트 고도화)
- ✅ 지도 기반 매장 분포 시각화 (고급)

Phase 3 (20k+ 테넌트) - 대규모 최적화:
- ✅ Multi-Region DR (외부 DB 사용 시, 난이도: 중)
  → 외부 PostgreSQL 솔루션(Neon, AWS RDS, Aurora) 기반 DR 도입
  → Supabase 단일 프로젝트에서는 불가능하므로 외부 DB 전환 필요
- ✅ PII AEAD 암호화
- ✅ KMS 키 회전
- ✅ 업종별 스키마 분리 검토
- ✅ 이중 파티셔닝 검토

Phase 4 (수십만 테넌트) - 초고급 기능:
- ⚠️ 중요: Phase 4는 현재 사업 목표(2~3만 테넌트)를 넘어서는 초과 성장 시나리오 기준입니다.
- ✅ Multi-Region + 샤딩 통합 구조 (난이도: 매우 높음)
  → Phase 3의 외부 DB 기반 DR을 확장하여 Multi-Region + 샤딩 통합 구조로 발전
- ✅ WebAuthn/Passkey
- ✅ Hot Tenant 수직 샤딩 (수동, 난이도: 매우 높음)
- ✅ Shard 재조정 (난이도: 매우 높음)
- ✅ CDC 기반 샤딩 자동화 (난이도: 매우 높음)

⚠️ 중요: 확장 로드맵 난이도 순서 재정렬:
- Phase 3: 외부 DB(Aurora/Neon) 기반 Multi-Region DR 도입 (난이도: 중)
- Phase 4: Multi-Region + 샤딩 통합 구조 (난이도: 매우 높음)
- Hot Tenant 샤딩은 CDC 동기화, conflict 해결, routing layer, 영구 분리 정책 등 복잡도가 매우 높아 Phase 4로 이동
- 실제 운영에서는 Phase 3의 외부 DB 기반 DR이 Hot Tenant 샤딩보다 훨씬 단순합니다

→ 각 섹션에 "Phase X+ 전용" 표시가 있는 경우, 해당 Phase 이전에는 구현하지 않습니다.

📘 PART 1
전체 아키텍처 / Monorepo / 멀티테넌트 / DB 모델

0. 목표 & 컨셉

이 플랫폼은 단일 Supabase + 단일 PostgreSQL 위에서
학원·미용실·네일샵·부동산·체육관·비영리 기관 등 여러 업종 SaaS를 동시에 운영하는 구조를 목표로 한다.

🎯 최종 목표

학원 10,000개, 부동산 10,000개, 기타 업종 수천 개

합계 20,000~30,000+ 테넌트 운영 가능한 구조

단일 코드베이스(Monorepo)에서 업종별 SaaS를 버튼처럼 생성

공통 Core Platform 모듈을 공유하면서 업종별 기능은 Industry Layer로 차별화

모바일·태블릿 완벽 대응

다크모드, UI 확대(Zoom) 기본 지원

효성FMS 알림뱅킹 연동(Payments Provider) 전 업종 공통 지원

장기적으로는 파티셔닝 → 리드 레플리카 → 샤딩까지 확장 가능한 구조

⚠️ 주의: 리전 분리는 Supabase에서 지원하지 않으므로, Multi-Region이 필요한 경우 외부 PostgreSQL 솔루션(Neon, AWS RDS, Aurora) 사용 필수

타임존 정책 (KST 표준):

모든 시간은 DB에는 UTC로 저장하되, 비즈니스 로직·표시·집계는 KST 기준으로 처리한다.

→ 상세 규칙은 PART 5 '19-1. 타임존(KST) 표준' 섹션 참조

여기서 말하는 "단일 Supabase + 단일 PostgreSQL"은 운영(prod) 환경 기준이며, dev/staging 환경은 별도 프로젝트/DB로 분리 운영하는 것을 전제로 한다.

📌 Supabase Multi-Region 제약 요약 (Critical - 즉시 수정)

⚠️ 중요: Supabase는 공식적으로 Cross-Region Read Replica / Region Failover 기능을 제공하지 않는다.

현재(2025 기준) Supabase는 단일 Region 운영만 가능하며, Replica도 동일 Region에서만 지원된다.

❌ Secondary Region = Supabase 기능이 아니다

❌ Region Failover = 불가능

❌ Replication across region = 지원 안 됨

DR/Failover를 하려면:

PostgreSQL 자체를 별도로 구축하거나

Neon/Aurora 등 외부 DB를 사용해야 한다

또는 Supabase의 단일 Region 백업/복원 기능만 사용

PITR(Point-in-Time Recovery)은 특정 시점 복원만 가능하며, table-level restore는 불가능하다.

→ Multi-Region DR이 필요한 경우 외부 PostgreSQL 솔루션(Neon, AWS RDS, Aurora) 사용 필수

⚠️ 주의: 위 제약사항과 수치는 2025년 기준이며, Supabase 기능·플랜 변경에 따라 달라질 수 있으므로 실제 설계·구현 시점에는 Supabase 최신 공식 문서를 다시 확인해야 한다.

⚠️ 중요: 우리 플랫폼의 초기~중기 단계에서는 Supabase 단일 리전 + 기본 백업만 사용하며, Multi-Region 구조를 당장 도입하지 않습니다.

→ Phase 1-2에서는 Supabase 단일 리전 운영이 기본입니다.
→ Phase 3에서는 외부 DB(Aurora/Neon) 기반 Multi-Region DR 도입을 검토합니다.
→ Phase 4에서는 Multi-Region + 샤딩 통합 구조를 검토합니다 (현재 사업 목표를 넘어서는 초과 성장 시나리오).

→ 상세 DR 정책은 PART 7 '장애 복구 / 백업·복원 (DR & BCP)' 섹션 참조

1. 전체 아키텍처 개요
1-1. Monorepo 구조
.
├─ apps/                        # 최종 배포되는 프론트엔드 애플리케이션
│  ├─ academy-admin/            # 학원 관리자/선생님용
│  ├─ academy-parent/           # 학부모용
│  ├─ super-admin/              # SaaS 본사 플랫폼 콘솔
│  └─ public-gateway/           # 로그인 없이 접근하는 결제/키오스크/공개 페이지
│
├─ packages/                    # 공유 모듈
│  ├─ core/                     # 업종 공통 Core Platform Layer
│  │  ├─ core-auth/
│  │  ├─ core-tenancy/
│  │  ├─ core-billing/
│  │  ├─ core-metering/
│  │  ├─ core-notification/
│  │  ├─ core-payment/
│  │  ├─ core-config/
│  │  ├─ core-party/            # 회원/고객 공통 모델 (persons 테이블 기반)
│  │  ├─ core-community/      # 공통 게시판/댓글/공지/파일 첨부 스키마 및 API
│  │  ├─ core-storage/         # 파일 업로드/권한/폴더 구조 공통화, Supabase Storage 래핑
│  │  ├─ core-calendar/        # 일정/예약/수업 스케줄 공통 도메인
│  │  ├─ core-search/          # Full Text Search 공통 레이어 (PART 16 참조)
│  │  ├─ core-tags/            # 공통 태깅 시스템(학생 태그, 고객 태그, 매물 태그 등)
│  │  ├─ core-analytics/       # 통계 파이프라인 (PART 3의 15. Analytics & 통계 섹션 참조)
│  │  ├─ core-activity/        # Activity Feed / 타임라인 이벤트 기록
│  │  ├─ core-consultation/    # 상담/기록 관리 공통 모듈
│  │  ├─ core-reviews/             # 리뷰/평가 시스템
│  │  ├─ core-coupons/         # 쿠폰/할인 관리
│  │  ├─ core-tenancy-referral/ # B2B 추천인 코드 제도
│  │  ├─ core-events/          # 이벤트/프로모션 관리
│  │  └─ ui-core/               # UI 컴포넌트 (DataTable, TableCardView, SplitTableLayout 등)
│  │
│  ├─ schema-engine/            # SDUI Renderer + Meta-Schema + Versioning + Custom Widget Registry
│  │
│  ├─ design-system/            # Design Tokens, Theme Engine (다크모드, Zoom 지원)
│  │
│  ├─ api-sdk/                  # Zero-Trust API SDK Layer
│  │
│  └─ theme-engine/             # Theme Override Engine (테넌트별 테마 커스터마이징)
│
⚠️ 중요: UI 레이어 구조 개념 설명
UI/UX 문서에서는 UI 아키텍처를 개념적으로 다음과 같이 설명합니다:
- schema-engine → core-ui → design-system → theme-engine

이는 논리적 레이어 구조이며, 실제 패키지 구조와는 다음과 같이 매핑됩니다:
- schema-engine: packages/schema-engine (독립 패키지)
- core-ui(개념 레이어): packages/ui-core (실제 패키지)
- design-system: packages/design-system (독립 패키지)
- theme-engine: packages/design-system 내부 또는 별도 theme-engine 패키지 (구현 방식에 따라)

→ UI 문서의 레이어 구조는 "의존성 방향"과 "책임 분리"를 설명하는 개념적 모델이며, 실제 디렉토리 구조와 1:1로 동일하지 않을 수 있습니다.
→ 개발 시에는 위 Monorepo 구조를 기준으로 하되, UI 문서의 레이어 개념을 참고하여 모듈 간 의존성을 관리합니다.
│  │  ├─ core/                  # 공통 API SDK (tenant_id, industry_type 자동 삽입)
│  │  └─ academy/               # 업종별 확장 SDK (향후 추가)
│  │
│  ├─ payments/
│  │  └─ payment-alimbank/      # 효성FMS 알림뱅킹 Adapter
│  │
│  ├─ industry/                 # 업종별 모듈 (학원/미용/네일/부동산/체육관/비영리)
│  │  ├─ industry-academy/
│  │  ├─ industry-salon/
│  │  ├─ industry-real-estate/
│  │  ├─ industry-gym/
│  │  ├─ industry-ngo/
│  │  └─ ...
│  │
│  ├─ services/                 # DB 접근 Service Layer
│  │  ├─ attendance-service/
│  │  ├─ billing-service/
│  │  ├─ messaging-service/
│  │  ├─ student-service/
│  │  ├─ community-service/
│  │  └─ ...
│  │
│  ├─ hooks/                    # React Query 기반 Hooks
│  │  ├─ use-attendance/
│  │  ├─ use-billing/
│  │  ├─ use-notification/
│  │  ├─ use-community/
│  │  └─ ...
│  │
│  ├─ lib/                      # 공통 유틸
│  │  ├─ supabase-client/
│  │  ├─ logger/
│  │  └─ router-guards/
│  │
│  ├─ env-registry/             # 중앙 환경변수 관리 시스템 (타입 안정성 + 검증 + 환경 자동 인식)
│  │
│  └─ docs/                     # 설계 문서
│
└─ infra/
   ├─ supabase/
   │  ├─ migrations/            # DB 마이그레이션 SQL
   │  ├─ functions/             # Supabase Edge Functions
   │  │  ├─ fns-payment-alimbank-webhook/
   │  │  ├─ fns-payment-alimbank-request/
   │  │  ├─ fns-notification-dispatch/
   │  │  ├─ fns-daily-metrics-aggregation/
   │  │  └─ ...
   │  └─ policies/              # RLS/정책 SQL
   │
   ├─ scripts/                  # 운영 스크립트
   └─ .github/                  # CI/CD

2. 멀티테넌트 모델 & 용어

2-0. 테넌트 삭제 정책 (Critical)

필수 항목:

grace period (예: 30일 보관 후 삭제):

테넌트 삭제 요청 시 즉시 삭제하지 않고 30일간 보관

30일 내 복구 요청 가능

billing unpaid 케이스 처리:

미납 테넌트는 삭제하지 않고 일시 정지 상태로 전환

미납 해결 후 자동 활성화 또는 수동 승인 필요

audit/events는 보관해야 하는가 여부:

audit.events는 법적 요구사항에 따라 최소 1년 보관

테넌트 삭제 후에도 audit.events는 보관 (tenant_id로 조회 가능)

storage 파일삭제 정책:

테넌트 삭제 시 storage 파일은 즉시 삭제하지 않고 30일 보관

30일 후 자동 삭제 배치 실행

구현 예시:

```typescript
async function deleteTenant(tenantId: string) {
  // 1. 테넌트 상태를 'deleting'으로 변경
  await db.updateTenantStatus(tenantId, 'deleting');

  // 2. 삭제 예약 (30일 후)
  await db.scheduleDeletion(tenantId, new Date(Date.now() + 30 * 24 * 60 * 60 * 1000));

  // 3. Storage 파일 삭제 예약
  await scheduleStorageDeletion(tenantId, 30);

  // 4. audit.events는 보관 (삭제하지 않음)
}
```
2-1. 용어 정의
용어	설명
Platform	전체 SaaS 생성 플랫폼
Tenant(테넌트)	하나의 사업자(학원/매장/지점 1개)
Industry	업종 레이어(academy/salon/real_estate/gym/ngo 등)
User	개인 계정 (여러 테넌트에 소속 가능)
SaaS 제품	업종별 패키지(학원관리, 네일샵관리 등)
2-2. 핵심 테이블
tenants (
  id uuid PK,
  name text,
  industry_type text,
  plan text,
  status text,
  created_at timestamptz
)

users (...)

user_tenant_roles (
  user_id,
  tenant_id,
  role (owner/staff/teacher/parent ...)
)

tenant_settings (
  tenant_id,
  key,
  value jsonb
)

tenant_features (
  tenant_id,
  feature_key,
  enabled,
  quota
)

2-2-1. 스키마 단단화(데이터 무결성) (Critical)

industry_type, status, role, provider 등은 ENUM 또는 CHECK로 표준화:

-- 예시
ALTER TABLE tenants
  ADD CONSTRAINT chk_tenants_status CHECK (status IN ('active','paused','closed'));

ALTER TABLE tenants
  ADD CONSTRAINT chk_tenants_industry CHECK (industry_type IN ('academy','salon','real_estate','gym','ngo'));

tenant_settings.value는 JSON Schema 유효성(서버단) + 마이그레이션 시 기본값 강제

→ 데이터 무결성 보장 및 런타임 오류 방지

→ 모든 도메인 테이블은 tenant_id 필수 + 인덱스 구성

2-2-2. 매장(Store) 및 지역(Region) 모델

⚠️ 중요: 기본 매장/지역 모델은 Phase 1 (MVP)에 포함되며, 고급 매장 관리 기능은 Phase 2+에서 도입합니다.

Phase 1 (MVP) 기본 구조:
- core_stores 테이블 (기본 매장 정보)
- core_regions 테이블 (지역 마스터 데이터)
- 매장 ↔ 지역 매핑 (지역 통계용)

Phase 2+ 고급 기능:
- 다중 매장 관리
- 매장별 세부 설정
- 매장별 권한 관리

지역 계층 테이블 (Core Layer 공통):

CREATE TABLE core_regions (
  id              uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  level           text NOT NULL CHECK (level IN ('dong', 'gu_gun', 'si', 'nation')), -- 동/읍/면, 구/군, 시/도, 전국
  code            text NOT NULL,    -- 행정안전부 행정구역 코드 등
  name_ko         text NOT NULL,
  parent_id       uuid NULL REFERENCES core_regions(id),
  created_at      timestamptz NOT NULL DEFAULT now()
);

CREATE UNIQUE INDEX ux_core_regions_level_code
  ON core_regions(level, code);

CREATE INDEX idx_core_regions_parent ON core_regions(parent_id);

매장(Store) 테이블:

CREATE TABLE core_stores (
  id              uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id       uuid NOT NULL REFERENCES tenants(id),
  name            text NOT NULL,
  industry_type   text NOT NULL,    -- tenants.industry_type과 동일
  region_id       uuid NOT NULL REFERENCES core_regions(id),  -- 매장이 속한 기준 지역(보통 동/읍/면)
  latitude        double precision,  -- 지도 렌더링용 위도 (WGS84)
  longitude       double precision, -- 지도 렌더링용 경도 (WGS84)
  address         text,
  phone           text,
  status          text NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'paused', 'closed')),
  created_at      timestamptz NOT NULL DEFAULT now(),
  updated_at      timestamptz NOT NULL DEFAULT now()
);

CREATE INDEX idx_core_stores_tenant ON core_stores(tenant_id);
CREATE INDEX idx_core_stores_region ON core_stores(region_id);
CREATE INDEX idx_core_stores_industry_region ON core_stores(industry_type, region_id);

ALTER TABLE core_stores ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_core_stores ON core_stores
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
);

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, JWT claim 기반 RLS를 사용해야 합니다. set_config 기반 RLS는 Session Pooling 또는 전용 커넥션 전용입니다.

→ Region은 Core Layer의 공통 차원(Dimension)이고, Industry Layer(학원, 부동산 등)는 이 Region을 그대로 공용으로 사용합니다.

→ Phase 1 (MVP)에서 기본 매장/지역 모델을 사용하며, 고급 매장 관리 기능은 Phase 2+에서 도입합니다.

3. Supabase 구조 & 원칙
3-1. 단일 프로젝트 전략

Supabase 프로젝트는 환경별로 분리하며, 특히 prod는 dev/staging과 완전히 다른 프로젝트/DB를 사용한다.

이 문서의 "단일 PostgreSQL"은 운영(prod) 환경 내 멀티테넌트를 의미한다.

모든 업종 SaaS 테넌트는 운영(prod) 환경의 단일 PostgreSQL에 저장

원칙적으로는 모든 테넌트가 단일 PostgreSQL 인스턴스에 공존하며, 특정 Hot Tenant가 전체 부하에 심각한 영향을 주는 경우에 한해 예외적으로 해당 테넌트만 별도 샤드(분리 DB)로 수직 분리할 수 있다.

RLS + tenant_id + app.current_tenant_id 조합으로 완전 격리

⚠️ 중요: 테넌트별 테이블 생성 구조가 아님

이 플랫폼은 "테넌트마다 스키마/테이블을 새로 만드는 구조"가 아닙니다.

기본 구조:
- public 스키마 + tenant_id + industry_type 컬럼 (표준)
- 파티셔닝은 시간 기준(RANGE, occurred_at)
- 업종별 테이블은 "필요할 때만" academy_*, salon_* 같은 소수의 prefix 테이블

즉, 테넌트 3만 개가 생겨도:
- "테이블 개수"는 그대로 (또는 월/연 파티션만 시간에 따라 증가)
- "행(row) 수"만 늘어나는 구조

Phase 3에서 말하는 "업종별 스키마 분리"도 industry 단위지, tenant 단위가 아닙니다.

→ "사스 하나 생길 때마다 DB 테이블 잔뜩 늘어나는 구조는 아니다"로 이해하면 됩니다.
→ 테이블 폭증은 "월별 파티션 수 × 로그성 테이블 수" 정도라서, 운영 설계로 컨트롤 가능합니다.

3-1-1. Supabase 단일 프로젝트 확장성 및 병목 대응 전략 (Critical)

⚠️ 중요: 20,000~30,000 테넌트를 단일 Supabase 프로젝트에서 운영하려면 반드시 다음 전략이 필요합니다.

DB 연결 수 & 풀링 전략:

[불변 규칙] Supabase는 플랜/컴퓨트 스펙별로 DB 연결 수가 제한되어 있으므로, PgBouncer(커넥션 풀러) 사용을 전제로 합니다.

연결 수 제한 (예시, 실제는 Supabase 최신 문서 확인 필요):
- Free/Pro 플랜: 제한적 연결 수
- Enterprise: 더 많은 연결 수 제공

PgBouncer 풀링 모드:
- Transaction Pooling (권장): 짧은 트랜잭션에 최적화
- Session Pooling: 긴 트랜잭션 필요 시

⚠️ Critical: PgBouncer Transaction Pooling과 RLS 전략 (구조적 해결책 필수)

🚨 중요: PgBouncer Transaction Pooling 모드에서는 세션 변수(set_config)가 트랜잭션 종료 후 유지되지 않으므로, RLS는 반드시 JWT claim 기반으로 구현해야 합니다.

[불변 규칙] PgBouncer Transaction Pooling 모드를 사용할 때는 RLS 정책이 JWT claim 기반으로 작동하도록 설계해야 합니다. set_config 기반 RLS는 Transaction Pooling과 호환되지 않습니다.

문제점:
- Transaction Pooling 모드에서는 세션 레벨 SET이 트랜잭션 종료 후 유지되지 않음
- set_config('app.current_tenant_id') 기반 RLS는 Transaction Pooling에서 작동하지 않음
- RLS 정책이 잘못된 tenant_id로 평가되거나 모든 row가 차단될 위험

해결책 (구조적):

옵션 1: JWT claim 기반 RLS (권장, Supabase 기본 방식):
- Supabase JWT에 tenant_id를 claim으로 포함
- RLS 정책에서 JWT claim을 직접 읽어 tenant_id 확인
- PgBouncer Transaction Pooling과 완벽 호환

옵션 2: Session Pooling 모드 (제한적):
- PgBouncer Session Pooling 모드 사용 (커넥션 수 제한 증가)
- 세션 변수 유지 가능하나 커넥션 효율성 저하

옵션 3: 전용 커넥션 (특수 케이스):
- 특정 Edge Function만 전용 커넥션 사용 (논풀링)
- 일반적인 경우에는 권장하지 않음

📌 JWT claim 기반 RLS 구현 (권장):

1. Supabase JWT에 tenant_id 포함:
   - 사용자 인증 시 user_tenant_roles에서 tenant_id 조회
   - JWT 생성 시 claim에 tenant_id 포함

2. RLS 정책 수정:
```sql
CREATE POLICY tenant_isolation_students ON public.students
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
);
```

3. Service Layer에서 withTenant() 사용:
   - RLS는 보안 레이어, Service Layer는 쿼리 레이어
   - 2중 필터로 보안 강화

모니터링 전략:
- RLS 실패율 모니터링 (예상치 못한 401/403 증가 감지)
- JWT claim 누락 감지 (로그 수집)
- 테넌트 간 데이터 누수 감지 (audit 로그 분석)

🚨 [불변 규칙] PgBouncer Transaction Pooling 사용 시 set_config 기반 RLS 금지:

[불변 규칙] Supabase 환경에서는 기본적으로 PgBouncer Transaction Pooling을 사용하므로, set_config('app.current_tenant_id') 기반 RLS는 절대 사용하지 않습니다.

[불변 규칙] Transaction Pooling 모드에서는 세션 변수가 트랜잭션 종료 후 유지되지 않으므로, set_config 기반 RLS는 보안 상 안전하게 동작하지 않을 가능성이 매우 높습니다.

[불변 규칙] 모든 RLS 정책은 반드시 JWT claim 기반(auth.jwt() -> 'tenant_id')으로 구현해야 합니다.

⚠️ 중요: 현재 문서의 set_config 기반 RLS 예시는 Session Pooling 모드 또는 전용 커넥션을 사용하는 경우에만 유효합니다. Transaction Pooling을 사용하는 경우(기본 설정) 반드시 JWT claim 기반 RLS로 변경해야 합니다.

[불변 규칙] 긴 트랜잭션 / 통계 쿼리 / 배치 쿼리는 Primary DB에 직접 실행하지 않으며, Read Replica 또는 외부 Worker로 분리합니다.

[불변 규칙] Admin 도구(예: Metabase, Grafana)도 낮은 커넥션 소비를 위해 Read Replica를 사용하도록 설정합니다.

연결 수 모니터링:
- pg_stat_activity 모니터링
- PgBouncer 통계 수집
- 연결 수 임계값 설정 (예: 80% 도달 시 알림)

리드 레플리카(Read Replica) 전략:

[불변 규칙] 운영 트랜잭션은 Primary, 대시보드·통계·리포트는 Read Replica로 분리합니다.

트래픽 분리 전략:

Primary DB (쓰기 + 실시간 읽기):
- INSERT/UPDATE/DELETE 작업
- 실시간 조회 (학생 목록, 수납 내역 등)
- Edge Function에서의 트랜잭션 작업

Read Replica (읽기 전용):
- 대시보드 통계 쿼리
- 리포트 생성
- Analytics 집계 쿼리
- Admin 도구 쿼리

Read Replica 라우팅 예시:

// services/analytics-service.ts
import { createClient } from '@supabase/supabase-js';
import { envServer } from '@env-registry/server';

// Primary DB (쓰기용)
const supabasePrimary = createClient(
  envServer.SUPABASE_URL,
  envServer.SERVICE_ROLE_KEY,
);

// Read Replica (읽기 전용)
const supabaseReplica = createClient(
  envServer.SUPABASE_READ_REPLICA_URL,  // Read Replica URL
  envServer.SUPABASE_ANON_KEY,  // 읽기 전용이므로 ANON_KEY 사용 가능
);

// 통계 쿼리는 Read Replica 사용
export async function getDashboardStats(tenantId: string) {
  return withTenant(
    supabaseReplica
      .from('analytics.daily_metrics')
      .select('*')
      .order('date', { ascending: false })
      .limit(30),
    tenantId,
  );
}

⚠️ 주의: Read Replica는 복제 지연(replication lag)이 있을 수 있으므로, 실시간성이 중요한 쿼리는 Primary를 사용합니다.

복제 지연 모니터링:
- pg_stat_replication 모니터링
- UI에 "최근 동기화 시각(KST)" 배지 표기

파티셔닝 전략:

[불변 규칙] 대용량 테이블은 반드시 파티셔닝을 적용합니다.

파티셔닝 대상 테이블:
- attendance_logs (로그성)
- invoice_items (거래 로그)
- notification_logs (알림 로그)
- audit_logs (감사 로그)
- analytics.events (이벤트 로그)

파티셔닝 전략:

로그성 테이블: tenant_id + 날짜(월) 기준 RANGE 파티셔닝

CREATE TABLE attendance_logs (
  id bigserial,
  tenant_id uuid NOT NULL,
  occurred_at timestamptz NOT NULL,
  ...
) PARTITION BY RANGE (occurred_at);

CREATE TABLE attendance_logs_2025_01
  PARTITION OF attendance_logs
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE INDEX ON attendance_logs_2025_01 (tenant_id, occurred_at DESC);

[불변 규칙] 로그성 테이블(attendance_logs, analytics.events 등)의 모든 파티션에는 반드시 (tenant_id, occurred_at DESC) 복합 인덱스가 적용되어야 합니다.

→ 파티셔닝 기준이 없으면, 5~10년 데이터가 쌓였을 때 인덱스가 비효율적이 됩니다.

파티셔닝 도입 기준 및 타이밍:

⚠️ Critical: 파티셔닝은 성능 저하가 발생하기 전에 미리 도입해야 합니다.

📌 파티셔닝 기준 수치 및 근거:

로그성 테이블 (attendance_logs, analytics.events 등):
- 도입 기준: 단일 파티션 1억 rows 또는 파티션 파일 크기 ~50GB 도달
- 근거: 로그성 테이블은 시간 기반 조회가 주 패턴이며, 인덱스 크기가 커질수록 성능 저하가 급격히 발생. 1억 rows 기준은 PostgreSQL 인덱스 효율성 임계값 근거
- 도입 타이밍: 임계값의 50~70% 도달 시점 (5천만 rows 또는 25GB 도달 시)에 미리 도입

코어 테이블 (students, invoices 등):
- 도입 기준: 테넌트 수 ≥ 5,000, 총 rows ≥ 5천만 또는 테이블 크기 ≥ 200GB 시 industry_type 기반 파티셔닝 검토
- 근거: 코어 테이블은 로그성 테이블보다 조회 패턴이 다양하고, tenant_id + industry_type 복합 인덱스로 인해 인덱스 크기가 더 크게 증가. 200GB 기준은 코어 테이블의 복잡한 인덱스 구조를 고려한 수치
- 도입 타이밍: 임계값의 50~70% 도달 시점에 미리 도입

→ 파티셔닝 도입은 "성능 문제 해결"이 아니라 "성능 문제 예방" 목적입니다.

Supabase 쿼터 / 제한:

⚠️ 중요: Supabase는 "서버리스처럼 무한정 쓴다"는 착각을 하면 안 됩니다. 플랜별 제한이 있습니다.

주요 제한 사항 (예시, 실제는 Supabase 최신 문서 확인 필요):

함수 실행 수:
- Free: 제한적
- Pro: 월간 실행 수 제한
- Enterprise: 더 높은 제한

스토리지:
- 파일 저장 용량 제한
- 대용량 파일 업로드 시 주의

네트워크 전송량:
- 월간 전송량 제한
- 대용량 리포트 다운로드 시 주의

DB 크기:
- 플랜별 최대 DB 크기 제한
- 파티셔닝으로 오래된 데이터 아카이빙 필요

모니터링 전략:
- Supabase Dashboard에서 사용량 모니터링
- 쿼터 임계값 설정 (예: 80% 도달 시 알림)
- Phase 2+에서 플랜 업그레이드 검토

→ 상세 제약사항은 Supabase 최신 공식 문서를 반드시 확인해야 합니다.

3-2. 멀티테넌트 & RLS 설계 원칙 (Critical)

⚠️ 중요: 이 섹션은 멀티테넌트 구조의 핵심 설계 원칙을 명시합니다.

3-2-1. tenant_id 전략 및 PK 설계

[불변 규칙] 모든 비즈니스 테이블은 tenant_id를 필수 컬럼으로 포함합니다.

[불변 규칙] PK 설계는 bigserial id + tenant_id 조합을 사용합니다. (tenant_id, local_id) 복합키는 사용하지 않습니다.

PK 설계 원칙:

✅ 권장 패턴 (표준):
CREATE TABLE students (
  id bigserial PRIMARY KEY,
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  name text NOT NULL,
  created_at timestamptz NOT NULL DEFAULT now(),
  ...
);

CREATE INDEX idx_students_tenant ON students(tenant_id);
CREATE INDEX idx_students_tenant_created ON students(tenant_id, created_at DESC);

❌ 금지 패턴:
CREATE TABLE students (
  tenant_id uuid NOT NULL,
  local_id bigint NOT NULL,
  PRIMARY KEY (tenant_id, local_id),  -- 복합키 사용 금지
  ...
);

이유:
- bigserial id는 전역 유니크성을 보장하여 외부 시스템 연동 시 안전
- 복합키는 JOIN 복잡도 증가 및 외래키 참조 어려움
- 인덱스 성능 측면에서 bigserial 단일 PK가 유리

industry_type 처리 전략:

[불변 규칙] industry_type은 tenants 테이블에서 조인하여 가져오는 것을 기본으로 하며, 자주 조회되는 테이블(students, invoices 등)에는 컬럼으로 함께 저장합니다.

옵션 1 (권장): 테이블에 industry_type 컬럼 포함
CREATE TABLE students (
  id bigserial PRIMARY KEY,
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  industry_type text NOT NULL,  -- tenants.industry_type과 동일
  name text NOT NULL,
  ...
);

옵션 2: tenant_settings에서 조인 (특수 케이스용)
-- 자주 조회되지 않는 테이블에서만 사용
SELECT s.*, t.industry_type
FROM students s
JOIN tenants t ON s.tenant_id = t.id;

→ 기본은 옵션 1이며, 옵션 2는 특수 케이스에서만 사용합니다.

3-2-2. RLS 규칙 템플릿 및 테이블 그룹 구분

[불변 규칙] RLS 정책은 테이블 그룹별로 다르게 적용합니다.

테이블 그룹 분류:

A. 완전 테넌트별 격리 테이블 (모든 비즈니스 데이터)

예: students, invoices, payments, attendance_logs, guardians, classes 등

RLS 정책 템플릿 (표준):

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, 반드시 JWT claim 기반 RLS를 사용해야 합니다.

옵션 1: JWT claim 기반 RLS (권장, Transaction Pooling 호환):

ALTER TABLE public.students ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_students ON public.students
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
);

→ JWT claim에서 tenant_id를 직접 읽어 RLS 정책 적용
→ PgBouncer Transaction Pooling과 완벽 호환
→ Supabase JWT 생성 시 tenant_id를 claim에 포함해야 함

옵션 2: 세션 변수 기반 RLS (Session Pooling 또는 전용 커넥션 전용):

ALTER TABLE public.students ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_students ON public.students
FOR ALL TO authenticated
USING (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
)
WITH CHECK (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
);

→ NULLIF(current_setting(..., true), '') 패턴은 미설정 시 NULL을 반환하여 어떤 row도 통과하지 못하도록 안전 가드를 제공합니다.
→ ⚠️ 주의: 이 방식은 PgBouncer Transaction Pooling과 호환되지 않습니다. Session Pooling 또는 전용 커넥션을 사용하는 경우에만 유효합니다.

→ 쿼리층(services/*)에서는 항상 명시적 tenant_id 필터를 동시에 적용해야 합니다 (RLS는 보안 레이어, 필터링은 쿼리 레이어).

B. 전역 공통 테이블 (RLS 적용 안 함 또는 제한적 적용)

예: notification_templates, system_configs, core_regions 등

RLS 정책:
- Super Admin만 접근 가능하거나
- RLS 비활성화 (전역 공통 데이터)

예시:
ALTER TABLE notification_templates ENABLE ROW LEVEL SECURITY;

CREATE POLICY notification_templates_superadmin ON notification_templates
FOR ALL TO authenticated
USING (
  EXISTS (
    SELECT 1 FROM user_tenant_roles
    WHERE user_id = auth.uid()
    AND role = 'super_admin'
  )
);

C. 익명 접근 허용 테이블 (Public 데이터)

예: public_landing_pages, public_announcements 등

RLS 정책:
- SELECT는 익명 사용자도 허용
- INSERT/UPDATE/DELETE는 인증된 사용자만

예시:
CREATE POLICY public_landing_pages_read ON public_landing_pages
FOR SELECT
TO public
USING (true);  -- 모든 사용자 조회 가능

CREATE POLICY public_landing_pages_write ON public_landing_pages
FOR ALL
TO authenticated
USING (
  EXISTS (
    SELECT 1 FROM user_tenant_roles
    WHERE user_id = auth.uid()
    AND role IN ('super_admin', 'admin')
  )
);

3-2-3. Industry Layer 스키마 확장 전략

[불변 규칙] Industry Layer는 "Core Party 테이블 + 업종별 확장 테이블" 패턴을 사용합니다.

업종별로 완전 별도 테이블을 만드는 패턴은 사용하지 않습니다.

⚠️ 중요: Core Party 모델은 `core-party` 모듈에서 관리됩니다.

Core Party 테이블 (모든 업종 공통):

CREATE TABLE persons (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  name text NOT NULL,
  email text,
  phone text,
  address text,
  person_type text NOT NULL CHECK (person_type IN ('student', 'customer', 'member', 'resident', 'donor')),  -- 업종별 의미 다름
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now()
);

[불변 규칙] persons 테이블은 `core-party` 모듈에서 관리되며, Industry Layer는 이를 확장하여 사용합니다.

업종별 확장 테이블:

학원(academy):
CREATE TABLE academy_students (
  person_id uuid PRIMARY KEY REFERENCES persons(id),
  grade text,
  class_name text,
  school_name text,
  ...
);

CREATE TABLE academy_classes (
  id uuid PRIMARY KEY,
  tenant_id uuid NOT NULL,
  name text NOT NULL,
  ...
);

미용실(salon):
CREATE TABLE salon_customers (
  person_id uuid PRIMARY KEY REFERENCES persons(id),
  hair_type text,
  preferred_style text,
  ...
);

CREATE TABLE salon_reservations (
  id uuid PRIMARY KEY,
  tenant_id uuid NOT NULL,
  customer_id uuid REFERENCES salon_customers(person_id),
  service_id uuid,
  ...
);

부동산(real_estate):
CREATE TABLE estate_properties (
  id uuid PRIMARY KEY,
  tenant_id uuid NOT NULL,
  address text NOT NULL,
  property_type text,
  ...
);

CREATE TABLE estate_contracts (
  id uuid PRIMARY KEY,
  tenant_id uuid NOT NULL,
  property_id uuid REFERENCES estate_properties(id),
  tenant_person_id uuid REFERENCES persons(id),  -- 세입자
  ...
);

→ 업종별 확장 테이블은 Industry Layer에서 정의하며, Core Layer는 공통 persons 테이블만 제공합니다.

→ 업종이 늘어나도 테이블 수는 "업종 수 × 도메인 수"에 따라 늘어나며, 테넌트 수와는 무관합니다.

3-2-3-1. Industry Layer 확장 규범 (Critical)

⚠️ 중요: 업종별 스키마 확장 시 반드시 준수해야 하는 규칙입니다.

컬럼 확장 규칙:

Core Party 테이블 (persons)은 Core Layer에서 관리:
- Core Layer는 persons 테이블의 기본 컬럼만 제공
- Core Layer는 업종별 확장 컬럼을 추가하지 않음

업종별 확장 테이블은 Industry Layer에서 관리:
- 업종별 확장 테이블은 persons 테이블을 참조 (person_id FK)
- 업종별 확장 테이블은 업종 전용 컬럼만 포함
- 업종별 확장 테이블은 tenant_id 필수 포함

업종 공통 vs 업종 특화 구분:

업종 공통 컬럼 (Core Party 테이블):
- name, email, phone, address, person_type
- created_at, updated_at

업종 특화 컬럼 (업종별 확장 테이블):
- 학원: grade, class_name, school_name
- 미용실: hair_type, preferred_style
- 부동산: property_type, contract_type

스키마 버전 충돌 전략:

업종별 확장 테이블 추가 시:
- 마이그레이션 스크립트는 Industry Layer 패키지에 포함
- 마이그레이션 파일명: `{업종}_{테이블명}_{날짜}.sql`
- 예: `academy_students_20250115.sql`

업종 간 스키마 충돌 방지:
- 업종별 확장 테이블은 업종 prefix 사용 (academy_, salon_, estate_ 등)
- 테이블 이름 충돌 방지
- 인덱스 이름 충돌 방지 (tenant_id 인덱스는 업종별로 분리)

업종별 마이그레이션 실행 순서:
1. Core Layer 마이그레이션 (persons 테이블 변경)
2. Industry Layer 마이그레이션 (업종별 확장 테이블)
3. 데이터 마이그레이션 (기존 데이터 변환)

업종별 기본 엔티티 템플릿:

모든 업종은 다음 패턴을 따라야 함:

```sql
-- Core Party 테이블 (Core Layer)
CREATE TABLE persons (
  id uuid PRIMARY KEY,
  tenant_id uuid NOT NULL,
  name text NOT NULL,
  -- ... 공통 필드
);

-- 업종별 확장 테이블 (Industry Layer)
CREATE TABLE {업종}_{엔티티명} (
  person_id uuid PRIMARY KEY REFERENCES persons(id),
  tenant_id uuid NOT NULL,  -- 인덱스 필수
  -- ... 업종 특화 필드
);

-- 인덱스
CREATE INDEX idx_{업종}_{엔티티}_tenant ON {업종}_{엔티티명}(tenant_id);

-- RLS 정책
CREATE POLICY tenant_isolation_{업종}_{엔티티} ON {업종}_{엔티티명}
FOR ALL TO authenticated
USING (tenant_id = (auth.jwt() -> 'tenant_id')::uuid)
WITH CHECK (tenant_id = (auth.jwt() -> 'tenant_id')::uuid);
```

→ 이 템플릿을 따라야 업종 간 일관성 유지 및 확장 용이

3-2-4. Soft vs Hard Isolation 수준

현재 구조: Soft Isolation (공용 DB + RLS)

[불변 규칙] 현재 구조는 Soft Isolation(공용 DB + RLS)을 사용하며, 모든 테넌트가 단일 PostgreSQL 인스턴스에 공존합니다.

📌 Isolation 전략 구분 (Critical):

| Isolation 수준 | 적용 범위 | 설명 | Phase |
|----------------|----------|------|-------|
| **Soft Isolation** | 모든 테넌트 | 공용 DB + RLS + tenant_id 논리적 격리 | Phase 1-3 기본 |
| **업종별 분리** | 업종 단위 | industry_type 파티셔닝 → prefix 테이블 → 스키마 분리 | Phase 2-3+ |
| **Hot Tenant 분리** | 특정 테넌트 단위 | 특정 tenant_id만 별도 DB로 수직 분리 | Phase 3+ |
| **Hard Isolation** | 전체 구조 변경 | 테넌트 단위 DB 분리, Multi-Region | Phase 4+ |

⚠️ 중요: 이 4가지 전략은 서로 다른 목적과 범위를 가지며, 혼동하지 않도록 명확히 구분해야 합니다.

Soft Isolation 특징:
- 모든 테넌트가 동일 DB/스키마 공유
- RLS + tenant_id로 논리적 격리
- 테넌트 수 증가 시 행(row) 수만 증가, 테이블 구조는 동일
- 운영 비용 효율적, 관리 단순
- **적용 범위**: Phase 1-3 기본 구조, 2~3만 테넌트까지 충분

업종별 분리 (업종 단위 Isolation):
- **목적**: 특정 업종의 데이터량/조회량이 폭증할 때 해당 업종만 분리
- **방식**: industry_type 파티셔닝 → prefix 테이블 → 스키마 분리 (Migration Roadmap 참조)
- **적용 범위**: Phase 2-3+, 업종 단위로 선택적 적용
- **예시**: academy 업종만 academy.students 스키마로 분리

Hot Tenant 분리 (테넌트 단위 Isolation):
- **목적**: 특정 테넌트의 트래픽/데이터량이 전체 DB 성능에 영향을 줄 때 해당 테넌트만 분리
- **방식**: 특정 tenant_id 데이터를 별도 PostgreSQL 인스턴스로 수직 분리 (수동)
- **적용 범위**: Phase 3+, 테넌트 단위로 선택적 적용
- **예시**: 대형 학원 체인(단일 테넌트)만 별도 DB로 분리

Hard Isolation 로드맵 (Phase 4+ 전용):

⚠️ 중요: Hard Isolation은 수십만 테넌트 규모에서만 검토하는 옵션입니다.

Hard Isolation 옵션:

옵션 1: 테넌트 단위 DB 분리 (수동)
- 특정 Hot Tenant만 별도 PostgreSQL 인스턴스로 분리
- CDC(Change Data Capture) 기반 동기화
- 운영 복잡도 매우 높음

옵션 2: 프로젝트 단위 분리 (Supabase Multi-Project)
- Supabase는 공식적으로 Multi-Project 자동화를 지원하지 않음
- 수동으로 프로젝트 생성/관리 필요

옵션 3: 외부 DB 솔루션 (Neon, AWS RDS, Aurora)
- Multi-Region 지원 필요 시
- Supabase 제약을 벗어나야 할 때

→ Phase 1-3에서는 Soft Isolation만 사용하며, Phase 4 (수십만 테넌트) 이상에서만 Hard Isolation을 검토합니다.

→ 실제 2~3만 테넌트 수준에서는 Soft Isolation + 파티셔닝 + Read Replica만으로 충분합니다.

⚠️ 중요: 멀티테넌트/RLS 구조 안전성

이 조합(tenant_id NOT NULL + INDEX + RLS + 서비스 레이어 2중 필터)은 Supabase + PostgreSQL 멀티테넌트에서 거의 표준에 가까운 패턴으로, 보안/성능 관점에서 구조적으로 안전합니다.

다만, 개발팀에 계속 강조해야 할 사항:
- 쿼리에서 tenant_id 조건 빠지면 "동작은 하지만 느려지는" 케이스 → 모니터링 필요
- 특히 attendance_logs, analytics.events 같이 파티셔닝된 테이블은 tenant_id, occurred_at 인덱스 패턴을 반드시 지켜야 함


Edge Function에서 tenant_id 설정:

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, set_config는 작동하지 않으므로 JWT claim 기반 RLS를 사용해야 합니다.

옵션 1: JWT claim 기반 (권장):
- Supabase JWT 생성 시 tenant_id를 claim에 포함
- RLS 정책에서 auth.jwt() -> 'tenant_id'로 읽기
- Edge Function에서 별도 설정 불필요

옵션 2: 세션 변수 기반 (Session Pooling 또는 전용 커넥션 전용) - ⚠️ Deprecated:

🚨 [불변 규칙] set_config('app.current_tenant_id')는 RLS 정책에서 직접 사용해서는 안 됩니다.

⚠️ 중요: 이 방식은 Supabase 환경에서 기본적으로 사용하는 PgBouncer Transaction Pooling과 호환되지 않으므로, 절대 사용하지 않습니다.

⚠️ Deprecated: Edge Function에서 set_config 호출은 더 이상 권장하지 않습니다:
```sql
-- ❌ 금지: RLS 정책에서 직접 사용하는 경우
SELECT set_config('app.current_tenant_id', tenant_id, true);
```

✅ 대신: JWT claim 기반 RLS를 사용하세요 (옵션 1 참조)

3-3. 스키마 분리

기본 구조: public 스키마 + industry_type 컬럼으로 관리 (표준)

모든 도메인 테이블은 public 스키마에 저장되며, industry_type 컬럼으로 업종을 구분한다.

스키마	역할
public	대부분의 도메인 (기본 패턴)
analytics	집계/통계
meta	배치/마이그레이션 관리
audit	감사 로그 (조회 포함)

업종별 데이터 분리 전략 (계층적 확장):

📌 상위 원칙 (철학적 통일성):

[불변 규칙] 기본 철학은 "단일 테이블 + industry_type 컬럼 + Soft Isolation"이며, 모든 확장 전략은 이 기본 구조를 유지하면서 선택적으로 분리하는 방식입니다.

핵심 원칙:
1. 기본 구조: 모든 업종이 public 스키마의 동일 테이블에 공존 (industry_type 컬럼으로 구분)
2. 확장 전략: 특정 업종의 데이터량/조회량이 폭증할 때만 해당 업종을 선택적으로 분리
3. 분리 범위: 전체 구조를 변경하지 않고, 필요한 업종만 선택적으로 분리
4. 일관성 유지: 분리된 업종도 동일한 스키마 구조와 비즈니스 로직을 유지

⚠️ 중요: 업종별 데이터 분리는 3가지 모델이 있으나, 도입 순서와 조건이 명확히 구분되어야 합니다.

📌 Migration Roadmap (업종별 데이터 분리 전략) - 통합 전환 기준표:

| 단계 | 분리 방식 | 전환 기준 (명확한 수치) | 설명 |
|------|----------|----------------------|------|
| Phase 1 | industry_type 컬럼 단일 테이블 | 테넌트 수 < 5,000<br>테이블 크기 < 50GB<br>단일 업종 row 수 < 1천만 | 기본 구조. 모든 업종이 public 스키마의 동일 테이블에 공존 |
| Phase 2 | industry_type 기반 파티셔닝 | 특정 업종 row 수 ≥ 1천만<br>또는 특정 업종 테이블 크기 ≥ 50GB<br>또는 특정 업종 QPS가 전체의 30% 초과 | SELECT 경로 차별화 용도. 예: `students_academy PARTITION OF students FOR VALUES IN ('academy')` |
| Phase 2+ | 업종별 prefix 테이블 (선택적) | 업종 전용 도메인 테이블 필요 시<br>(Core Party 테이블과는 별개) | 업종 전용 도메인 테이블만. 예: `academy_classes`, `salon_customers` (Core Party 테이블과는 별개) |
| Phase 3+ | 업종별 스키마 분리 | 테넌트 수 ≥ 20k<br>또는 Core 테이블(students/invoices) 단일 파티션 ≥ 200GB<br>또는 특정 업종 조회량이 전체의 50% 초과 | 조회량 편중 시. 예: `academy.students`, `salon.customers` |

📌 전환 기준 상세 설명:

1. **테넌트 수 기준**: 전체 테넌트 수가 증가하면 업종별 분리 필요성 증가
2. **테이블 크기 기준**: 단일 테이블 또는 파티션이 50GB(파티셔닝) 또는 200GB(스키마 분리) 도달 시 성능 저하
3. **Row 수 기준**: 특정 업종의 row 수가 1천만 이상이면 파티셔닝 검토
4. **트래픽 기준**: 특정 업종의 QPS가 전체의 30% 초과 시 파티셔닝, 50% 초과 시 스키마 분리 검토
5. **업종별 데이터 증가 속도**: 월간 증가율이 10% 이상 지속되면 조기 전환 검토

⚠️ 중요: 위 기준 중 하나라도 도달하면 해당 업종만 선택적으로 분리합니다. 전체 구조를 변경하지 않고 필요한 업종만 분리하는 것이 핵심 원칙입니다.

⚠️ 중요: 업종별 스키마 분리(academy.students)와 업종별 테이블 prefix(academy_classes)는 서로 다른 전략이며, 둘 중 하나만 선택합니다. 둘을 동시에 사용하지 않습니다.

기본 원칙:
- 기본은 public 스키마 + industry_type 컬럼
- 확장은 파티셔닝 → prefix 테이블 → 스키마 분리 순서로 검토
- 업종별 스키마 분리는 "특수 케이스(초대규모)"에만 제한적으로 사용
- ⚠️ 중요: "3만 테넌트까지 괜찮다"는 것은 Soft Isolation 구조를 유지할 수 있다는 의미이며, 업종별 분리 전략(파티셔닝/prefix/스키마 분리)은 3만 테넌트 이전에도 필요할 수 있습니다. 업종별 데이터량/조회량이 폭증하면 해당 업종만 선택적으로 분리합니다.

3-4. 중앙 환경변수 관리 시스템 (Critical)

⚠️ 중요: 모든 환경변수는 packages/env-registry를 통해서만 접근해야 하며, process.env 직접 접근은 금지됩니다.

3-4-1. 구조 및 위치

packages/env-registry/

├─ src/
│  ├─ index.ts                 # 진입점 (server/client/common export)
│  ├─ server.ts                # 🔵 서버/Edge 전용 (Node + Edge + Supabase용)
│  ├─ client.ts                # 🔵 클라이언트 전용 (React/Next.js 클라이언트용)
│  ├─ common.ts                # 🔵 서버/클라이언트 공통 (앱명, 버전정보 등)
│  ├─ schema.ts                 # Zod 기반 환경변수 스키마 정의
│  └─ resolve.ts               # Vercel/Supabase 환경변수 로딩 로직 (Edge/App/Node 환경 자동 인식)
├─ .env.example                # 환경변수 예시 파일 (실제 키 제외)
└─ package.json

⚠️ 중요: 환경변수 파일 위치
- 프로젝트 루트 디렉토리: .env.local (로컬 개발용, gitignore, 중앙 관리)
- packages/env-registry/.env.example: 예시 파일만 (실제 키 제외)
- 모든 앱과 패키지는 루트의 .env.local 파일을 공유하며, packages/env-registry/src/server.ts에서 dotenv로 자동 로드됨

3단계 분리 구조:
- 🔵 server-env: 모든 SECRET 변수 포함 (SERVICE_ROLE_KEY, webhook secret 등)
- 🔵 client-env: NEXT_PUBLIC_*로 시작하는 변수만 (절대 Service Role Key 포함 X)
- 🔵 common-env: 서버/클라이언트 공통 (industry_mode, 앱명, 버전정보 등)

특징:
- 유효성 검증(Zod): Missing 변수 에러 즉시 표시
- Edge / App / Node 환경 자동 인식
- 서버/클라이언트/공통 3단계 분리: 비밀 값이 클라이언트 번들에 포함되지 않도록 보호
- Cursor가 .env 직접 접근할 일 없음
- 타입 안정성 보장

3-4-2. 핵심 원칙

[불변 규칙] 서버/Edge/Node 코드(services/*, Edge Functions, Server Components)는 process.env를 직접 사용하지 않고 반드시 packages/env-registry에서 export된 envServer 객체를 사용해야 합니다.

[불변 규칙] React 클라이언트 코드에서는 @env-registry/server import는 금지이고, @env-registry/client, envClient/envCommon만 사용합니다. Service Role Key가 포함된 envServer는 절대 클라이언트 번들에 들어가면 안 됩니다.

[불변 규칙] 환경변수는 애플리케이션 시작 시 한 번만 검증되며, 누락되거나 잘못된 값이 있으면 즉시 에러를 발생시켜야 합니다.

[불변 규칙] 민감한 정보(Service Role Key, Webhook Secret 등)는 타입 안정성을 보장하면서도 런타임에만 접근 가능하도록 설계해야 합니다.

[불변 규칙] Edge/App/Node 환경은 자동으로 인식되며, 각 환경에 맞는 환경변수 로딩 전략을 사용합니다.

[불변 규칙] envServer는 서버/Edge 전용이며, 클라이언트 번들에 포함되면 안 됩니다. ESLint 규칙으로 강제합니다.

3-4-3. 환경변수 스키마 정의 예시

// packages/env-registry/src/schema.ts
import { z } from 'zod';

// 서버/Edge 전용 스키마 (모든 환경변수 포함)
const envServerSchema = z.object({
  // Supabase
  SUPABASE_URL: z.string().url(),
  SUPABASE_ANON_KEY: z.string().min(1),
  SERVICE_ROLE_KEY: z.string().min(1),  // Edge Function / 서버 전용
  SUPABASE_READ_REPLICA_URL: z.string().url().optional(),  // Phase 2+ Read Replica (읽기 전용)

  // 환경 구분
  NODE_ENV: z.enum(['development', 'staging', 'production']),

  // 결제/알림뱅킹 (Phase 1 필수, 실제 사용 시점에 requireEnv()로 체크)
  PAYMENT_ALIMBANK_API_URL: z.string().url().optional(),
  PAYMENT_ALIMBANK_API_KEY: z.string().min(1).optional(),
  PAYMENT_WEBHOOK_SECRET: z.string().min(1).optional(),

  // Phase 2+ (Role 분리)
  PAYMENT_WEBHOOK_ROLE_KEY: z.string().min(1).optional(),
  BILLING_BATCH_ROLE_KEY: z.string().min(1).optional(),
  ANALYTICS_ROLE_KEY: z.string().min(1).optional(),

  // Custom Domain (Phase 2+)
  CUSTOM_DOMAIN_VERIFY_SECRET: z.string().min(1).optional(),

  // 외부 워커 (Phase 2+)
  AWS_LAMBDA_ANALYTICS_FUNCTION_NAME: z.string().optional(),
  CLOUDFLARE_WORKER_ANALYTICS_URL: z.string().url().optional(),

  // Kakao Maps API (Phase 2+ 지도 기능용, 서버/Edge Function 전용)
  KAKAO_REST_API_KEY: z.string().min(1).optional(),
});

// 클라이언트 전용 스키마 (NEXT_PUBLIC_* 등 빌드타임 노출 값만)
const envClientSchema = z.object({
  NEXT_PUBLIC_SUPABASE_URL: z.string().url().optional(),
  NEXT_PUBLIC_SUPABASE_ANON_KEY: z.string().min(1).optional(),
  NEXT_PUBLIC_KAKAO_JS_KEY: z.string().min(1).optional(),  // Phase 2+ 지도 기능용 (JavaScript SDK)
  // 클라이언트에 노출 가능한 공개 값만 포함
  // 절대 Service Role Key나 비밀 값 포함 금지
});

// 서버/Edge 전용 공통 스키마 (앱명, 버전정보 등)
// 클라이언트에서 필요한 값은 NEXT_PUBLIC_*로 envClient에 포함
const envCommonSchema = z.object({
  APP_NAME: z.string().min(1).optional(),
  APP_VERSION: z.string().min(1).optional(),
  INDUSTRY_MODE: z.enum(['academy', 'salon', 'real_estate', 'gym', 'ngo']).optional(),
  // 서버/Edge에서만 사용하는 공개 값
});

export type EnvServer = z.infer<typeof envServerSchema>;
export type EnvClient = z.infer<typeof envClientSchema>;
export type EnvCommon = z.infer<typeof envCommonSchema>;
export { envServerSchema, envClientSchema, envCommonSchema };

// packages/env-registry/src/resolve.ts
/**
 * 서버/Edge 환경별 환경변수 로딩 전략
 * - Edge Function (Supabase): Deno.env.toObject()
 * - Vercel (App/Node): process.env
 * - 로컬 개발: process.env (dotenv로 루트 디렉토리의 .env.local 파일 자동 로드)
 *
 * ⚠️ 주의: 브라우저 환경에서는 사용 불가 (resolveEnv() 호출 시 에러 발생)
 *
 * 환경변수 파일 위치:
 * - 프로젝트 루트 디렉토리: .env.local (로컬 개발용, 중앙 관리)
 * - packages/env-registry/src/server.ts에서 dotenv로 자동 로드
 */
export function resolveEnv(): Record<string, string | undefined> {
  // Edge Function 환경 감지 (Supabase Edge Functions는 Deno 런타임)
  if (typeof Deno !== 'undefined' && Deno.env) {
    const env: Record<string, string | undefined> = {};
    for (const [key, value] of Object.entries(Deno.env.toObject())) {
      env[key] = value;
    }
    return env;
  }

  // Node.js / Vercel 환경
  if (typeof process !== 'undefined' && process.env) {
    return process.env;
  }

  throw new Error(
    '환경변수 접근 불가: Edge/App/Node 환경을 감지할 수 없습니다.\n' +
    '브라우저 환경에서는 env-registry/server를 사용할 수 없습니다.\n' +
    '클라이언트 코드에서는 NEXT_PUBLIC_* 등 빌드타임 값을 직접 사용하세요.'
  );
}

// packages/env-registry/src/server.ts
import { envServerSchema, type EnvServer } from './schema';
import { resolveEnv } from './resolve';

function validateEnvServer(): EnvServer {
  const rawEnv = resolveEnv();
  const parsed = envServerSchema.safeParse(rawEnv);

  if (!parsed.success) {
    const errors = parsed.error.errors.map(e =>
      `${e.path.join('.')}: ${e.message}`
    ).join('\n');

    const missingVars = parsed.error.errors
      .filter(e => e.code === 'invalid_type' && e.received === 'undefined')
      .map(e => e.path.join('.'))
      .join(', ');

    throw new Error(
      `환경변수 검증 실패:\n${errors}\n\n` +
      (missingVars ? `누락된 필수 환경변수: ${missingVars}\n\n` : '') +
      `필수 환경변수가 누락되었거나 형식이 잘못되었습니다.\n` +
      `프로젝트 루트 디렉토리에 .env.local 파일을 생성하거나, packages/env-registry/.env.example 파일을 참고하세요.`
    );
  }

  return parsed.data;
}

// 애플리케이션 시작 시 한 번만 검증
export const envServer = validateEnvServer();

// 타입 안전한 접근
// 사용 예: envServer.SUPABASE_URL, envServer.SERVICE_ROLE_KEY

// packages/env-registry/src/client.ts
import { envClientSchema, type EnvClient } from './schema';

function validateEnvClient(): EnvClient {
  // 클라이언트 환경에서는 process.env가 빌드타임에 인라인됨
  // Next.js의 경우 NEXT_PUBLIC_*만 클라이언트 번들에 포함
  // ⚠️ 주의: 클라이언트 번들에서 process.env는 빌드 타임에만 존재하며,
  // 런타임(브라우저)에서는 이미 값이 인라인되어 있어 process.env 객체 자체는 undefined일 수 있습니다.
  if (typeof window !== 'undefined' || typeof process === 'undefined') {
    // 브라우저 환경에서는 빌드타임에 이미 값이 인라인되어 있음
    const rawEnv: Record<string, string | undefined> = {};
    if (typeof process !== 'undefined' && process.env) {
      // 빌드타임에 이미 NEXT_PUBLIC_* 값만 포함됨
      // 런타임에서는 process.env가 undefined일 수 있지만, 빌드타임에 인라인된 값은 정상 동작합니다.
      for (const key in process.env) {
        if (key.startsWith('NEXT_PUBLIC_')) {
          rawEnv[key] = process.env[key];
        }
      }
    }
    const parsed = envClientSchema.safeParse(rawEnv);
    return parsed.success ? parsed.data : ({} as EnvClient);
  }

  // 서버 사이드 렌더링 중에도 클라이언트 스키마만 사용
  const rawEnv: Record<string, string | undefined> = {};
  if (process.env) {
    for (const key in process.env) {
      if (key.startsWith('NEXT_PUBLIC_')) {
        rawEnv[key] = process.env[key];
      }
    }
  }
  const parsed = envClientSchema.safeParse(rawEnv);
  return parsed.success ? parsed.data : ({} as EnvClient);
}

export const envClient = validateEnvClient();

// packages/env-registry/src/common.ts
import { envCommonSchema, type EnvCommon } from './schema';

function validateEnvCommon(): EnvCommon {
  // 공통 환경변수는 기본적으로 서버/Edge에서 사용
  // 클라이언트에서 필요한 값은 NEXT_PUBLIC_*로 별도 노출
  const rawEnv: Record<string, string | undefined> = {};

  if (typeof process !== 'undefined' && process.env) {
    // APP_NAME, APP_VERSION, INDUSTRY_MODE 등 공개 값만
    for (const key in process.env) {
      if (['APP_NAME', 'APP_VERSION', 'INDUSTRY_MODE'].includes(key)) {
        rawEnv[key] = process.env[key];
      }
    }
  }

  const parsed = envCommonSchema.safeParse(rawEnv);
  return parsed.success ? parsed.data : ({} as EnvCommon);
}

export const envCommon = validateEnvCommon();

// packages/env-registry/src/index.ts
// 🔵 서버/Edge 전용 export (클라이언트에서 import 시 ESLint 에러)
export { envServer } from './server';
export type { EnvServer } from './schema';

// 🔵 클라이언트 전용 export
export { envClient } from './client';
export type { EnvClient } from './schema';

// 🔵 서버/Edge 전용 공통 export (클라이언트에서는 사용하지 않음)
// envCommon은 서버/Edge에서만 사용하며, 클라이언트에서 필요한 값은 NEXT_PUBLIC_*로 envClient에 포함
export { envCommon } from './common';
export type { EnvCommon } from './schema';

3-4-4. 사용 패턴

❌ 금지 (process.env 직접 접근):
const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.SERVICE_ROLE_KEY!,
);

✅ 허용 (서버/Edge 코드):
import { envServer } from '@env-registry/server';

const supabase = createClient(
  envServer.SUPABASE_URL,
  envServer.SERVICE_ROLE_KEY,
);

✅ 허용 (클라이언트 코드):
// 클라이언트에서는 NEXT_PUBLIC_* 값만 직접 사용
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

// 또는 선택적으로 envClient 사용 (빌드타임 값만)
import { envClient } from '@env-registry/client';
const supabaseUrl = envClient.NEXT_PUBLIC_SUPABASE_URL;

❌ 절대 금지 (클라이언트 코드):
import { envServer } from '@env-registry/server';  // ESLint 에러 발생
// Service Role Key가 클라이언트 번들에 포함될 위험

3-4-5. 환경별 설정 관리

개발 환경:
- 프로젝트 루트 디렉토리: .env.local (로컬 개발용, gitignore, 중앙 관리)
  - 모든 앱과 패키지가 이 파일을 공유
  - packages/env-registry/src/server.ts에서 dotenv로 자동 로드
- packages/env-registry/.env.example: 예시 파일 (실제 키 제외, git 포함)

스테이징/프로덕션:
- 환경변수는 배포 플랫폼(Vercel, Supabase Secrets 등)에서 관리
- 코드에는 기본값이나 예시만 포함

⚠️ 중요:
- .env.local 파일은 프로젝트 루트 디렉토리에만 생성 (각 앱별로 생성하지 않음)
- .env.local 파일에는 실제 Service Role Key를 포함하지 않고, 개발용 테스트 키만 사용합니다.

3-4-6. Edge Function에서의 사용

Edge Function은 Supabase Secrets를 통해 환경변수를 주입받으며, 동일한 packages/env-registry 패키지를 사용합니다.

resolve.ts가 자동으로 Deno 환경을 감지하여 Deno.env.toObject()를 사용합니다.

⚠️ 주의: Edge Function 번들에 env-registry 패키지를 포함할 때 번들 사이즈와 cold start 영향이 있을 수 있습니다. Phase 2+에서 실제 성능 측정 후 최적화를 검토합니다.

// supabase/functions/payment-webhook/index.ts
import { envServer } from '@env-registry/server';

// envServer.SERVICE_ROLE_KEY는 Supabase Secrets에서 자동 주입됨
// resolve.ts가 Deno 환경을 자동 감지하여 Deno.env에서 로드

3-4-7. Phase별 환경변수 관리

Phase 1 (MVP):
- SUPABASE_URL, SUPABASE_ANON_KEY, SERVICE_ROLE_KEY (단일)
- PAYMENT_ALIMBANK_* (결제 연동) - 스키마는 optional이지만 실제 사용 시점에 requireEnv()로 체크
- PAYMENT_WEBHOOK_SECRET

Phase 2+ (확장):
- Read Replica: SUPABASE_READ_REPLICA_URL (읽기 전용, 통계/리포트 쿼리 분리용)
- Role 분리: PAYMENT_WEBHOOK_ROLE_KEY, BILLING_BATCH_ROLE_KEY 등
- Custom Domain: CUSTOM_DOMAIN_VERIFY_SECRET
- 외부 워커: AWS_LAMBDA_*, CLOUDFLARE_WORKER_* 등
- Kakao Maps API: KAKAO_REST_API_KEY (서버/Edge Function 전용), NEXT_PUBLIC_KAKAO_JS_KEY (클라이언트 전용)

→ Phase 2+ 환경변수는 .optional()로 정의하여 MVP에서 누락되어도 검증 에러가 발생하지 않도록 합니다.

3-4-7-1. Optional 환경변수의 실제 사용 시점 체크 (Lazy Validation)

Phase 1에서 알림뱅킹은 필수 기능이지만, 스키마에서는 optional로 정의하여 알림뱅킹이 활성화되지 않은 환경에서는 앱 시작 시 에러가 발생하지 않도록 합니다.

실제 payment-alimbank, analytics, custom-domain 모듈에서 사용 시점에 requireEnv() 유틸을 사용하여 강하게 체크합니다 (Lazy Validation):

// packages/payments/payment-alimbank/src/env.ts
import { envServer, type EnvServer } from '@env-registry/server';

/**
 * 환경변수가 실제로 필요한 시점에만 체크하는 유틸 (Lazy Validation)
 * Phase 1에서 알림뱅킹은 필수이지만, 스키마는 optional로 정의되어 있음
 *
 * 사용 패턴:
 * const secret = envServer.PAYMENT_ALIMBANK_SECRET;
 * if (!secret) throw new Error("PAYMENT_ALIMBANK_SECRET missing");
 *
 * 또는 requireEnv() 유틸 사용:
 */
export function requireEnv<K extends keyof EnvServer>(
  key: K
): NonNullable<EnvServer[K]> {
  const value = envServer[key];
  if (!value) {
    throw new Error(
      `환경변수 ${key}가 설정되어 있지 않습니다. (payment-alimbank 모듈)\n` +
      `알림뱅킹 기능을 사용하려면 이 환경변수가 필수입니다.`
    );
  }
  return value as NonNullable<EnvServer[K]>;
}

// 사용 예시
// packages/payments/payment-alimbank/src/client.ts
import { requireEnv } from './env';

const apiUrl = requireEnv('PAYMENT_ALIMBANK_API_URL');
const apiKey = requireEnv('PAYMENT_ALIMBANK_API_KEY');
const webhookSecret = requireEnv('PAYMENT_WEBHOOK_SECRET');

// 또는 직접 체크 (간단한 경우)
const secret = envServer.PAYMENT_ALIMBANK_SECRET;
if (!secret) throw new Error("PAYMENT_ALIMBANK_SECRET missing");

→ 이렇게 하면 Phase 1에서 알림뱅킹 기능을 실제로 "사용하는 순간"에만 강하게 에러를 띄우고, 알림뱅킹이 아직 활성화되지 않은 환경에서는 그냥 그 코드를 안 타면 됩니다.

→ Payment, Analytics, Custom Domain 모듈 모두 동일한 패턴을 사용합니다.

3-4-7-2. 테넌트별 환경변수 관리 (Phase 3+ 전용)

⚠️ 중요: 이 섹션은 Phase 3 (20k+ 테넌트) 이상에서만 검토하는 기능입니다.

현재 구조는 "환경변수는 전역(Global)"이지만, SaaS가 커지면 "테넌트별 Secret Storage"가 필요해질 수 있습니다.

사용 사례:
- Larger SaaS 고객이 자체 PG 계약을 사용하고 싶을 때
- Industry Layer에 따라 키가 달라질 때
- 테넌트별 Custom Domain Key 관리가 필요한 경우

구조 예시:

CREATE TABLE tenant_secrets (
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  secret_key text NOT NULL,  -- 예: 'payment_alimbank_api_key', 'custom_domain_verify_secret'
  secret_value text NOT NULL,  -- 암호화된 값
  encrypted_at timestamptz NOT NULL DEFAULT now(),
  key_version smallint DEFAULT 1,
  PRIMARY KEY (tenant_id, secret_key)
);

CREATE INDEX idx_tenant_secrets_tenant ON tenant_secrets(tenant_id);

ALTER TABLE tenant_secrets ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_tenant_secrets ON tenant_secrets
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
);

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, JWT claim 기반 RLS를 사용해야 합니다. set_config 기반 RLS는 Session Pooling 또는 전용 커넥션 전용입니다.

보안 고려사항:
- secret_value는 반드시 암호화하여 저장 (AEAD 암호화, Phase 3+)
- KMS 기반 키 회전 지원
- 테넌트별 Secret 접근은 RLS로 격리

사용 패턴:

// packages/services/tenant-secret-service.ts
// services/tenant-secret-service.ts
import { withTenant } from '../_db';

export async function getTenantSecret(
  tenantId: string,
  secretKey: string
): Promise<string | null> {
  // RLS로 자동 필터링 + withTenant() 사용
  const { data } = await withTenant(
    supabase
      .from('tenant_secrets')
      .select('secret_value, key_version')
      .eq('secret_key', secretKey),
    tenantId
  ).single();

  if (!data) return null;

  // 복호화 후 반환
  return decryptSecret(data.secret_value, data.key_version);
}

→ Phase 1-2에서는 전역 환경변수만 사용하며, Phase 3+에서 테넌트별 Secret Storage를 도입합니다.

3-4-8. 보안 고려사항

[불변 규칙] Service Role Key는 프론트엔드 코드(apps/*의 Client Components)에서 절대 사용하지 않으며, Edge Function과 서버 사이드 코드에서만 사용됩니다.

[불변 규칙] envServer는 서버/Edge 전용이며, 클라이언트 번들에 포함되면 안 됩니다. ESLint 규칙으로 강제합니다.

[불변 규칙] 환경변수는 코드에 하드코딩하지 않고, 반드시 환경변수 또는 Secrets 관리 시스템을 통해 주입받아야 합니다.

[불변 규칙] .env.local 파일은 git에 커밋하지 않으며, 프로젝트 루트 디렉토리에만 생성합니다 (각 앱별로 생성하지 않음).
[불변 규칙] packages/env-registry/.env.example 파일에 예시만 포함합니다 (실제 키 제외).

3-4-8-1. ESLint 규칙 (클라이언트에서 envServer import 금지)

클라이언트 코드에서 envServer를 import하면 Service Role Key 등 비밀 값이 번들에 포함될 위험이 있습니다.

ESLint 규칙으로 강제합니다:

// .eslintrc.json (apps/* 프로젝트)
{
  "rules": {
    "no-restricted-imports": [
      "error",
      {
        "paths": [
          {
            "name": "@env-registry/server",
            "message": "클라이언트 코드에서는 @env-registry/server를 import할 수 없습니다. NEXT_PUBLIC_* 값만 직접 사용하세요."
          }
        ],
        "patterns": [
          {
            "group": ["@env-registry/server"],
            "message": "클라이언트 코드에서는 @env-registry/server를 import할 수 없습니다."
          }
        ]
      }
    ]
  }
}

→ 클라이언트 컴포넌트에서 envServer를 import하려고 하면 빌드 시점에 ESLint 에러가 발생합니다.

3-4-9. Phase별 확장 전략

Phase 1 (MVP) - 현재 방식 (A안: Monorepo 내부 패키지):
- packages/env-registry/ 사용
- Zod 기반 검증
- Edge/App/Node 환경 자동 인식
- Vercel Environment Variables + Supabase Secrets

Phase 2+ (확장 시 고려 가능한 옵션):

B안) 외부 비밀 관리 시스템 연동:
- AWS SSM Parameter Store
- AWS Secrets Manager
- HashiCorp Vault
- Doppler / Infisical / 1Password Secrets Automation
- → DearSaaS 규모가 커지면 확장성과 보안 면에서 최상

C안) Supabase Config 기반:
- Edge Function: Supabase Secrets 사용
- 프론트와 Node: Vercel Environment Variables 사용
- 중앙 Manifest에서 동기화

⚠️ 중요: Phase 1에서는 A안(Monorepo 내부 패키지)을 사용하며, Phase 2+에서 실제 필요성이 확인된 후 B안 또는 C안으로 확장을 검토합니다.

4. Core 데이터 모델

4-0. Profile 확장 전략 (Critical)

업종별/테넌트별로 회원가입 양식/필드 구성이 다르므로, Profile 확장 전략이 필요하다.

옵션 1: 공통 profiles + 업종별 확장 테이블

공통 profiles 테이블:
CREATE TABLE profiles (
  id uuid PRIMARY KEY,
  user_id uuid NOT NULL,
  tenant_id uuid NOT NULL,
  name text,
  email text,
  phone text,
  created_at timestamptz
);

4-0-1. Profile Schema 변경 정책 (migration 없는 schema add/remove)

업종마다 다른 profile schema 정의 전략:

migration 없는 schema add/remove 정책 명시:

JSON Schema 기반 동적 필드 추가/제거는 migration 없이 가능

테이블 컬럼 추가/제거는 반드시 migration 필요

업종별 확장 테이블:

CREATE TABLE academy_profiles (
  profile_id uuid PRIMARY KEY REFERENCES profiles(id),
  grade text,        -- 학년
  class_name text,   -- 반
  school_name text   -- 학교명
);

CREATE TABLE salon_profiles (
  profile_id uuid PRIMARY KEY REFERENCES profiles(id),
  hair_type text,      -- 모발타입
  preferred_style text -- 선호스타일
);

옵션 2: 공통 profiles + extra_fields jsonb + JSON Schema

CREATE TABLE profiles (
  id uuid PRIMARY KEY,
  user_id uuid NOT NULL,
  tenant_id uuid NOT NULL,
  name text,
  email text,
  phone text,
  extra_fields jsonb,  -- 업종별/테넌트별 확장 필드
  created_at timestamptz
);

테넌트별 폼 설정은 tenant_settings.profile_schema에 JSON Schema로 저장:

{
  "schema": {
    "type": "object",
    "properties": {
      "grade": { "type": "string" },
      "class_name": { "type": "string" }
    }
  }
}

Core는 공통 필드만 알고, 업종별/테넌트별 폼은 JSON Schema 기반 렌더링

→ 업종/테넌트별 프로필 컬럼 차이 이슈 해결

4-1. Billing/Payment 공통 스키마
invoices

tenant_id

payer_id

amount

due_date

status

industry_type

…

invoice_items

item_type

category

quantity

unit_price

description

payments

invoice_id

provider(alimbank/toss/kg 등)

paid_at

amount

status

업종별 차이는 industry 모듈에서 templating/mapping,
DB는 Core에서 공통 유지.

4-1-1. 트랜잭션 격리 수준 명시 (Critical)

금융성 도메인은 트랜잭션 격리 수준을 명확히 정의해야 함:

Billing: REPEATABLE READ

청구서 생성 시 일관성 보장 필요

중복 청구 방지

Attendance: READ COMMITTED

출결 데이터는 실시간성이 중요

낮은 격리 수준으로 성능 최적화

Payments: REPEATABLE READ (권장)

SERIALIZABLE은 PostgreSQL에서 비용이 커서 REPEATABLE READ 권장

중복 결제 방지 및 금액 정합성 보장

설정 예시:

BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;

-- billing 작업 수행

COMMIT;

4-1-2. 멱등성 및 중복 방지 전략 (Critical)

⚠️ 중요: 멱등성 및 Duplicate 처리 상세 정책은 PART 3의 14-2-1-1 "결제/알림뱅킹 운영 정책" 섹션을 참조하세요.

멱등성 키 + 유니크 제약으로 논리적 중복 차단:

-- 청구서 멱등성 (테넌트·주기·템플릿 조합)
ALTER TABLE invoices
  ADD CONSTRAINT ux_invoice_period UNIQUE (tenant_id, period_start, period_end, template_key);

-- 결제 멱등성 (요청 단위)
ALTER TABLE payments
  ADD COLUMN idempotency_key text,
  ADD CONSTRAINT ux_payment_idem UNIQUE (tenant_id, idempotency_key);

-- Webhook 멱등성은 14-2-1-1 (audit.webhook_events) 섹션 참조

Advisory Lock 사용 (청구서 생성 시):

-- 서비스 계층에서 테넌트-주기 단위 Advisory Lock 사용
-- SELECT pg_advisory_xact_lock(hashtext(:tenant_id || :period_key));

-- 청구서 생성 전 락 획득 → 중복 생성 방지
-- 트랜잭션 종료 시 자동 해제

주의사항:

Supabase 플랜·pool 모드에 따라 트랜잭션 격리 수준 변경이 제한될 수 있으므로, 실제 prod 환경에서 지원 여부를 확인하고, 필요한 경우 DB 레벨 기본 격리 수준 또는 별도 전용 커넥션을 사용한다.

예시는 direct PG 접속 또는 전용 커넥션(논풀링) 기준이며, PgBouncer 트랜잭션 풀링일 때 SET류가 세션에 안 남는 문제가 있을 수 있다.

→ 금융성 도메인에서는 반드시 명시해야 함

4-2. 공통 도메인 예시

students, guardians, classes, attendance

members, contracts

contacts, properties

donors, donations

→ tenant_id + industry_type로 확장 지원.

4-3. Multi-Industry 공용 테이블 경쟁 위험 (Optional)

현재 구조는 industry_type + tenant_id 모델로 동작하며 매우 효율적입니다.

그러나 Core 테이블(students, invoices 등)은 여러 산업을 공유하므로 테이블이 수십~수백 GB 수준까지 커질 수 있습니다.

Industry 간 cross-traffic 영향 방지:

Core 테이블은 industry_type + tenant_id 복합 인덱스가 필수

예시:

CREATE INDEX idx_students_industry_tenant
ON students(industry_type, tenant_id, created_at DESC);


장기적으로 industry_type 단위 파티셔닝도 옵션으로 고려:

CREATE TABLE students_academy PARTITION OF students
FOR VALUES IN ('academy');

CREATE TABLE students_salon PARTITION OF students
FOR VALUES IN ('salon');

Industry 파티션 테이블명 규칙:

Industry 파티션 테이블명은 <table>_<industry_type> 패턴을 강제한다.

예: industry_type='academy' → students_academy, industry_type='salon' → students_salon

→ industry_type 값과 partition 이름을 1:1로 맞춰야 하며, 테이블 이름을 제멋대로 짓지 않도록 규칙화


업종별 스키마 분리 도입 기준 (Phase 3+ 전용):

⚠️ 중요: 이 섹션은 Phase 3 (20k+ 테넌트) 이상에서만 검토하는 기능입니다.

MVP/Phase 1-2에서는 industry_type 컬럼 기반 단일 public 테이블을 유지합니다.

📌 Migration Roadmap 참조: 위 "업종별 데이터 분리 전략" 섹션의 단계별 도입 조건을 따릅니다.

Core 테이블(students/invoices)이 200~300GB 이상으로 커지거나 industry_type 교착이 발생하는 경우, 업종별 분리 옵션을 도입할 수 있다.

📌 명시적 전환 기준:

다음 기준 중 하나라도 도달하면 업종별 스키마 분리 검토가 필요합니다:

- students 테이블 단일 파티션 200~300GB 도달
- invoices 테이블 100M rows 이상
- analytics.events 연간 1B rows 이상

근거:
- students/invoices는 코어 테이블로 복잡한 인덱스 구조(tenant_id + industry_type + created_at 등)를 가지므로, 200~300GB 도달 시 인덱스 크기가 수십 GB에 달하여 쿼리 성능 저하가 발생
- analytics.events는 로그성 테이블이지만 연간 1B rows는 월 파티션 기준 약 8천만 rows/월로, 단일 파티션 1억 rows 임계값에 근접
- Industry 간 cross-traffic 영향 최소화를 위한 필수 인덱스 전략

→ 업종 데이터량이 200~300GB 넘어가기 전에는 필요 없으며, "향후 파티셔닝 필요 시 도입 가능" 정도로 축소합니다.

⚠️ 중요: 업종별 스키마 분리(academy.students)와 업종별 테이블 prefix(academy_classes)는 서로 다른 전략이며, 둘 중 하나만 선택합니다. 둘을 동시에 사용하지 않습니다.

- 업종별 스키마 분리: academy.students, salon.customers (스키마 레벨 분리)
- 업종별 prefix 테이블: academy_classes, salon_customers (같은 스키마 내 prefix)

→ 기본은 industry_type 컬럼 기반 단일 테이블이며, 확장 시 파티셔닝 → prefix 테이블 → 스키마 분리 순서로 검토합니다.

5. 대규모 테넌트 확장 전략
5-1. 예상 규모

10,000 학원 × 50명 = 학생 50만

출결 로그: 연 1억 8천만 건

납부 로그: 연 600만 건

5-2. 단계별 확장
단계 1) 기본 멀티테넌트

모든 테이블 tenant_id & 인덱스

RLS 전면 적용

analytics 집계는 외부 런타임(Lambda/Cloudflare Workers) 배치로 처리

단계 2) 파티셔닝 도입 (5천~2만 테넌트 구간)

로그성 테이블 대상:

attendance_logs

activity_logs

payments

전략: 월/연 단위 RANGE 파티셔닝

✅ 기본 권장안(단일 RANGE 파티션) 예시:

CREATE TABLE attendance_logs (
  id bigserial,
  tenant_id uuid,
  ...
  occurred_at timestamptz
) PARTITION BY RANGE (occurred_at);

파티셔닝 도입 기준 (구체적 수치):

로그성 테이블: 월 파티션 권장. 단일 파티션 1억 rows 또는 파티션 파일 크기 ~50GB 도달 시 분할 검토.
- 근거: 로그성 테이블은 시간 기반 조회가 주 패턴이며, 인덱스 크기가 커질수록 성능 저하가 급격히 발생

코어 테이블(students/invoices): 테넌트 수 ≥ 5,000, 총 rows ≥ 5천만 or 테이블 크기 ≥ 200GB 시 industry_type 서브테이블(파티션) 분리 검토.
- 근거: 코어 테이블은 로그성 테이블보다 조회 패턴이 다양하고, tenant_id + industry_type 복합 인덱스로 인해 인덱스 크기가 더 크게 증가

각 파티션에 인덱스:

[불변 규칙] 모든 파티션에는 반드시 (tenant_id, occurred_at DESC) 복합 인덱스가 적용되어야 합니다.

CREATE INDEX ON attendance_logs_2025 (tenant_id, occurred_at DESC);

기본 파티셔닝 예시 (Phase 1-2):

CREATE TABLE attendance_logs (
  id bigserial,
  tenant_id uuid NOT NULL,
  student_id uuid,
  occurred_at timestamptz NOT NULL,
  ...
) PARTITION BY RANGE (occurred_at);

CREATE TABLE attendance_logs_2025
  PARTITION OF attendance_logs
  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');

[불변 규칙] 모든 파티션에는 반드시 (tenant_id, occurred_at DESC) 복합 인덱스가 적용되어야 합니다.

CREATE INDEX ON attendance_logs_2025 (tenant_id, occurred_at DESC);

→ Phase 1-2에서는 단일 RANGE 파티셔닝만 사용합니다.

코어 조회 인덱스 (필수):

CREATE INDEX IF NOT EXISTS idx_students_tenant_created
  ON public.students(tenant_id, created_at DESC);

CREATE INDEX IF NOT EXISTS idx_invoices_tenant_status_due
  ON public.invoices(tenant_id, status, due_date DESC);

Phase 2+ 선택 인덱스 (이름 검색 등 실운영 최적화):

학생 이름 검색이 빈번한 경우 (Phase 2+):
CREATE INDEX IF NOT EXISTS idx_students_name_pattern
  ON public.students USING btree (name text_pattern_ops)
  WHERE tenant_id IS NOT NULL;

→ text_pattern_ops는 LIKE '김%' 같은 패턴 검색에 최적화된 인덱스입니다.
→ Phase 1에서는 필수 아니며, Phase 2에서 실제 검색 성능 문제가 발생할 때 추가합니다.

인덱스 검증 루틴:

월 1회 pg_stat_statements 상위 50개 쿼리 분석 → 인덱스 점검 체크리스트에 반영

Autovacuum 튜닝:

attendance_logs, payments 등 write-heavy 테이블은 autovacuum_vacuum_scale_factor, autovacuum_analyze_scale_factor, freeze_min_age 파라미터를 테이블 단위로 조정해야 한다.

예시:

ALTER TABLE attendance_logs SET (
  autovacuum_vacuum_scale_factor = 0.05,
  autovacuum_analyze_scale_factor = 0.02,
  autovacuum_freeze_min_age = 50000000
);

→ 수백만 row/hour 수준의 write-heavy 테이블에서는 필수 튜닝

5-2-1. 파티션 자동 생성·보존 배치 (Critical)

매월 25일 03:00 KST: 다음 달 파티션 자동 생성

매월 01일 03:10 KST: TTL 지난 파티션 아카이브/드롭

파티션 생성 함수 예시:

CREATE OR REPLACE FUNCTION meta.create_month_partition(_table regclass, _yyyymm text) RETURNS void AS $$
DECLARE
  _from date := to_date(_yyyymm || '01','YYYYMMDD');
  _to   date := (_from + INTERVAL '1 month')::date;
BEGIN
  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %s_%s PARTITION OF %s FOR VALUES FROM (%L) TO (%L);',
    _table::text, to_char(_from,'YYYY_MM'), _table::text, _from, _to
  );
END; $$ LANGUAGE plpgsql SECURITY DEFINER;

스케줄: 외부 런타임(Lambda/Cloudflare Workers)에서 호출 (KST 03:00/03:10)

→ 파티션 관리 자동화는 운영 필수 요소

5-3. RLS 성능 가드레일 및 최적화

실시간 트랜잭션 → RLS 100% 적용

Heavy Analytics / Export → SECURITY DEFINER 또는 Edge Function + Service Role

tenant_id 화이트리스트, audit 로그 필수

제어된 우회 예시:

CREATE OR REPLACE FUNCTION analytics.fn_aggregate_daily(
  _tenant_ids uuid[], _kst_date date
) RETURNS void
LANGUAGE plpgsql SECURITY DEFINER AS $$
BEGIN
  -- tenant_id IN (_tenant_ids) 강제
  -- statement_timeout, row limit 필수
END; $$;


UI 트랜잭션 경로에서는 항상 RLS 적용

모든 우회 쿼리는 audit.events 에 로그 남김

RLS 성능 최적화: 2중 필터링 패턴 (Critical)

문제점: PostgreSQL RLS 정책으로 인해 쿼리 플래너가 인덱스를 최적으로 선택하지 못하는 경우 존재

RLS + Partition 조합 시 예상되는 성능 문제 (Critical):

Partition Pruning이 tenant_id에 의존하지 않음 (시간 기반 파티션 기준)

RLS 조건이 planner에 영향을 줄 수 있음

PostgreSQL 14+에서도 RLS가 planner에 간섭 가능

Partitioned Table에서는 RLS가 Partition Pruning에 영향을 줄 수 있다

→ RLS와 Partition은 완전히 독립적이지 않으며, planner가 최적화를 제대로 수행하지 못할 수 있음

⚠️ 중요: Supabase 환경에서의 추가 고려사항

PgBouncer 트랜잭션 풀링에서는 set_config가 세션 레벨이 아님

일부 Edge Function 환경에선 planner 예측이 낮아질 가능성 있음

📌 권고: Service Layer에서 tenant_id 강제 필터를 lint 규칙으로 만들어라

multi-column index 설계 전략이 명확해야 함

해결책: Service Layer에서 항상 tenant_id 조건을 명시적으로 추가

규칙: 모든 Service Layer 쿼리는 WHERE 절에 tenant_id 조건 필수

→ 이미 문서에 기재되어 있으므로 OK. ESLint 규칙으로 강제하여 개발자가 실수로 tenant_id 조건을 빠뜨리는 것을 방지합니다.

5-3-1. 쿼리 패턴별 권장 인덱스 매트릭스 (Critical)

쿼리 패턴	권장 인덱스	예시
tenant_id + occurred_at (시간 범위)	(tenant_id, occurred_at)	attendance_logs 조회
tenant_id + status + created_at	(tenant_id, status, created_at)	미납 청구서 조회
tenant_id + industry_type	(tenant_id, industry_type)	업종별 학생 조회
tenant_id + email_hash (PII 검색)	(tenant_id, email_hash)	보호자 이메일 검색

인덱스 설계 원칙:

항상 tenant_id를 첫 번째 컬럼으로 포함 (Partition Pruning 최적화)

시간 기반 쿼리는 (tenant_id, occurred_at) 복합 인덱스 필수

RLS 조건과 WHERE 절 조건이 일치하도록 설계

예시:

-- ❌ 잘못된 예 (RLS만 의존)
SELECT * FROM students WHERE name = '김철수';

-- ✅ 올바른 예 (RLS + 명시적 필터)
SELECT * FROM students
WHERE tenant_id = :tenant_id AND name = '김철수';


RLS는 보안 레이어, 필터링은 쿼리 레이어에서 수행하는 "2중 필터링 패턴" 도입

→ 성능 저하 방지에 매우 효과적이며 실무에서 필수적으로 사용하는 방식

RLS + Partition 조합 성능 고려사항:

Partitioned Tables 사용 시, RLS 조건이 Partition Pruning에 영향을 줄 수 있으므로, tenant_id를 Partition Key로 사용하지 않는 구조(=시간 기반 파티션)는 유지하는 것이 옳음.

시간 기반 파티셔닝을 유지하면 RLS 조건과 독립적으로 Partition Pruning이 작동하여 쿼리 플래너가 최적의 플랜을 생성할 수 있다.

5-4. 이중 파티셔닝 (시간 RANGE + tenant HASH) (Phase 3+ 전용, 선택적)

⚠️ 중요: 이 섹션은 Phase 3 (20k+ 테넌트) 이상에서만 검토하는 고급 기능입니다.

MVP/Phase 1-2에서는 단일 RANGE 파티셔닝만으로 충분합니다.

트래픽이 매우 큰 환경에서 선택적으로 도입 가능한 옵션(이중 파티셔닝 예시):

Hot Partition 방지 및 Shard 이행 용이성을 위해 이중 파티셔닝 전략 적용 (Phase 3+ 전용):

⚠️ 중요: 이 섹션은 Phase 3 (20k+ 테넌트) 이상에서만 검토하는 기능입니다.

MVP/Phase 1-2에서는 단일 RANGE 파티셔닝만 사용합니다.

이중 파티셔닝 구조 (참고용 예시):

CREATE TABLE attendance_logs (
  id bigserial,
  tenant_id uuid NOT NULL,
  occurred_at timestamptz NOT NULL
) PARTITION BY RANGE (occurred_at);

CREATE TABLE attendance_logs_2025_01
  PARTITION OF attendance_logs
  FOR VALUES FROM ('2025-01-01') TO ('2025-02-01')
  PARTITION BY HASH (tenant_id);

→ Hot Partition 방지 / Shard 이행 용이.

→ Phase 1-2에서는 단일 RANGE 파티셔닝만 사용하며, Phase 3+에서 이중 파티셔닝을 검토합니다.

→ 실제 2~3만 테넌트 수준에서는 단일 RANGE 파티셔닝만으로 충분하며, 이중 파티셔닝은 수십만 테넌트 규모에서만 검토합니다.

단계 3) Read Replica (조회 트래픽 분리)

리포트/통계/대시보드 조회는 replica로 전송

core-analytics는 replica 기반 heavy query 실행

단계 4) 리전/샤딩 (수십만 테넌트 이상)

AP-Northeast-2(한국), AP-Southeast-1(동남아) 등 분리

테넌트 ID 해시 기반 라우팅

Supabase 클라이언트에서 DB route layer 추가

5-5. Hot Tenant 대응 전략 (Critical)

문제점: 특정 테넌트의 트래픽·청구·출결 폭주 시 전체 DB 성능에 영향

Hot Tenant 자동 감지 지표

tenant별 QPS, CPU, IOPS 비중 모니터링

급증 패턴 탐지: 5분 이동평균 대비 200% 증가 시 경고

Hot Tenant 감지 임계값 (모니터링용):
- 단일 테넌트 QPS가 전체의 10% 초과
- 단일 테넌트 CPU 사용량이 전체의 15% 초과
- 단일 테넌트 IOPS가 전체의 20% 초과

📌 Hot Tenant 샤딩 트리거 기준 (정량화된 수치):

[불변 규칙] 다음 기준 중 3개 이상을 동시에 만족하면 Hot Tenant 샤딩을 검토합니다:

1. 초당 요청 수 (QPS):
   - 단일 테넌트 QPS ≥ 1,000 req/s
   - 또는 단일 테넌트 QPS가 전체의 30% 초과 (7일 이동평균)

2. 월별 Row 증가량:
   - 단일 테넌트 월별 row 증가량 ≥ 1천만 rows/월
   - 또는 단일 테넌트 총 row 수가 전체의 20% 초과

3. 이벤트 Ingestion 속도:
   - 단일 테넌트 이벤트 ingestion 속도 ≥ 10,000 events/min
   - 또는 analytics.events 테이블에서 단일 테넌트 비중 ≥ 25%

4. CPU/IO 부하 기준:
   - 단일 테넌트 CPU 사용량이 전체의 25% 초과 (1시간 이동평균)
   - 단일 테넌트 IOPS가 전체의 30% 초과 (1시간 이동평균)
   - 단일 테넌트 DB 연결 수가 전체의 20% 초과

5. 트래픽 급증 패턴:
   - 5분 이동평균 대비 300% 증가가 3회 이상 발생
   - 또는 일일 트래픽이 전일 대비 200% 증가

⚠️ 중요: 위 기준 중 3개 이상을 동시에 만족하고, Read Replica로 트래픽 분산, 파티셔닝, 업종별 분리 전략으로 해결되지 않는 경우에만 Hot Tenant 샤딩을 검토합니다.

Hot Tenant 수직 샤딩 절차

Step 1: 특정 tenant_id 트래픽을 read replica 또는 전용 replica로 라우팅

Step 2: traffic routing layer에서 해당 테넌트만 별도 DB로 이동 (vertical split)

Step 3: 다른 테넌트 영향 없이 실시간 마이그레이션 수행

5-5-1. Hot Tenant 수직 분리 절차 (Phase 4+ 전용)

⚠️ 중요: 이 섹션은 Phase 4 (수십만 테넌트) 이상에서만 검토하는 초고급 기능입니다.

🚨 현실성 경고: Hot Tenant 수직 샤딩은 기술적으로 매우 복잡한 작업이며, Supabase 단일 프로젝트 철학과 충돌할 수 있습니다.

⚠️ 중요: 확장 로드맵 난이도 재정렬:
- Multi-Region DR은 외부 DB(Aurora/Neon) 기반이면 난이도가 낮아 Phase 3로 이동
- Hot Tenant 샤딩은 CDC 동기화, conflict 해결, routing layer, 영구 분리 정책 등 복잡도가 매우 높아 Phase 4로 이동
- 실제 운영에서는 Multi-Region 구성이 Hot Tenant 샤딩보다 훨씬 단순합니다

실제 난이도:
- CDC 동기화: 복잡도 매우 높음
- 다운타임 없는 이행: 매우 어려움
- Merge back 불가: 영구 분리 정책 유지 필요
- 모니터링 파이프라인: 별도 구축 필요

MVP/Phase 1-2에서는 Read Replica로 트래픽 분산만으로 충분합니다.

CDC 기반 샤딩 자동화는 수십만 테넌트급 기업용 아키텍처에서나 사용하는 방식이며, 실제 2~3만 테넌트 수준에서는 PostgreSQL 파티셔닝 + Read Replica만으로 충분합니다.

Hot Tenant 발생 시 수동 수직 분리 절차 (Phase 3+):

⚠️ 중요: Hot Tenant 샤딩은 "최후의 수단"이며, 다음 순서로 대응을 검토합니다:
1. Read Replica로 트래픽 분산 (우선 시도)
2. 파티셔닝으로 데이터 분리 (다음 단계)
3. 업종별 분리 전략 적용 (업종 단위 분리)
4. Hot Tenant 수직 샤딩 (최후의 수단, 수동 분리만)

수동 수직 분리 절차 (Phase 3+):

Step 1: 특정 tenant_id 데이터를 별도 DB로 수동 마이그레이션
- 다운타임 최소화를 위한 점진적 마이그레이션
- CDC 동기화는 Phase 4+에서만 검토

Step 2: 트래픽 라우팅 레이어에서 해당 테넌트만 별도 DB로 라우팅
- 애플리케이션 레벨에서 tenant_id 기반 라우팅 구현
- Supabase 클라이언트 래퍼 필요

Step 3: 마이그레이션 완료 후 소스 DB에서 해당 tenant_id 데이터 제거
- Merge back 불가 정책 유지
- 영구 분리로 운영

→ 자동화된 CDC 기반 샤딩은 개발 복잡도가 매우 높으므로, Phase 3+에서도 수동 분리 방식을 우선 검토하고, 실제 수십만 테넌트 규모에 도달한 후에만 자동화를 고려합니다.

구현 Phase:

Phase 1-2 (초기, 학원 100~300개 수준): Read Replica로 트래픽 분산만 사용

Phase 3 (20k+ 테넌트): Multi-Region DR 도입 (외부 DB 사용 시, 난이도: 중)

Phase 4 (수십만 테넌트): Hot Tenant 수직 샤딩 도입 (수동 분리, 난이도: 매우 높음)

Phase 4+ (수십만 테넌트): CDC 기반 샤딩 자동화 검토 (선택적, 난이도: 매우 높음)

→ 초기 단계에서는 Over-engineering을 방지하기 위해 Phase 3 이상에서도 수동 방식을 우선 사용합니다.

5-5-2. Hot Tenant 수직 샤딩 원복 전략 (Critical)

수직 샤딩된 테넌트는 원칙적으로 "영구 분리(shard-pinned)" 상태로 유지하며, merge-back은 지원하지 않는다.

정책 근거:

Merge-back 과정에서 데이터 충돌 방지 복잡도가 매우 높음

CDC 동기화 중단 및 정합성 검증 프로세스가 복잡

운영 난이도 극적으로 감소

대안:

트래픽이 진정된 경우에도 독립 샤드에서 계속 운영

샤드 간 부하 분산으로 전체 시스템 안정성 향상

만약 merge-back이 필수인 경우:

CDC 기반 양방향 동기화 필요

정합성 검증 프로세스 필수

데이터 충돌 해결 전략 수립

→ 운영 복잡도를 줄이기 위해 영구 분리 정책 권장

5-5-3. Shard 재조정 전략 (Phase 4+ 전용, 선택적)

⚠️ 중요: 이 섹션은 Phase 4 (수십만 테넌트) 이상에서만 검토하는 초고급 기능입니다.

MVP/Phase 1-3에서는 샤딩 자체가 불필요하므로 이 기능도 불필요합니다.

샤드 간 부하 불균형이 생겼을 때 대응 (Phase 4+):

시나리오:

특정 shard만 과부하되는 경우 (수십만 테넌트 운영 시 발생 가능)

샤드 간 부하 분산을 위한 테넌트 재배치

구현 방식:

수동 마이그레이션 기반 재배치 (우선 권장)

CDC 기반 자동화는 운영 복잡도가 매우 높으므로 실제 필요성이 확인된 후에만 검토

운영 조건:

부하 기반 shard 재조정은 운영 비용이 크므로 월 단위/분기 단위와 같은 제한된 시점에만 실행한다.

→ 수십만 테넌트 이상 규모에서만 검토하는 선택적 기능입니다.

자동 경고 및 라우팅 시스템

Edge → Supabase Routing Layer → fallback replica

모니터링 대시보드에서 Hot Tenant 자동 감지 시 Slack/이메일 알림

라우팅 레이어에서 tenant_id 기반 자동 분산 처리

Hot Tenant 라우팅 레이어는 Edge Middleware 또는 Server Gateway(API Layer)에 구현되며, Supabase의 단일 RLS 모델과 충돌 없이 테넌트 단위 수직 샤딩을 가능하게 한다.

5. Schema Registry 운영 문서 (Critical)

⚠️ 중요: Schema Registry는 수천 테넌트 운영 시 핵심 인프라입니다. 스키마 버전 관리, 충돌 해결, Rollback 정책이 필수입니다.

5-6. Schema Registry 저장 위치 및 관리 방식

저장 방식 옵션:

옵션 1: PostgreSQL 테이블 (권장, Phase 1-2)
- 테이블: `meta.schema_registry`
- 장점: Supabase와 통합, 트랜잭션 보장, RLS 적용 가능
- 단점: Git 연동이 수동

옵션 2: Git-managed JSON 파일 (Phase 2+ 권장)
- 저장 위치: `infra/schemas/{industry_type}/{entity}/{version}.json`
- 장점: 버전 관리 자동화, PR 기반 검토, 롤백 용이
- 단점: Git 연동 필요, CI/CD 파이프라인 구성 필요

옵션 3: S3 + Git 하이브리드 (Phase 3+)
- Git: 스키마 정의 파일 (소스)
- S3: 배포된 스키마 버전 (런타임)
- 장점: 소스 관리와 배포 분리, CDN 캐싱 가능
- 단점: 복잡도 증가

Phase 1-2 권장 구조:

```sql
CREATE SCHEMA IF NOT EXISTS meta;

CREATE TABLE meta.schema_registry (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  entity text NOT NULL,              -- 'student', 'invoice', 'schedule' 등
  industry_type text,                -- 'academy', 'salon' 등 (nullable = 공통)
  version text NOT NULL,             -- '2.0.1'
  min_supported_client text,         -- '1.12.0'
  schema_json jsonb NOT NULL,        -- 실제 스키마 정의
  migration_script text,             -- Migration Script (nullable)
  status text NOT NULL DEFAULT 'draft', -- 'draft', 'active', 'deprecated'
  registered_by uuid REFERENCES auth.users(id),
  registered_at timestamptz NOT NULL DEFAULT now(),
  activated_at timestamptz,          -- 활성화 시점
  deprecated_at timestamptz,         -- 폐기 시점
  UNIQUE(entity, industry_type, version)
);

CREATE INDEX idx_schema_registry_entity ON meta.schema_registry(entity, industry_type, status);
CREATE INDEX idx_schema_registry_version ON meta.schema_registry(entity, industry_type, version DESC);
```

5-7. Schema Registry 등록 시점 Validation

스키마 등록 시 다음 검증을 수행합니다:

1. Meta-Schema Validation
   - 스키마 구조가 Meta-Schema 규칙을 준수하는지 검증
   - 필수 필드: version, minSupportedClient, entity
   - Tailwind 클래스 문자열 사용 금지 검증

2. 버전 충돌 검증
   - 동일 entity + industry_type에서 이미 활성화된 버전과 충돌 여부 확인
   - Major 버전 업그레이드 시 Migration Script 필수

3. 하위 호환성 검증
   - 기존 클라이언트가 새 스키마를 렌더링할 수 있는지 검증
   - Breaking change 감지 시 경고 또는 거부

4. Migration Script 검증 (Major 업그레이드 시)
   - Migration Script 구문 검증
   - 빌드 타임 변환 가능 여부 확인

등록 프로세스:

```typescript
// packages/schema-engine/registry.ts
export async function registerSchema(schema: SchemaDefinition) {
  // 1. Meta-Schema Validation
  const validationResult = validateMetaSchema(schema);
  if (!validationResult.valid) {
    throw new Error(`Meta-Schema validation failed: ${validationResult.errors}`);
  }

  // 2. 버전 충돌 검증
  const existingActive = await getActiveSchema(schema.entity, schema.industry_type);
  if (existingActive && isVersionConflict(existingActive.version, schema.version)) {
    throw new Error(`Version conflict: ${existingActive.version} is still active`);
  }

  // 3. 하위 호환성 검증
  if (existingActive && !isBackwardCompatible(existingActive, schema)) {
    if (!schema.migrationScript) {
      throw new Error('Breaking change requires migration script');
    }
  }

  // 4. 등록 (status = 'draft')
  await db.insert('meta.schema_registry', {
    entity: schema.entity,
    industry_type: schema.industry_type,
    version: schema.version,
    min_supported_client: schema.minSupportedClient,
    schema_json: schema,
    migration_script: schema.migrationScript,
    status: 'draft'
  });
}
```

5-8. Git 연동 (Phase 2+)

Git-managed Schema Registry 구조:

```
infra/schemas/
  ├─ common/                    # 공통 스키마
  │  ├─ invoice/
  │  │  ├─ 1.0.0.json
  │  │  ├─ 2.0.0.json
  │  │  └─ migrations/
  │  │     └─ 1.0.0_to_2.0.0.ts
  │  └─ payment/
  │     └─ 1.0.0.json
  ├─ academy/                   # 업종별 스키마
  │  ├─ student/
  │  │  ├─ 1.0.0.json
  │  │  ├─ 2.0.1.json
  │  │  └─ migrations/
  │  └─ class/
  └─ salon/
     └─ customer/
```

CI/CD 파이프라인:

1. 개발자가 PR 생성 → 스키마 파일 추가/수정
2. CI에서 Meta-Schema Validation 실행
3. PR 머지 시 자동으로 `meta.schema_registry`에 등록 (status = 'draft')
4. 운영자가 Super Admin에서 활성화 (status = 'active')

5-9. Rollback 정책

Rollback 시나리오:

시나리오 1: 새 스키마 버전 배포 실패
- 이전 활성 버전으로 자동 롤백
- `meta.schema_registry`에서 새 버전 status를 'deprecated'로 변경
- 이전 버전을 다시 'active'로 변경

시나리오 2: Migration Script 실행 실패
- 스키마 활성화 전에 Migration Script를 테스트 환경에서 검증
- 실패 시 스키마 등록 자체를 거부

시나리오 3: 클라이언트 호환성 문제
- `min_supported_client` 버전 미만 클라이언트가 존재하는 경우
- 스키마 활성화를 지연하거나 클라이언트 업데이트 유도

Rollback 절차:

```typescript
export async function rollbackSchema(entity: string, industryType: string | null) {
  // 1. 현재 활성 버전 확인
  const active = await getActiveSchema(entity, industryType);
  if (!active) {
    throw new Error('No active schema to rollback');
  }

  // 2. 이전 버전 찾기
  const previous = await getPreviousVersion(entity, industryType, active.version);
  if (!previous) {
    throw new Error('No previous version available');
  }

  // 3. 현재 버전 비활성화
  await db.update('meta.schema_registry',
    { id: active.id },
    { status: 'deprecated', deprecated_at: now() }
  );

  // 4. 이전 버전 활성화
  await db.update('meta.schema_registry',
    { id: previous.id },
    { status: 'active', activated_at: now() }
  );

  // 5. 알림 발송
  await sendAlert('Schema rollback', { entity, industryType, from: active.version, to: previous.version });
}
```

5-10. Version Pinning 정책

테넌트별 스키마 버전 고정:

특정 테넌트가 특정 스키마 버전을 사용해야 하는 경우 (예: 커스텀 위젯 호환성):

```sql
CREATE TABLE meta.tenant_schema_pins (
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  entity text NOT NULL,
  industry_type text,
  pinned_version text NOT NULL,
  reason text,
  pinned_at timestamptz NOT NULL DEFAULT now(),
  pinned_by uuid REFERENCES auth.users(id),
  UNIQUE(tenant_id, entity, industry_type)
);
```

Version Pinning 우선순위:

1. 테넌트별 Pin이 있으면 해당 버전 사용
2. Pin이 없으면 활성화된 최신 버전 사용
3. 클라이언트 `min_supported_client` 미만 버전은 사용 불가

5-11. Conflict Resolution 정책

스키마 버전 충돌 해결:

충돌 유형 1: 동시 등록
- 동일 entity + industry_type + version이 동시에 등록되는 경우
- UNIQUE 제약조건으로 차단
- 먼저 등록된 것이 승인, 나머지는 거부

충돌 유형 2: 활성 버전과의 호환성
- 새 버전이 기존 활성 버전과 호환되지 않는 경우
- Migration Script 필수
- Migration Script 없이는 등록 거부

충돌 유형 3: 클라이언트 지원 범위
- `min_supported_client`가 너무 높아서 기존 클라이언트가 지원하지 않는 경우
- 경고 발송, 활성화는 수동 승인 필요

5-12. 운영 담당자 기준 문서

Super Admin에서 Schema Registry 관리:

1. 스키마 목록 조회
   - entity, industry_type, version, status 필터링
   - 활성/비활성 버전 구분 표시

2. 스키마 활성화/비활성화
   - Draft → Active 전환 시 Migration Script 실행 확인
   - Active → Deprecated 전환 시 영향 범위 확인

3. Rollback 실행
   - 이전 버전 목록 표시
   - Rollback 실행 시 영향 범위 경고

4. 테넌트별 Version Pinning 관리
   - 특정 테넌트의 스키마 버전 고정/해제
   - Pin 이유 기록

5. 충돌 해결
   - 충돌 감지 시 알림
   - 수동 승인/거부 인터페이스

→ Schema Registry는 실 서비스 환경에서 Schema Rollout 실패 시 대응을 위한 핵심 인프라이므로, 위 정책을 반드시 준수해야 합니다.

📘 PART 2
Core Platform / Industry 모듈 / Services / Hooks / core-ui / 반응형 / 모바일·태블릿 / 다크모드 / 확대보기(Zoom)

6. Core Platform Layer 상세 설계

Core Layer는 전 업종 공통 기능을 제공하며, 모든 Industry 모듈의 기반이 된다.

6-1. core-auth / core-tenancy (인증·테넌시)

1) 인증 (Supabase Auth)

[불변 규칙] 인증 로직은 core-auth 모듈에서 공통으로 관리합니다.

패키지 구조:
- packages/core/core-auth/src/login.ts: 로그인 서비스 (이메일/소셜/OTP)
- packages/core/core-auth/src/signup.ts: 회원가입 서비스 (사용자 계정 생성)
- packages/core/core-auth/src/service.ts: 기본 인증 서비스 (사용자 조회 등)

지원 인증 방식:
- 이메일/비밀번호 로그인 (loginWithEmail)
- 소셜 로그인 (Google, Kakao 등) (loginWithOAuth)
- 전화번호·OTP 로그인 (업종에 따라 활성화) (loginWithOTP)

로그인 플로우:
1. 사용자 인증 (Supabase Auth)
2. 사용자의 테넌트 목록 조회 (user_tenant_roles)
3. 테넌트 선택 (JWT claim에 tenant_id 포함)
4. 세션 새로고침 (업데이트된 JWT 받기)

회원가입 플로우:
1. 사용자 계정 생성 (Supabase Auth) - core-auth/signup.ts
2. 이메일 인증 (선택적)
3. 테넌트 생성 및 온보딩 - core-tenancy/onboarding.ts
4. 업종별 초기 데이터 시드 - Industry Layer

2) 테넌트 조인 모델

하나의 유저 → 여러 테넌트 소속 가능
(user_tenant_roles로 매핑)

user_tenant_roles
- user_id
- tenant_id
- role (owner, admin, sub_admin, manager, staff, teacher, assistant, counselor, parent, super_admin)

3) 테넌트 온보딩 (core-tenancy/onboarding.ts)

[불변 규칙] 테넌트 생성 및 초기화는 core-tenancy/onboarding.ts에서 공통으로 관리합니다.

테넌트 생성 플로우:
1. tenants 테이블에 row 생성
2. tenant_settings에 업종별 기본값 저장 (timezone, locale, industry_type)
3. tenant_features에 플랜/기능 ON/OFF 설정
4. owner 유저를 user_tenant_roles에 연결
5. 추천인 코드 처리 (선택적, core-tenancy-referral 연동)
6. 업종별 seed 실행 (Industry Layer에서 별도 처리)

⚠️ 중요: 업종별 초기 데이터 시드(예: 학원 기본 반, 미용실 기본 서비스)는 Industry Layer에서 처리합니다.
core-tenancy/onboarding.ts는 테넌트 생성, 기본 설정, 역할 할당만 담당합니다.

4) RLS 보안 규칙

유저가 소속된 테넌트만 접근 가능

표준 RLS 패턴 템플릿 (3-2 참조):

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, 반드시 JWT claim 기반 RLS를 사용해야 합니다. 아래는 옵션 2 (Session Pooling 또는 전용 커넥션 전용)입니다.

옵션 1: JWT claim 기반 RLS (권장, Transaction Pooling 호환):
CREATE POLICY tenant_isolation_<table> ON public.<table>
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
);

옵션 2: 세션 변수 기반 RLS (Session Pooling 또는 전용 커넥션 전용):
CREATE POLICY tenant_isolation_<table> ON public.<table>
FOR ALL TO authenticated
USING (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
)
WITH CHECK (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
);

→ 모든 RLS 정책은 위 옵션 중 하나를 선택하여 사용해야 합니다. Transaction Pooling을 사용하는 경우 반드시 옵션 1을 사용해야 합니다.

5) Service Layer 및 Hooks

[불변 규칙] Service Layer는 Core Layer를 래핑하여 제공합니다.

패키지 구조:
- packages/services/auth-service: Auth Service (Core Layer 래퍼)
- packages/hooks/use-auth: React Query 기반 인증 관리 Hook

주요 Hook:
- useLoginWithEmail: 이메일/비밀번호 로그인
- useLoginWithOAuth: 소셜 로그인
- useLoginWithOTP: OTP 로그인
- useSelectTenant: 테넌트 선택
- useLogout: 로그아웃
- useSignupWithEmail: 회원가입
- useCreateTenant: 테넌트 생성 및 온보딩
- useUserTenants: 사용자 테넌트 목록 조회

6-2. core-billing / core-metering (과금·사용량 추적)
Billing 공통 규칙

invoices / invoice_items 구조 모든 업종 공통

item_type / category로 업종별 청구항목을 분류

결제는 payments 테이블에서 provider별 통합 처리

Metering(사용량 계측)

출결 건수

문자발송 수

활성 모듈 수

사용자 수

Edge Function에서 수집하여 billing engine이 인보이스 자동 생성.
배치 실행 시각은 매일 04:00 KST 고정.

6-3. core-notification (메시징/알림)

지원 채널:

SMS

카카오 알림톡

이메일

앱 Push (선택)

Edge Function:

fns-notification-dispatch


기능:

템플릿 관리

메시지 큐 처리

재시도 정책

발송 로그 저장

6-4. core-payment (결제/알림뱅킹 Provider)

core-payment는 결제 도메인 공통 스키마/비즈니스 규칙을 제공하고, 실제 결제 API 연동 코드는 /packages/payments/* Provider 모듈에서 구현한다.

Provider 구조:

/packages/payments/
  ├─ payment-alimbank/
  ├─ payment-toss/
  ├─ payment-kg/
  └─ payment-nice/


각 Provider는 다음을 구현:

결제 요청 생성

결과 웹훅 수신 처리

응답 검증(HMAC/Signature)

멱등성 처리

invoice-status 업데이트

Edge Function:

fns-payment-alimbank-request
fns-payment-alimbank-webhook

6-5. core-config (환경설정)

tenant_settings 기반으로 업종별 세팅 제공:

예시:

출결 기준 시간
지각/결석 기준 (분 단위)
기본 청구 주기
UI 테마(light/dark)
기본 로고/브랜딩
기능 on/off


JSON 구성:

{
  "attendance": {
    "late_after": 10,
    "absent_after": 60
  },
  "billing": {
    "cycle": "monthly"
  },
  "ui": {
    "theme": "light",
    "zoom": 100
  }
}

6-6. core-analytics (통계 파이프라인)
데이터 소스

출결 이벤트

결제 이벤트(invoices/payments)

수강신청/예약

로그인 기록

직원 활동

파이프라인 구조
원시 이벤트 테이블 (로그성) — 파티셔닝
↓
외부 런타임(Lambda/Cloudflare Workers) 집계 (매일 04:00 KST, Supabase cron은 트리거만 수행)
↓
analytics.daily_metrics
analytics.monthly_revenue
↓
뷰(Materialized View)
↓
대시보드

6-7. core-party (회원/고객 공통 모델)

⚠️ 중요: 모든 업종에서 회원/고객 개념이 필요하므로 공통 모듈로 구현합니다.

목적

모든 업종의 회원/고객 공통 모델 제공

업종별 사용:
- 학원: 학생(Student)
- 체육관: 회원(Member)
- 미용실: 고객(Customer)
- 부동산: 입주자(Resident)
- 비영리: 후원자(Donor)

데이터 모델

Core Party 테이블 (persons):

CREATE TABLE persons (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  name text NOT NULL,
  email text,
  phone text,
  address text,
  person_type text NOT NULL CHECK (person_type IN ('student', 'customer', 'member', 'resident', 'donor')),
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now()
);

업종별 확장 테이블 패턴:

학원(academy):
CREATE TABLE academy_students (
  person_id uuid PRIMARY KEY REFERENCES persons(id),
  grade text,
  class_name text,
  school_name text,
  ...
);

미용실(salon):
CREATE TABLE salon_customers (
  person_id uuid PRIMARY KEY REFERENCES persons(id),
  hair_type text,
  preferred_style text,
  ...
);

주요 기능

Party CRUD (persons 테이블 기반)

person_type 관리

공통 필드 관리 (name, email, phone, address 등)

업종별 확장 지원

Industry Layer 연동

Industry Layer는 core-party를 확장하여 사용:

```typescript
// Industry Layer에서 사용
import { partyService } from '@core/party/service';
import type { Person } from '@core/party';

// 학원 업종에서 학생 생성 시
const person = await partyService.createPerson(tenantId, {
  name: '홍길동',
  email: 'hong@example.com',
  person_type: 'student',
  ...
});

// 이후 academy_students 테이블에 확장 정보 저장
```

6-8. core-consultation (상담/기록 관리)

목적

모든 업종의 상담/기록 공통 관리

업종별 사용:
- 학원: 상담일지/학습일지
- 체육관: 수련 기록
- 미용실: 시술 기록
- 부동산: 상담 기록

주요 기능

상담/기록 CRUD

첨부 파일 관리 (core-storage 연동)

검색 기능 (core-search 연동)

AI 요약 연동 (향후)

데이터 모델

CREATE TABLE consultations (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  person_id uuid REFERENCES persons(id),
  consultation_type text NOT NULL,
  title text,
  content text NOT NULL,
  consultation_date date NOT NULL,
  created_by uuid REFERENCES auth.users(id),
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now()
);

6-9. core-reviews (리뷰/평가 시스템)

목적

모든 업종의 리뷰/평가 공통 관리

업종별 사용:
- 학원: 학부모 평가
- 체육관: 회원 평가
- 미용실: 고객 리뷰
- 부동산: 입주자 평가

주요 기능

리뷰/평가 CRUD

평점 시스템 (1-5점)

댓글 기능 (core-community와 연동 가능)

사진 첨부 (core-storage 연동)

데이터 모델

CREATE TABLE reviews (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  person_id uuid REFERENCES persons(id),
  rating integer NOT NULL CHECK (rating >= 1 AND rating <= 5),
  title text,
  content text,
  is_visible boolean NOT NULL DEFAULT true,
  created_by uuid REFERENCES auth.users(id),
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now()
);

6-10. core-coupons (쿠폰/할인 관리)

목적

모든 업종의 쿠폰/할인 관리 (고객 대상)

주요 기능

쿠폰 CRUD

할인 적용 로직

쿠폰 사용 내역

쿠폰 유효성 검증

데이터 모델

CREATE TABLE coupons (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  code text NOT NULL,
  name text NOT NULL,
  discount_type text NOT NULL CHECK (discount_type IN ('percentage', 'fixed')),
  discount_value numeric NOT NULL,
  min_purchase_amount numeric,
  max_discount_amount numeric,
  valid_from date NOT NULL,
  valid_until date NOT NULL,
  usage_limit integer,
  usage_count integer NOT NULL DEFAULT 0,
  is_active boolean NOT NULL DEFAULT true,
  created_at timestamptz NOT NULL DEFAULT now()
);

CREATE TABLE coupon_usages (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  coupon_id uuid NOT NULL REFERENCES coupons(id),
  person_id uuid REFERENCES persons(id),
  invoice_id uuid REFERENCES invoices(id),
  used_at timestamptz NOT NULL DEFAULT now()
);

6-11. core-tenancy-referral (B2B 추천인 코드)

⚠️ 중요: SaaS 사용자(테넌트) 간 B2B 추천인 코드 제도입니다.

목적

SaaS 사용자(학원 운영자)가 다른 학원 원장에게 추천하는 B2B 추천인 시스템

특별 요구사항

B2B 추천인 코드 제도 필수 포함

추천인 코드 생성/사용/보상 관리

주요 기능

추천인 코드 생성 (추천인 tenant_id와 연결)

추천인 코드 검증

추천인 코드 사용 추적 (신규 가입자 tenant_id와 연결)

추천인 보상 시스템 (할인/크레딧 등)

추천인 통계 (추천 건수, 성공 건수 등)

데이터 모델

CREATE TABLE referral_codes (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  referrer_tenant_id uuid NOT NULL REFERENCES tenants(id),
  code text NOT NULL UNIQUE,
  reward_type text NOT NULL CHECK (reward_type IN ('discount', 'credit', 'free_trial')),
  reward_value numeric,
  is_active boolean NOT NULL DEFAULT true,
  expires_at timestamptz,
  created_at timestamptz NOT NULL DEFAULT now()
);

CREATE TABLE referral_usages (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  referral_code_id uuid NOT NULL REFERENCES referral_codes(id),
  new_tenant_id uuid NOT NULL REFERENCES tenants(id),
  used_at timestamptz NOT NULL DEFAULT now(),
  reward_applied boolean NOT NULL DEFAULT false,
  reward_applied_at timestamptz
);

보상 지급 로직

신규 테넌트 가입 시 추천인 코드 사용

보상 타입에 따라 할인/크레딧/무료 체험 적용

보상 지급 후 reward_applied 플래그 업데이트

6-12. core-events (이벤트/프로모션)

목적

모든 업종의 이벤트/프로모션 공통 관리

주요 기능

이벤트 CRUD

참여 관리

알림 발송 (core-notification 연동)

통계 집계

데이터 모델

CREATE TABLE events (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  title text NOT NULL,
  description text,
  event_type text NOT NULL,
  start_date date NOT NULL,
  end_date date NOT NULL,
  is_active boolean NOT NULL DEFAULT true,
  created_at timestamptz NOT NULL DEFAULT now()
);

CREATE TABLE event_participants (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  event_id uuid NOT NULL REFERENCES events(id),
  person_id uuid REFERENCES persons(id),
  participated_at timestamptz NOT NULL DEFAULT now()
);

6-13. core-calendar (일정/예약/수업 스케줄)

⚠️ 중요: 자체 구현 권장 (디자인 시스템 통합, 멀티테넌트 특화)

목적

일정/예약/수업 스케줄 공통 도메인

구현 방식

자체 구현 권장:
- 디자인 시스템(@ui-core/react)과 완벽 통합
- 멀티테넌트 특화 기능 구현 용이
- 번들 크기 최적화
- Zero-Trust 아키텍처와의 통합 용이

Phase 1에서는 기본 캘린더 기능만 구현

복잡한 기능은 Phase 2+에서 추가

주요 기능

스케줄/예약 CRUD

반복 일정 관리

정원 관리

담당자 배정

캘린더 뷰 지원 (기본 기능만 Phase 1)

데이터 모델

CREATE TABLE schedules (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  title text NOT NULL,
  description text,
  start_time timestamptz NOT NULL,
  end_time timestamptz NOT NULL,
  repeat_pattern text, -- 'daily', 'weekly', 'monthly', 'none'
  capacity integer,
  assigned_to uuid REFERENCES auth.users(id),
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now()
);

6-14. core-storage (파일 업로드/권한)

목적

파일 업로드/권한/폴더 구조 공통화, Supabase Storage 래핑

주요 기능

파일 업로드/다운로드

권한 관리

폴더 구조 관리

파일 메타데이터 관리

문서 버전 관리 (문서 관리 기능 포함)

구현 방식

Supabase Storage 래핑

테넌트별 폴더 구조: `{tenant_id}/{module}/{file_id}`

RLS 기반 권한 관리

6-15. core-community (게시판/댓글/공지)

⚠️ 중요: 자체 구현 권장 (RLS 기반 테넌트 격리)

목적

공통 게시판/댓글/공지/파일 첨부 스키마 및 API

구현 방식

자체 구현 권장:
- RLS 기반 완벽한 테넌트 격리
- 디자인 시스템 통합
- Zero-Trust 아키텍처 준수
- 커스터마이징 자유도

주요 기능

게시판 CRUD

댓글 기능

공지사항 관리

파일 첨부 (core-storage 연동)

데이터 모델

CREATE TABLE posts (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  title text NOT NULL,
  content text NOT NULL,
  post_type text NOT NULL CHECK (post_type IN ('notice', 'board', 'announcement')),
  is_pinned boolean NOT NULL DEFAULT false,
  created_by uuid REFERENCES auth.users(id),
  created_at timestamptz NOT NULL DEFAULT now(),
  updated_at timestamptz NOT NULL DEFAULT now()
);

CREATE TABLE comments (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL REFERENCES tenants(id),
  post_id uuid NOT NULL REFERENCES posts(id),
  content text NOT NULL,
  created_by uuid REFERENCES auth.users(id),
  created_at timestamptz NOT NULL DEFAULT now()
);

6-16. core-search (Full Text Search)

⚠️ 중요: Phase 1은 PostgreSQL Full Text Search, Phase 2+에서 외부 검색 엔진 검토

목적

Full Text Search 공통 레이어

구현 방식

Phase 1: PostgreSQL Full Text Search
- 추가 인프라 불필요
- RLS와 완벽 통합
- 비용 절감

Phase 2+: 외부 검색 엔진 검토
- Meilisearch, Algolia 등
- 고급 검색 기능 필요 시

주요 기능

검색 인덱싱 (PostgreSQL FTS)

검색 쿼리 처리

검색 결과 정렬

6-17. 외부 라이브러리 vs 자체 구현 정책

⚠️ 중요: Core Layer 모듈 구현 시 외부 라이브러리 사용 정책

원칙

멀티테넌트 격리와 Zero-Trust 아키텍처가 핵심 요구사항

디자인 시스템 통합이 중요

자체 구현 권장 모듈

core-calendar: 기본 기능만 Phase 1에서 자체 구현

core-community: 게시판/댓글은 자체 구현 (RLS 기반 테넌트 격리)

core-search: Phase 1은 PostgreSQL Full Text Search

외부 라이브러리 고려 모듈 (Phase 2+)

고급 캘린더 기능: 필요 시 react-big-calendar 검토

고급 검색: Phase 2+에서 Meilisearch/Algolia 검토

외부 라이브러리 사용 시 고려사항

번들 크기 증가

커스터마이징 제한

디자인 시스템과의 통합 어려움

멀티테넌트 특화 기능 추가 어려움

RLS 정책과의 통합 복잡

7. Industry Layer 설계

Industry Layer는 업종별 비즈니스 로직을 Core 위에서 확장하는 구조이다.

업종별 추가 필드는 PART 1의 4-0 (Profile 확장 전략) 섹션의 Profile 확장 모델(JSON Schema 또는 확장 테이블)에 의해 구현된다.

⚠️ 중요: Industry Layer 구조는 Phase 1 (MVP)부터 적용됩니다.
- 업종별 비즈니스 로직은 `packages/industry/industry-{업종}/`에 구현됩니다.
- Service Layer는 Industry Layer를 래핑하여 제공합니다.
- Core Layer는 Industry Layer를 import하지 않습니다 (단방향 의존성).

7-1. industry-academy (학원)

구조:
```
packages/industry/industry-academy/
├── package.json
├── tsconfig.json
└── src/
    ├── index.ts          # 타입만 export (클라이언트 번들 제외)
    ├── types.ts          # 학원 전용 타입 (Student, Guardian, Consultation 등)
    └── service.ts        # 학원 전용 비즈니스 로직 (서버 전용)
```

Domain

학생(Student)

보호자(Guardian)

반(Class)

수업(Lesson)

출결(Attendance)

청구/수납(Billing)

상담(Consultation)

학습일지(Learning Report)

Billing Mapping Example
교육비
교재비
특별활동비
기타비용

출결 Hook 흐름
출석 체크 → 출결 이벤트 발생 → core-notification → 학부모 알림
→ core-metering → 사용량 기록 → core-billing → 월말 자동청구

Service Layer 연동:
- `@services/student-service`는 `@industry/academy/service`를 래핑하여 제공합니다.
- 클라이언트는 `@services/student-service`를 통해 타입을 import합니다.
- 서버는 `@industry/academy/service`를 직접 사용하거나 `@services/student-service/service`를 사용합니다.

7-2. industry-salon (미용/네일)
Domain

시술 메뉴

예약

고객

멤버십/횟수권

시술 기록

POS 매출

Billing Mapping

시술비

재료비

패키지/회원권

7-3. industry-real-estate (부동산)
Domain

매물

임대/매매 계약

중개 수수료

관리비

입주자 관리

Billing Mapping

중개 수수료

관리비

옵션비

7-4. industry-gym (체육관)
Domain

회원

수련비

도복비

심사비

출결

락커/시설 관리

Billing Mapping

수련비

도복비

심사비

시설 이용료

7-5. industry-ngo (비영리 기관)
Domain

후원자

정기/일시 후원

캠페인

영수증 발행

기부금 영수증

Billing Mapping

정기 후원금

일시 후원금

캠페인 기부금

7-6. Industry 공통 규칙

[불변 규칙] Core Layer는 Industry 모듈에 의존하지 않고, Industry 모듈이 Core를 import하는 단방향 구조(Industry → Core)를 유지한다.

[불변 규칙] Industry Layer는 `packages/industry/industry-{업종}/` 구조로 구현됩니다.

[불변 규칙] Industry Layer의 `index.ts`는 타입만 export하며, 서버 코드는 `/service` 경로에서만 import합니다.

[불변 규칙] Service Layer는 Industry Layer를 래핑하여 제공합니다. 예: `@services/student-service` → `@industry/academy/service`

[불변 규칙] Industry Layer는 Core Party 모델(`core-party`)을 확장하여 사용합니다. 예: `academy_students` 테이블은 `persons` 테이블을 참조합니다.

공통 데이터 스키마(invoices/payments/attendance 등) 사용

업종별 configuration + 템플릿으로 커스터마이징

→ Industry → Core 방향으로 의존하며, Core는 Industry를 모르면 됩니다.

→ Service Layer → Industry Layer → Core Layer 의존성 방향을 유지합니다.

8. Service Layer

React 컴포넌트는 Supabase 쿼리를 직접 실행할 수 없다.
Service Layer가 모든 DB 접근을 캡슐화한다.

⚠️ 중요: Service Layer는 Zero-Trust 아키텍처의 핵심 구성 요소입니다.

8-0. Zero-Trust와 Service Layer 관계 (Critical)

보안 책임 분담 구조:

UI Layer (React 컴포넌트):
- tenant_id를 직접 생성/수정하지 않음
- @api-sdk/core를 통해서만 데이터 요청
- 권한 추론하지 않음

API SDK Layer (@api-sdk/core):
- Context에서 tenant_id, industry_type 자동 가져오기
- 모든 요청에 tenant_id, industry_type, auth token 자동 삽입
- 권한 생성하지 않음
- 에러 처리 및 재시도 정책 관리
- 요청 캐싱 (선택적)
- Edge Function 호출 래핑

Service Layer (@services/*, @industry/*/service):
- tenant_id를 파라미터로 받아서 사용
- withTenant()를 사용하여 쿼리 필터링
- RLS 정책과 함께 2중 필터링 보장
- DB 접근 캡슐화

RLS Layer (PostgreSQL RLS):
- 최종 보안 경계
- JWT claim 기반 tenant_id 필터링
- 권한 결정 및 데이터 격리

보안 흐름:
```
UI → @api-sdk/core (Context에서 tenant_id 가져오기)
  → Service Layer (tenant_id 파라미터로 전달)
  → withTenant() (쿼리 필터링)
  → RLS (최종 보안 검증)
  → DB
```

Service Layer의 보안 책임:
- tenant_id 파라미터 검증 (null/undefined 체크)
- withTenant() 사용 강제 (SELECT/UPDATE/DELETE)
- INSERT 시 tenant_id 직접 포함
- RLS 우회 금지 (Service Role Key 사용 시에도 RLS 정책 준수)

8-1. 규칙

Service만 Supabase 쿼리를 수행

React → Hook → Service 순서

Service는 항상 tenant_id를 강제로 주입

Service는 RLS를 우회하지 않는다

복잡 쿼리는 Edge Function 사용

8-2. 예시 코드
// attendance-service
import { withTenant } from '../_db';

export const attendanceService = {
  async checkIn(tenantId, studentId) {
    // INSERT는 tenant_id를 row object에 직접 포함
    return supabase
      .from('attendance_logs')
      .insert({
        tenant_id: tenantId,
        student_id: studentId,
        occurred_at: new Date()
      });
  },

  async list(tenantId, filters) {
    // SELECT는 반드시 withTenant() 사용
    return withTenant(
      supabase
      .from('attendance_logs')
      .select('*')
        .order('occurred_at', { ascending: false }),
      tenantId
    );
  }
}

8-2-1. 서비스 공통 쿼리 가드 (Critical)

// services/_db.ts
export function withTenant<T>(q: PostgrestFilterBuilder<T>, tenantId: string) {
  return q.eq('tenant_id', tenantId);
}

// 사용 예
return withTenant(
  supabase.from('students').select('*').order('created_at', { ascending: false }),
  tenantId
);

8-2-2. Supabase 커넥션 풀링/쿼리 가드 (Critical)

테넌트/앱 수 증대 시 커넥션 고갈·큐잉 위험 방지:

pgbouncer(세션/트랜잭션 모드) 상정, Edge/Lambda 동시접속 상한치 문서화

서비스 레이어 공통 래퍼에 타임아웃 강제:

가능하면 DB 레벨 기본값으로 설정하고, 필요 시 Edge Function에서 쿼리 직전에 SET LOCAL을 쓰는 형태로 적용한다.

-- 세션 가드 (로그인 직후, 또는 서비스 커넥션 초기화 시)
-- 주의: Supabase PgBouncer 풀링 모드에서는 세션 레벨 SET이 제한될 수 있음
SET statement_timeout = '8s';
SET idle_in_transaction_session_timeout = '3s';
SET lock_timeout = '2s';

실패 시 재시도 정책(지수 백오프)과 결제/웹훅 재처리와의 중복 방지 로직 연결 (14-2-1 참조)

→ 커넥션 풀 관리 및 쿼리 타임아웃은 대규모 운영 필수

8-3. 에러 핸들링 전략 (Critical)

Service Layer 에러 분류:

ValidationError: 입력값 검증 실패 (400 Bad Request)

NotFoundError: 리소스 없음 (404 Not Found)

PermissionError: 권한 없음 (403 Forbidden)

ConflictError: 리소스 충돌 (409 Conflict)

RateLimitError: 요청 한도 초과 (429 Too Many Requests)

InternalError: 서버 내부 오류 (500 Internal Server Error)

에러 응답 표준화:

모든 Service 함수는 표준 에러 객체 반환

클라이언트에는 민감 정보 노출 금지 (예: DB 에러 메시지 숨김)

에러 로깅:

모든 에러는 audit.events에 기록 (InternalError는 즉시 알림)

에러 로그 및 audit.events에는 PII(이름, 전화번호, 이메일 등)를 직접 남기지 않는다.

필요한 경우 식별 가능한 최소 단위(ID, hash, key_version 등)만 기록한다.

PII 최소화 강제 규칙:

audit.events.meta에 PII 금지 룰 추가 (정규식 마스킹 후 삽입)

ESLint/TS Rule: logger.* 호출 시 PII 타입 경고

19-6-1. PII 마스킹 유틸리티 (Critical)

⚠️ 중요: Phase 1에서는 마스킹만으로 충분하며, 모든 PII 마스킹 유틸리티는 중앙 모듈에 정의되어야 합니다.

[불변 규칙] PII 마스킹 유틸리티는 packages/core/pii-utils 또는 packages/core-config/pii-utils에 정의하며, 모든 애플리케이션(academy-admin, academy-parent 등)에서 일관되게 사용합니다.

마스킹 유틸리티 위치:

packages/core/pii-utils/src/index.ts

또는

packages/core-config/pii-utils/src/index.ts

마스킹 유틸리티 정의:

export const maskPhone = (phone: string | null | undefined): string => {
  if (!phone) return '';
  // 010-1234-5678 → 010-****-5678
  return phone.replace(/(\d{3})\d{4}(\d{4})/, '$1****$2');
};

export const maskEmail = (email: string | null | undefined): string => {
  if (!email) return '';
  // user@example.com → u***@example.com
  return email.replace(/(^.).*(@.*$)/, '$1***$2');
};

export const maskName = (name: string | null | undefined): string => {
  if (!name) return '';
  // 홍길동 → 홍*동
  if (name.length <= 2) return name.charAt(0) + '*';
  return name.charAt(0) + '*'.repeat(name.length - 2) + name.charAt(name.length - 1);
};

export const maskPII = (data: any): any => {
  if (typeof data === 'string') {
    // 이메일 마스킹
    data = data.replace(/(^.).*(@.*$)/, '$1***$2');
    // 전화번호 마스킹
    data = data.replace(/(\d{3})\d{4}(\d{4})/, '$1****$2');
  }
  return data;
};

→ 감사 로그의 PII 최소화는 법적 요구사항

재시도 정책:

재시도 가능: NetworkError, TimeoutError, RateLimitError

재시도 불가능: ValidationError, PermissionError, NotFoundError

구현 예시:

export class AppError extends Error {
  constructor(
    public code: string,
    public statusCode: number,
    message: string,
    public isRetryable: boolean = false
  ) {
    super(message);
  }
}

export const handleServiceError = (error: unknown) => {
  if (error instanceof AppError) {
    // 클라이언트용 안전한 메시지
    return { code: error.code, message: error.message };
  }
  // 예상치 못한 에러는 InternalError로 처리
  logger.error('Unexpected error', error);
  return { code: 'INTERNAL_ERROR', message: 'An error occurred' };
};

Supabase PostgREST Error 변환:

Supabase PostgREST error (code, message, details, hint)는 AppError로 변환해 statusCode · isRetryable을 명시적으로 설정해야 한다.

예시:

const mapPostgrestError = (error: PostgrestError): AppError => {
  const code = error.code;
  if (code === '23505') return new AppError('CONFLICT', 409, error.message, false);
  if (code === '23503') return new AppError('NOT_FOUND', 404, error.message, false);
  // ... 기타 에러 코드 매핑
  return new AppError('INTERNAL_ERROR', 500, error.message, false);
};


→ 실무에서 필수적인 에러 처리 전략

8-4. Service vs Edge Key 경계 명문화

Layer	허용 Key	설명
Service Layer	anon/auth	RLS 우회 금지
Edge Functions	Service Role	Webhook·배치·서명 검증용

클라이언트에서 tenant_id 전달값 신뢰 금지

⚠️ Deprecated: Edge Function에서 set_config 사용은 더 이상 권장하지 않습니다.

✅ 대신: JWT claim 기반 RLS를 사용하세요 (PART 1의 3-1-1 섹션 참조)

❌ 금지 예시:
```typescript
// Edge Function에서 set_config 사용 (더 이상 사용하지 않음)
await supabase.rpc('set_config', {
  key: 'app.current_tenant_id',
  value: verified_tenant_id
});
```

✅ 권장 예시:
```typescript
// JWT에 tenant_id를 claim으로 포함하여 RLS 정책에서 자동으로 읽음
const supabase = createClient(url, key, {
  global: {
    headers: {
      'x-tenant-id': verified_tenant_id, // JWT 생성 시 claim에 포함
    },
  },
});
```

9. Hooks Layer (React Query)

각 Service 호출은 Hook으로 래핑되어 UI에서 사용한다.

예:

useAttendanceList
useCheckIn
useInvoices
useNotifications
useTenantSettings


Hook은 다음 기능 제공:

로딩 상태

캐싱

에러 핸들링

refetch 정책

10. core-ui 설계

10-1. 기본 컴포넌트

DataTable, TableCardView, SplitTableLayout 등 기본 컴포넌트는 기존 설계를 따릅니다.

10-2. 지도(Geo) 기반 UI 패턴 (Phase 2+ 전용)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

// packages/ui-core/src/... (예시)
type MapMetricMode =
  | 'store-density'      // 매장 수
  | 'revenue-avg'        // 평균 매출
  | 'members-avg';       // 평균 회원수

interface MapViewProps {
  center?: { lat: number; lng: number };
  zoom?: number;
  metricMode: MapMetricMode;
  // region 단위 히트맵 데이터 (region_code별 값)
  regionMetrics?: Array<{
    regionCode: string;
    value: number;
  }>;
  // 내 매장 위치 표시용
  myStores?: Array<{
    storeId: string;
    lat: number;
    lng: number;
  }>;
}

반응형 레이아웃:

Desktop: 지도 + 우측 KPI 카드/테이블 (Split layout)

Tablet: 지도 상단 / KPI 하단 (vertical split)

Mobile:
- 기본은 KPI 카드 리스트
- 지도는 "지도 보기" 버튼으로 풀스크린 모달로 전환

→ useResponsiveMode()와 함께 레이아웃 패턴을 명시합니다.

지도 데이터 소스:

지도에서 사용하는 색상/히트맵 값은 analytics.daily_region_metrics의 최근 N일 평균 혹은 선택 기간 평균.

매장 위치 마커는 core_stores.latitude/longitude.

// services/analytics-service.ts
export const analyticsService = {
  async getRegionHeatmap(industryType: string, dateKst: string) {
    return supabase
      .from('analytics.daily_region_metrics')
      .select('region_level, region_code, revenue_avg, active_members_avg, store_count')
      .eq('industry_type', industryType)
      .eq('date_kst', dateKst)
      .eq('region_level', 'dong'); // or 'gu_gun', 'si', etc
  },
};
⚠️ 중요: UI/UX 규약(반응형, 다크모드, Zoom, 접근성 등)의 정식 출처는 〈UI/UX Technical Architecture〉 문서입니다.

→ 상세 규칙은 UI/UX 문서의 "6. Responsive UX — Enterprise Version" 섹션을 참조하세요.

주요 컴포넌트 (core-ui 패키지):

DataTable

TableCardView (모바일 전용)

SplitTableLayout (태블릿 전용)

FormField

Drawer / Modal

⚠️ 중요: 모달 사용 규칙 (Critical)

[불변 규칙] 모든 알림/경고/확인 대화상자는 커스텀 모달을 사용해야 합니다.

❌ 금지:
- window.alert()
- window.confirm()
- window.prompt()

✅ 허용:
- useModal().showAlert(message, title?, type?)
- useModal().showConfirm(message, title?)
- 커스텀 Modal 컴포넌트

이유:
1. 일관된 UX: 모든 알림이 동일한 디자인 시스템 사용
2. 접근성: 커스텀 모달은 접근성 개선 가능
3. 모바일 최적화: 모바일에서 네이티브 alert는 부자연스러움
4. 테마 지원: 다크모드, 테넌트 테마 적용 가능
5. i18n 지원: 다국어 메시지 지원

모달 vs 페이지 선택 기준:
- 모달: 간단한 수정 작업, 목록에서 빠른 액션, 확인/알림 메시지, 모바일 환경
- 페이지: 복잡한 작업, 독립적인 작업 흐름, 상세 정보 조회, URL 공유 필요

→ 상세 가이드라인은 `docu/UI_가이드라인_모달_페이지_선택.md` 참조

AppShellLayout

SearchBar

ActionHeader

11. 반응형 UX 전략 (요약)

⚠️ 중요: 반응형 UX 상세 규칙은 〈UI/UX Technical Architecture〉 문서의 "6. Responsive UX — Enterprise Version" 섹션을 참조하세요.

11-0. 반응형 브레이크포인트 표준 (Critical)

⚠️ 중요: 모든 반응형 구현은 다음 Tailwind 표준 브레이크포인트를 사용합니다.

브레이크포인트 수치 (고정 값):

| 브레이크포인트 | 최소 너비 | 용도 |
|--------------|----------|------|
| xs (기본) | 0px | 모바일 (기본) |
| sm | 640px | 큰 모바일 / 작은 태블릿 |
| md | 768px | 태블릿 |
| lg | 1024px | 작은 데스크톱 |
| xl | 1280px | 큰 데스크톱 |

→ 이 브레이크포인트 수치는 디자인팀/프론트엔드팀/백엔드팀 간 일관성을 보장하기 위한 표준입니다.

핵심 원칙:

useResponsiveMode() 훅 사용 필수

기기별 테이블 전략:
- 휴대폰 (xs, sm): TableCardView (행 → 카드)
- 태블릿 (md): compact table or SplitTableLayout
- PC (lg, xl): DataTable (고정 헤더 + 수평 스크롤)

터치 타깃 최소 44px 보장 (확대 125% 이상 시에도 적용)

다크모드 및 UI 확대(Zoom) 지원 필수

→ 상세 규칙은 UI/UX 문서 참조

→ 모바일 UX 성능 및 가독성 보장

11-3. 태블릿 SplitTableLayout

좌측: 테이블/카드 목록
우측: 상세 패널(고정, 최소 폭 ≥ 360px)

키보드/펜 입력 포커스 유지 정책 명시

→ 아이패드/태블릿 UX 최적화

12. 다크모드
ThemeProvider 제공

light/dark 테마 토큰 사용

OS 설정 자동 감지

사용자 override 가능

CSS class 예:

bg-background
text-foreground
border-border
bg-card

13. UI 확대(Zoom)

ZoomContext에서 확대값 제공:

100%

110%

125%

150%

모든 컴포넌트는 px 값 직접 지정 금지
→ 토큰 기반으로 비율 자동 적용

확대 125% 이상 시:

행 높이/아이콘 터치 타깃 44px 보장

텍스트 가독성 유지 (최소 폰트 크기 14px)

→ 접근성 요구사항 준수

📘 PART 3
결제·알림뱅킹 / Public Gateway / Analytics / 배치(04:00 KST) / 통계
14. 결제 & 알림뱅킹 흐름
14-1. payment-alimbank 모듈

효성FMS 알림뱅킹과의 연동은 다음 역할을 수행하는 Provider 모듈에서 담당한다.

결제 요청 Payload 생성

알림뱅킹/PG URL 또는 QR 코드 생성

응답 검증(서명·HMAC 검증)

상태 매핑 (성공/실패/취소)

멱등성 보장(Idempotency Key)

오류/지연에 대한 재시도 정책

14-1-1. 결제/알림뱅킹 Provider Retry Matrix (Critical)

PG사·효성FMS의 API 실패/지연/타임아웃에 대한 표준 Retry 정책:

Failure Type	처리 방식	재시도 횟수	백오프 전략
Timeout	재시도	3회	5초, 15초, 30초 (지수 백오프)
Signature mismatch	즉시 중단	0회	재시도 불가 (보안 위반)
PG internal error (5xx)	재시도	3회	5초, 30초, 120초 (지수 백오프)
Duplicate payment	멱등성 키로 차단	0회	재시도 불가 (이미 처리됨)
Network error (ECONNRESET 등)	재시도	3회	즉시, 5초, 15초
Rate limit (429)	재시도	2회	60초, 120초 (고정 대기)
Invalid request (4xx, 서명 제외)	즉시 중단	0회	재시도 불가 (클라이언트 오류)

구현 예시:

```typescript
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number,
  backoffMs: number[]
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      if (isNonRetryableError(error)) throw error;
      if (i < maxRetries - 1) {
        await sleep(backoffMs[i] || backoffMs[backoffMs.length - 1]);
      }
    }
  }
  throw new Error('Max retries exceeded');
}
```

구조 예시:

// packages/payments/payment-alimbank/index.ts

export const alimbankProvider = {
  async createPaymentRequest(invoice) { ... },
  async verifyWebhookSignature(headers, rawBody) { ... },
  async mapStatus(alimbankStatus) { ... }
}

14-2. Edge Function 연동 (Server Side)
fns-payment-alimbank-request

역할

invoice_id 기반으로 결제 요청 생성

알림뱅킹 API 호출

PG URL/QR 반환

상태 Pending 설정

흐름

클라이언트에서 /pay/:invoice_id 호출

Edge Function에서 invoice 조회 (tenant_id 포함)

alimbankProvider로 결제 요청 생성

요청 성공 시:

payments 테이블 Pending 상태 row 생성

클라이언트로 결제 URL/QR 반환

fns-payment-alimbank-webhook

역할

알림뱅킹/PG에서 보내는 결제 결과 수신

서명 검증 + 멱등성 처리

payments 상태 업데이트

invoices 상태 업데이트

core-notification 트리거

analytics 집계용 이벤트 기록

보안/멱등성 조건

x-signature, x-timestamp, idempotency-key 헤더 필수

타임스탬프는 KST 기준 ±5분 윈도우 안이어야 유효

idempotency-key 단위로 중복 처리 방지

14-2-1. Webhook 멱등성 인덱스 및 재시도 표준화

audit.webhook_events 테이블 정의:

CREATE TABLE audit.webhook_events (
  id bigserial primary key,
  provider text not null,
  idempotency_key text not null,
  status text not null,            -- 'success','failed','retrying' 등
  payload jsonb,
  event_timestamp timestamptz,       -- 웹훅에서 받은 원본 타임스탬프
  received_at timestamptz default now(),  -- 우리 시스템에서 받은 시각
  created_at timestamptz default now()
);

CREATE UNIQUE INDEX IF NOT EXISTS ux_webhook_idem
  ON audit.webhook_events(provider, idempotency_key);

CREATE INDEX idx_webhook_timestamp
  ON audit.webhook_events(provider, event_timestamp);

재시도 백오프 : 5s → 30s → 2m → 10m → 30m (최대 5회)

대시보드 지표 : 실패율 / 멱등충돌률 / 지연 P95

14-2-1-1. 결제/알림뱅킹 운영 정책 (핀테크 수준 필수)

⚠️ 중요: SaaS Billing에서 가장 중요한 "실운영 안정성"을 보장하기 위한 핵심 정책입니다.

1. Webhook Idempotency 강화:

[불변 규칙] 모든 webhook 이벤트는 반드시 idempotency_key 기반 중복 처리 방지를 수행합니다.

중복 이벤트 처리 로직:
```typescript
async function processWebhook(provider: string, idempotencyKey: string, event: WebhookEvent) {
  // 1. 중복 체크 (트랜잭션 내에서)
  const existing = await db.findWebhookEvent(provider, idempotencyKey);
  if (existing && existing.status === 'success') {
    return { status: 'duplicate', event: existing }; // 이미 처리된 이벤트
  }

  // 2. 동시 처리 방지 (SELECT FOR UPDATE)
  const locked = await db.lockWebhookEvent(provider, idempotencyKey);
  if (!locked) {
    throw new Error('Event is being processed by another worker');
  }

  // 3. 이벤트 처리
  try {
    await processPaymentEvent(event);
    await db.updateWebhookEvent(provider, idempotencyKey, 'success');
  } catch (error) {
    await db.updateWebhookEvent(provider, idempotencyKey, 'failed');
    throw error;
  }
}
```

2. Duplicate Event 처리:

[불변 규칙] 동일 idempotency_key로 수신된 이벤트는 첫 번째 이벤트만 처리하고, 이후 이벤트는 무시합니다.

Duplicate 감지 기준:
- idempotency_key 동일
- provider 동일
- event_timestamp 차이 ±5분 이내

Duplicate 처리 정책:
- 첫 번째 이벤트: 정상 처리
- 이후 이벤트: audit.webhook_events에 'duplicate' 상태로 기록, 처리하지 않음

3. Settlement Mismatch Reconciliation (정산 불일치 조정):

[불변 규칙] 결제/알림뱅킹 webhook과 실제 정산 데이터 간 불일치가 발생하면 자동으로 감지하고 수동 조정 UI를 제공합니다.

⚠️ 중요: 정산 불일치 조정 상세 정책은 아래 "5. 회계적 정합성 검증" 및 "6. 수동 조정 UI 요구사항" 섹션을 참조하세요.

정산 불일치 감지:
```sql
-- 일별 정산 불일치 조회
SELECT
  DATE(event_timestamp) as settlement_date,
  provider,
  SUM(CASE WHEN status = 'success' THEN amount ELSE 0 END) as webhook_total,
  (SELECT SUM(amount) FROM settlement_records
   WHERE provider = w.provider AND date = DATE(w.event_timestamp)) as settlement_total,
  ABS(webhook_total - settlement_total) as mismatch_amount
FROM audit.webhook_events w
WHERE event_timestamp >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY DATE(event_timestamp), provider
HAVING ABS(webhook_total - settlement_total) > 0.01; -- 1원 이상 차이
```

자동 조정 정책:
- 불일치 금액 < 1,000원: 자동 조정 (로그 기록)
- 불일치 금액 ≥ 1,000원: 수동 조정 UI에서 승인 필요

4. 결제 실패 자동 재시도:

[불변 규칙] 결제 실패 시 지수 백오프 패턴으로 자동 재시도하며, 최대 재시도 횟수와 재시도 간격을 명확히 정의합니다.

재시도 정책:
- 재시도 횟수: 최대 5회
- 재시도 간격: 5s → 30s → 2m → 10m → 30m
- 재시도 조건: 네트워크 오류, 타임아웃, 일시적 서버 오류만 재시도
- 재시도 제외: 인증 실패, 잔액 부족, 카드 정지 등 영구적 오류는 즉시 실패 처리

재시도 로직:
```typescript
async function retryPayment(paymentId: string, attempt: number = 1) {
  const maxAttempts = 5;
  const backoff = [5000, 30000, 120000, 600000, 1800000]; // ms

  try {
    const result = await processPayment(paymentId);
    return result;
  } catch (error) {
    if (isRetryableError(error) && attempt < maxAttempts) {
      await sleep(backoff[attempt - 1]);
      return retryPayment(paymentId, attempt + 1);
    }
    throw error;
  }
}
```

5. 회계적 정합성 검증 (정산 불일치 조정 정책 통합):

[불변 규칙] 모든 결제/수납/환불 거래는 회계적 정합성을 검증하며, 불일치 시 즉시 알림을 발송합니다.

정합성 검증 항목:
- 입금액 = 출금액 (거래 총합)
- 미정산 금액 = 정산 예정 금액
- 환불 금액 ≤ 원거래 금액
- 중복 결제 없음

검증 주기:
- 실시간 검증: 모든 거래 처리 시
- 일별 검증: 매일 04:00 KST
- 월별 검증: 매월 1일 04:00 KST

정산 불일치 감지 및 조정:
- 위 "3. Settlement Mismatch Reconciliation" 섹션 참조

6. 수동 조정 UI 요구사항:

[불변 규칙] 운영팀이 결제/정산 불일치를 수동으로 조정할 수 있는 UI를 제공합니다.

수동 조정 UI 기능:
- 정산 불일치 목록 조회 (날짜별, 업체별 필터)
- 불일치 상세 내역 확인 (webhook 이벤트 vs 정산 데이터 비교)
- 수동 조정 승인/거부 (승인 시 audit.events에 기록)
- 조정 이력 조회 (누가, 언제, 무엇을 조정했는지)

수동 조정 권한:
- Super Admin만 수동 조정 가능
- 모든 조정 작업은 audit.events에 기록
- 조정 전후 금액 비교 리포트 생성

7. 실시간 모니터링:

[불변 규칙] 결제/알림뱅킹 시스템의 실시간 상태를 모니터링하고, 이상 징후 시 즉시 알림을 발송합니다.

모니터링 지표:
- Webhook 수신 지연률 (P95, P99)
- Webhook 실패율 (5분 이동평균)
- 정산 불일치 건수 (일별)
- 재시도율 (전체 요청 대비)
- 중복 이벤트율

알림 임계값:
- Webhook 실패율 > 5%: 즉시 알림
- 정산 불일치 금액 > 10,000원: 즉시 알림
- 재시도율 > 20%: 경고 알림
- 중복 이벤트율 > 1%: 경고 알림

8. 부분 실패 보정 로직:

[불변 규칙] 결제/알림뱅킹 처리 중 일부 단계만 실패한 경우, 완료된 단계는 롤백하지 않고 부분 성공 상태로 기록하며, 실패한 단계만 재시도합니다.

부분 실패 시나리오:
- Webhook 수신 성공 → DB 저장 실패: Webhook은 재수신 불가하므로 DB 저장만 재시도
- 결제 처리 성공 → 알림 발송 실패: 결제는 유지하고 알림만 재시도
- 정산 기록 성공 → 리포트 생성 실패: 정산은 유지하고 리포트만 재시도

부분 실패 처리 로직:
```typescript
async function processPaymentWithPartialFailure(paymentId: string) {
  const steps = [
    { name: 'webhook_received', fn: () => saveWebhookEvent(paymentId) },
    { name: 'payment_processed', fn: () => processPayment(paymentId) },
    { name: 'notification_sent', fn: () => sendNotification(paymentId) },
    { name: 'settlement_recorded', fn: () => recordSettlement(paymentId) },
  ];

  const completedSteps = [];
  const failedSteps = [];

  for (const step of steps) {
    try {
      await step.fn();
      completedSteps.push(step.name);
    } catch (error) {
      failedSteps.push({ step: step.name, error });
      // 부분 실패 상태로 기록
      await recordPartialFailure(paymentId, completedSteps, failedSteps);
      break; // 실패한 단계에서 중단
    }
  }

  // 실패한 단계만 재시도
  if (failedSteps.length > 0) {
    await retryFailedSteps(paymentId, failedSteps);
  }
}
```

9. 결제 취소 / 재요청 정책:

[불변 규칙] 결제 취소는 원거래와 연결하여 처리하며, 재요청은 멱등성 키를 재사용하여 중복 결제를 방지합니다.

결제 취소 정책:
- 취소 가능 기간: 결제 완료 후 7일 이내 (업체별 정책에 따라 조정)
- 취소 처리: 원거래와 연결하여 환불 처리, audit.events에 취소 사유 기록
- 부분 취소: 지원하지 않음 (전액 취소만 가능)

결제 재요청 정책:
- 재요청 시 동일 idempotency_key 사용: 중복 결제 방지
- 재요청 가능 횟수: 최대 3회
- 재요청 간격: 최소 1분 (스팸 방지)

재요청 로직:
```typescript
async function retryPaymentRequest(paymentId: string, reason: string) {
  const originalPayment = await getPayment(paymentId);

  // 동일 idempotency_key로 재요청
  const retryPayment = await createPayment({
    ...originalPayment,
    idempotency_key: originalPayment.idempotency_key, // 재사용
    retry_count: originalPayment.retry_count + 1,
    retry_reason: reason,
  });

  if (retryPayment.retry_count > 3) {
    throw new Error('Maximum retry count exceeded');
  }

  return retryPayment;
}
```

10. 알림뱅킹 장애 대비 Fallback 처리:

[불변 규칙] 알림뱅킹 서비스 장애 시 자동으로 대체 채널(SMS)로 전환하거나, 장애 복구 후 재시도 큐에 추가합니다.

Fallback 전략:
- 1차: 알림뱅킹 API 호출
- 2차 (장애 시): SMS 발송 (core-notification 모듈)
- 최종 (모든 채널 실패): 재시도 큐에 추가 (최대 24시간 보관)

Fallback 처리 로직:
```typescript
async function sendNotificationWithFallback(userId: string, message: string) {
  const channels = [
    { name: 'alimbank', fn: () => sendAlimbankNotification(userId, message) },
    { name: 'sms', fn: () => sendSMS(userId, message) },
  ];

  for (const channel of channels) {
    try {
      await channel.fn();
      await recordNotificationSuccess(userId, channel.name);
      return { success: true, channel: channel.name };
    } catch (error) {
      await recordNotificationFailure(userId, channel.name, error);
      // 다음 채널로 Fallback
      continue;
    }
  }

  // 모든 채널 실패 시 재시도 큐에 추가
  await addToRetryQueue(userId, message, { maxRetries: 5, ttl: 24 * 60 * 60 * 1000 });
  return { success: false, queued: true };
}
```

장애 감지 기준:
- 알림뱅킹 API 응답 시간 > 5초: 장애로 간주
- 알림뱅킹 API 에러율 > 10% (5분 이동평균): 장애로 간주
- 알림뱅킹 API 5xx 에러: 즉시 Fallback

장애 복구 감지:
- 알림뱅킹 API 정상 응답 3회 연속: 장애 복구로 간주
- Fallback 모드 해제 후 재시도 큐 처리 시작

14-2-2. Webhook 이벤트 순서 보장 (Phase 2+ 선택적)

⚠️ 중요: 이 섹션은 Phase 2 이상에서 선택적으로 도입하는 기능입니다.

MVP/Phase 1에서는 멱등성 처리만으로 충분하며, PG/알림뱅킹에서 순서를 보장할 때 대부분 불필요합니다.

핀테크 프로젝트에서는 Idempotency + Ordering Guarantee(순서 보장) 모두 필요하지만, "학원관리 SaaS에서 알림뱅킹만 지원"하는 경우 멱등성 + 서명 검증만으로 충분합니다.

Ordering Guarantee가 필요한 경우 (Phase 2+):

문제: retry 때문에 success → pending 같은 순서로 도착할 수 있음

해결책:

상태 전이 규칙 정의(State transition machine):

pending → success (허용)

success → pending (거부, late event drop)

success → cancelled (허용)

cancelled → success (거부, late event drop)

timestamp 비교:

event_timestamp가 기존 상태의 event_timestamp보다 이전이면 late event로 간주하여 무시

late event drop 로직:

```typescript
async function processWebhook(provider: string, idempotencyKey: string, event: WebhookEvent) {
  const existing = await db.findWebhookEvent(provider, idempotencyKey);

  if (existing) {
    // 순서 보장 검증 (Phase 2+ 선택적)
    if (event.timestamp < existing.event_timestamp) {
      // late event, 무시
      return { status: 'ignored', reason: 'late_event' };
    }

    // 상태 전이 규칙 검증
    if (!isValidTransition(existing.status, event.status)) {
      return { status: 'rejected', reason: 'invalid_transition' };
    }
  }

  // 처리 진행...
}
```

→ MVP에서는 멱등성 처리만 필수이며, Ordering Guarantee는 Phase 2+에서 실제 필요성이 확인된 후 도입합니다.

14-3. Public Gateway UX

apps/public-gateway/는 로그인 없이 접근 가능한 공개 페이지 집합이다.

주요 시나리오

청구서 조회(링크/QR)

결제 진행

결제 결과 안내

키오스크/데스크용 출결 화면 (숫자패드, QR체크 등)

보안 원칙

Public Gateway 보안 정책은 14-3-1 (Verification Gateway Pattern) 및 19-8 (Public Gateway/키오스크 보안) 섹션을 참조한다.

invoice_id를 URL에 직접 노출하지 않고 서명 토큰 기반으로 식별

signed token 기반 invoice 접근 (Critical)

Public Gateway 접근 시 다음을 반드시 추가:

1) Signed token 기반 invoice 접근

예시: /invoice/:signed_token (친구에게 링크 공유해도 유출 불가)

토큰 스펙 (JWT/HMAC):

알고리즘: HMAC-SHA256

만료 시간: 10분 (KST 기준)

클레임 구조:

{
  "iss": "dearsaas",
  "aud": "public-gateway",
  "sub": "invoice:<uuid>",
  "tenant_id": "<uuid>",
  "scope": ["invoice.read","payment.create"],
  "exp": <unix_KST_plus_600s>,
  "jti": "<random-uuid>"
}

토큰 생성: HMAC-SHA256(invoice_id + tenant_id + timestamp, secret_key)

토큰 검증: Edge Function에서 서명 검증 후 invoice_id 추출

시계 드리프트 허용: ±120s

2) URL 만료 정책

Phase 1: 만료 시간 10분으로 짧게 설정하여 재사용 방지 (만료 시간으로 현실적으로 커버)

Phase 2+: Edge KV / audit.public_tokens 기반 재사용 방지 및 rate-limit 도입

→ Edge KV / audit.public_tokens 기반 재사용 방지와 rate-limit는 Phase 2+에서 도입 가능합니다. MVP에서는 만료시간 짧은 signed token만으로도 리스크를 수용합니다.

14-3-2. Public Gateway Token 회수 정책 (Critical, Phase 2+ 고도화)

⚠️ 중요: 이 섹션의 고급 기능은 Phase 2+에서 도입합니다.

Phase 1: 만료 시간 10분으로 짧게 설정하여 재사용 방지 (만료 시간으로 현실적으로 커버)

Phase 2+: Used Token의 즉시 폐기

사용된 토큰은 DB 또는 KV에 즉시 기록하여 재사용 차단

잠재 중복 공격 패턴 분석:

같은 jti로 짧은 시간 내 다수 요청 시 차단

같은 invoice_id에 대한 토큰 재사용 시도 감지

단일 invoice 조회 시 rate-limit 필요:

같은 invoice_id에 대한 조회는 1분당 최대 10회 제한

IP 기반 rate-limit: 1분당 최대 30회

→ Phase 1에서는 서명 검증 + exp(만료) + jti만 적용하고, 재사용 방지는 짧은 만료 시간(10분)으로 현실적으로 커버합니다.

구현 예시:

```typescript
async function verifyPublicToken(token: string, invoiceId: string) {
  // 1. 토큰 검증
  const payload = await verifyToken(token);

  // 2. 사용 여부 확인
  const used = await kv.get(`token:${payload.jti}`);
  if (used) {
    throw new Error('Token already used');
  }

  // 3. Rate limit 확인
  const rateLimitKey = `rate:invoice:${invoiceId}`;
  const count = await kv.incr(rateLimitKey);
  if (count === 1) {
    await kv.expire(rateLimitKey, 60); // 1분 TTL
  }
  if (count > 10) {
    throw new Error('Rate limit exceeded');
  }

  // 4. 토큰 사용 기록
  await kv.set(`token:${payload.jti}`, 'used', { ex: 600 });

  return payload;
}
```

저장소 정책 (표준):

기본 저장소: Edge KV (Redis 기반) - 빠른 조회, TTL 자동 관리 (권장)

선택 저장소: audit.public_tokens 테이블 - 영구 기록, 감사 추적 필요 시에만 사용

→ 기본은 Edge KV로 통일하고, audit 테이블은 "선택적 + 감사용"으로 사용

audit.public_tokens 테이블 정의 (옵션 2 사용 시):

CREATE TABLE audit.public_tokens (
  id bigserial primary key,
  token_jti text not null,           -- JWT jti 또는 토큰 해시
  tenant_id uuid,
  resource_type text,                  -- 'invoice', 'kiosk', 'qr' 등
  resource_id text,
  used_at timestamptz,
  created_at timestamptz default now(),
  expires_at timestamptz
);

CREATE UNIQUE INDEX IF NOT EXISTS ux_public_tokens_jti
  ON audit.public_tokens(token_jti);

CREATE INDEX IF NOT EXISTS idx_public_tokens_expires
  ON audit.public_tokens(expires_at);

옵션 3: JWT jti 기반 revoke 리스트 - JWT 사용 시

14-3-1. Verification Gateway Pattern (Critical)

모든 Public Gateway 요청은 fns-public-gateway-verify를 통해 서명 검증 후 내부 API로 전달하는 단일 진입점 구조(Verification Gateway Pattern)를 사용한다.

구조:

/invoice/:token → fns-public-gateway-verify → 검증 성공 시 invoice_id 반환 → 내부 API 호출

/kiosk/:token → fns-public-gateway-verify → 검증 성공 시 tenant_id 반환 → 내부 API 호출

/qr/:token → fns-public-gateway-verify → 검증 성공 시 resource_id 반환 → 내부 API 호출


장점:

각 페이지마다 개별 검증 로직을 넣을 필요 없음 (실수 발생 확률 감소)

보안의 "최종 관문"이 단일 지점에 집중

프록시 패턴으로 보안 사고 가능성 크게 감소

주의사항:

Verification Gateway는 Public Gateway의 단일 진입점이므로, 장애 시 전체 Public UX에 영향이 갈 수 있다.

완화 전략:

다중 배포/헬스체크/자동 롤백 전략 필수 적용

읽기 전용 페이지는 CDN으로 바로 제공하고, 토큰 검증이 필요한 엔드포인트만 이 Gateway를 거치도록 구분

RLS 우회 권한:

Verification Gateway는 Public Gateway의 단일 진입점이므로, 토큰 검증 후 내부 API 호출 시 적절한 DB Role을 사용해야 한다.

일반적으로 public_gateway_role 또는 verification_role을 사용하며, 해당 Role은 필요한 테이블(invoices, payments 등)에 대한 최소 권한만 부여한다.

→ Public Gateway 특성상 거의 필수적 아키텍처 패턴이지만, 단일 장애점(SPOF) 완화 전략 필수

CSRF 방어 (POST 요청 시 토큰)

Clickjacking 방지(X-Frame-Options, CSP)

Referrer 최소화(Referrer-Policy: no-referrer)

시간 표시 정책:

상세 KST 표준은 PART 5의 '19-1. 타임존(KST) 표준' 섹션 규칙을 따른다.

청구일, 납부기한, 결제시간 등 Public Gateway에 노출되는 시간은 모두 KST 기준으로 표기한다.

→ 결제/청구 시스템에서 매우 중요한 보안 요소

14-4. 키오스크 모드 (태블릿/모바일)

UI는 core-ui의 KioskLayout 컴포넌트 사용

기능 예:

번호 입력 후 출결 체크

QR/바코드 스캔 (브라우저 카메라 API)

결제용 QR 노출

자동 로그아웃/세션 만료 타이머 (예: 10분 무입력 시 자동 잠금, KST 기준 세션 관리)

15. Analytics & 통계

15-0. Analytics UI 구성 규약 (Critical)

⚠️ 중요: Analytics UI 구성 규약은 디자인팀/프론트엔드팀 간 일관성을 보장하기 위한 표준입니다.

15-0-1. 차트 표준

도넛 차트 (Donut Chart):
- 용도: 비율 표시 (예: 결제 수단 비율, 업종별 분포)
- 색상: Theme Token의 `colors.chart.*` 사용
- 최소 섹션 크기: 3% (3% 미만은 "기타"로 통합)
- 호버 시 툴팁: 값, 비율, 라벨 표시
- 접근성: ARIA label 필수, 키보드 네비게이션 지원

바 차트 (Bar Chart):
- 용도: 비교 표시 (예: 일별 매출, 지역별 비교)
- 색상: Theme Token의 `colors.chart.*` 사용
- 축 레이블: 최대 10자, 초과 시 말줄임표
- 그리드 라인: 연한 회색 (colors.border)
- 호버 시 툴팁: 정확한 값 표시

15-0-2. 색상 토큰 기준

차트 색상은 Theme Token의 `colors.chart.*`를 사용합니다:

```typescript
// packages/design-system/tokens/chart-colors.ts
export const chartColors = {
  primary: 'var(--color-chart-primary)',
  secondary: 'var(--color-chart-secondary)',
  success: 'var(--color-chart-success)',
  warning: 'var(--color-chart-warning)',
  error: 'var(--color-chart-error)',
  info: 'var(--color-chart-info)',
  // ... 추가 색상
};
```

색상 사용 규칙:
- 시리즈가 5개 이하: 각 시리즈마다 고유 색상 할당
- 시리즈가 6개 이상: 색상 순환 사용 (동일 색상 재사용)
- 다크모드: 자동으로 다크모드 색상 토큰 사용
- 접근성: WCAG 2.1 AA 대비율 준수 (4.5:1 이상)

15-0-3. 지도 줌/패닝 UX

지도 줌 레벨 ↔ 지역 레벨 자동 전환:
- 줌 레벨 1-5: 시/도 레벨 (region_level = 'sido')
- 줌 레벨 6-8: 시/군/구 레벨 (region_level = 'sigungu')
- 줌 레벨 9-11: 읍/면/동 레벨 (region_level = 'eupmyeondong')
- 줌 레벨 12+: 법정동 레벨 (region_level = 'beopjeongdong')

→ 상세 매핑 규칙은 "15-6-0-3. 지도 줌 레벨 ↔ 지역 레벨 자동 전환" 섹션 참조

패닝 UX:
- 드래그로 지도 이동
- 이동 시 자동으로 해당 지역 레벨 데이터 로드
- 로딩 중 스켈레톤 UI 표시
- 데이터 로드 실패 시 에러 메시지 표시

15-0-4. KPI 카드 규격

KPI 카드 표준 구조:

```
┌─────────────────────────┐
│ [아이콘] KPI 이름        │
│                         │
│      주요 값            │
│   (큰 폰트, 강조)       │
│                         │
│ 전월 대비: +10% ↑       │
│ (또는 전년 동월 대비)   │
└─────────────────────────┘
```

KPI 카드 규격:
- 최소 너비: 200px (모바일), 250px (태블릿), 300px (데스크톱)
- 최대 너비: 400px
- 패딩: 16px (모바일), 20px (태블릿), 24px (데스크톱)
- 테두리: 1px solid colors.border
- 배경: colors.card
- 호버 효과: 그림자 증가 (elevation 증가)

KPI 카드 레이아웃:
- 그리드: 반응형 그리드 (xs: 1열, sm: 2열, md: 3열, lg: 4열, xl: 5열)
- 간격: 16px (모바일), 20px (태블릿), 24px (데스크톱)

KPI 값 표시 규칙:
- 숫자: 천 단위 콤마 표시 (예: 1,234,567)
- 통화: 원화 기호 표시 (예: ₩1,234,567)
- 비율: 소수점 1자리까지 표시 (예: 12.5%)
- 증감률: 색상으로 구분 (증가: colors.success, 감소: colors.error)
- 증감 아이콘: ↑ (증가), ↓ (감소)

15-0-5. Analytics 대시보드 레이아웃

표준 레이아웃 구조:

```
┌─────────────────────────────────────────┐
│ [KPI 카드 그리드]                        │
│ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐        │
│ │ KPI │ │ KPI │ │ KPI │ │ KPI │        │
│ └─────┘ └─────┘ └─────┘ └─────┘        │
├─────────────────────────────────────────┤
│ [차트 섹션]                              │
│ ┌──────────────────┐ ┌────────────────┐ │
│ │   도넛 차트      │ │   바 차트      │ │
│ └──────────────────┘ └────────────────┘ │
├─────────────────────────────────────────┤
│ [지도 섹션] (선택)                       │
│ ┌─────────────────────────────────────┐ │
│ │         지도 시각화                  │ │
│ └─────────────────────────────────────┘ │
├─────────────────────────────────────────┤
│ [테이블 섹션]                            │
│ ┌─────────────────────────────────────┐ │
│ │         데이터 테이블                │ │
│ └─────────────────────────────────────┘ │
└─────────────────────────────────────────┘
```

반응형 레이아웃:
- 모바일 (xs, sm): 세로 스택 (KPI → 차트 → 지도 → 테이블)
- 태블릿 (md): 2열 그리드 (KPI 그리드, 차트 2열)
- 데스크톱 (lg, xl): 3-4열 그리드 (KPI 그리드, 차트 2-3열, 지도 풀폭)

15-0-6. 데이터 시각화 우선순위

데이터 시각화 우선순위:
1. 숫자 카드 (KPI 카드) - 가장 중요
2. 차트 (도넛/바) - 비교/비율 표시
3. 지도 - 지역 분포 시각화
4. 테이블 - 상세 데이터

→ 모든 Analytics 화면은 위 우선순위를 따릅니다.

15-1. Analytics 파이프라인 설계 원칙 (Critical)

⚠️ 중요: Analytics Layer는 실시간성과 정확성 사이의 트레이드오프를 명확히 정의해야 합니다.

📌 파이프라인 구조:

원시 이벤트 테이블 (로그성) — 파티셔닝
↓
외부 런타임(Lambda/Cloudflare Workers) 집계 (매일 04:00 KST, Supabase cron은 트리거만 수행)
↓
analytics.daily_metrics
analytics.monthly_revenue
↓
뷰(Materialized View)
↓
대시보드

📌 이벤트 스키마 구조:

analytics.events 테이블 구조:
- id: bigserial (전역 유니크)
- tenant_id: uuid (필수, RLS 기반 필터링)
- user_id: uuid (선택적, 사용자 추적용)
- event_type: text (필수, 업종별 이벤트 타입)
- occurred_at: timestamptz (필수, UTC 저장)
- payload: jsonb (업종별 확장 데이터)
- store_id: uuid (Phase 1+, 지역 벤치마킹용)
- region_id: uuid (Phase 1+, 지역 벤치마킹용)
- industry_type: text (Phase 1+, 지역 벤치마킹용)
- event_date_kst: date (Phase 1+, KST 기준 일자)

📌 ETL 규칙:

1. 이벤트 수집 (실시간):
   - Edge Function 또는 서버 코드에서 즉시 analytics.events에 INSERT
   - occurred_at는 UTC로 저장, event_date_kst는 서버 코드에서 toKST()로 계산하여 함께 저장
   - Phase 2+에서는 store_id, region_id, industry_type을 함께 저장

2. 일별 집계 (배치):
   - 매일 04:00 KST에 외부 Worker(Lambda/Cloudflare Workers)가 전날 데이터 집계
   - analytics.events에서 event_date_kst 기준으로 그룹핑하여 analytics.daily_metrics에 upsert
   - 업종별 KPI는 Industry Layer의 Mapper를 사용하여 계산

3. 월별 집계 (배치):
   - 매월 1일 04:00 KST에 전월 데이터 집계
   - analytics.daily_metrics에서 월별 합산하여 analytics.monthly_revenue에 저장

📌 지연 허용 시간(SLA):

- 실시간 이벤트 수집: 즉시 저장 (지연 없음)
- 일별 집계: 매일 04:00 KST 기준, 최대 1시간 지연 허용 (04:00~05:00 KST 완료 목표)
- 월별 집계: 매월 1일 04:00 KST 기준, 최대 2시간 지연 허용 (04:00~06:00 KST 완료 목표)
- 대시보드 조회: 집계 완료된 데이터만 표시 (최신 데이터는 "집계 중" 표시)

📌 실시간 vs 배치 분리 기준:

실시간 처리 (Edge Function):
- 이벤트 수집: analytics.events에 즉시 INSERT
- 단일 테넌트 조회: 최신 이벤트 조회 (analytics.events 직접 조회)
- 실시간 알림: 이벤트 발생 즉시 처리

배치 처리 (외부 Worker):
- 일별/월별 집계: 대량 데이터 집계는 외부 Worker에서 수행
- 통계/리포트 생성: heavy query는 배치로 처리
- 백필(Backfill): 과거 데이터 재집계는 배치로 처리

📌 인덱스 설계:

필수 인덱스:
- (tenant_id, occurred_at DESC): 테넌트별 최신 이벤트 조회
- (tenant_id, store_id, occurred_at DESC): Phase 1+, 매장별 이벤트 조회
- (industry_type, region_id, event_date_kst): Phase 1+, 지역별 집계
- (event_date_kst, industry_type, region_id): Phase 1+, 날짜 기준 집계

→ 모든 인덱스는 파티션별로 생성되며, 파티션 삭제 시 인덱스도 함께 삭제됩니다.

15-0-7. 지역 통계 활성화 최소 요구 조건 (Phase 1 시작 전 반드시 구축)

⚠️ Critical: 지역 통계 기능이 작동하려면 반드시 다음 3가지 인프라가 구성되어 있어야 합니다.

1. core_regions 테이블 (지역 마스터 데이터)

- 행정안전부 행정구역 코드 기반 지역 계층 구조
- 초기 데이터 구성: 행정구역 마스터 데이터를 migration으로 로드
- 예: 전국 동/읍/면, 구/군, 시/도 데이터 (약 5천~6천 row)

2. core_stores.region_id (매장 ↔ 지역 매핑)

- 매장 등록 시 주소 → 좌표 → 법정동 코드 변환 (Kakao Reverse Geocoding 사용)
- region_id를 core_stores에 저장하여 지역 매핑 완료
- 좌표(lat/lng)와 region_id를 함께 저장

3. analytics.events.region_id & event_date_kst (이벤트 지역 정보)

- 이벤트 저장 시 반드시 UTC → KST 변환을 수행하고 event_date_kst에 저장
- store_id → region_id 조회하여 events에 함께 저장
- 집계 시에는 event_date_kst를 그대로 사용하며 추가 변환을 수행하지 않음

⚠️ 중요: KST 변환은 이벤트 저장 시점(Edge Function/서버 코드)에서 처리하여 events에 event_date_kst를 함께 기록합니다.

집계 단계에서 다시 변환하는 것은 금지합니다.

이유:
- 출결/결제 이벤트가 분/초 단위로 세밀하여, 집계 시 변환하면 날짜경계 오류 위험
- 시간대가 하루에도 변하지 않도록 이벤트 입력 시점에서 고정해야 일관성 유지

15-0-8. 지역 기반 벤치마킹 플랫폼 설계 원칙 (Critical)

⚠️ 중요: 기본 기능은 Phase 1 (MVP)에 포함되며, 고급 기능은 Phase 2+에서 도입합니다.

Phase 1 (MVP) 기본 기능:
- 지역순위 (학생 수, 매출, 출석률 기준)
- 지역 평균 대비 비교 차트
- 행정동 기준 기본 히트맵
- 기본 AI 인사이트 (3종)

Phase 2+ 고급 기능:
- 고급 히트맵 (다중 지표, 시계열)
- 다중 지역 비교
- AI 인사이트 고도화
- 지도 기반 매장 분포 시각화 (고급)

15-0-9. 설계 철학

지역 기반 벤치마킹 플랫폼:

각 매장은 자신의 데이터를 보는 것에 그치지 않고, 같은 업종 + 같은 지역(동/읍/면, 구/군, 시/도, 전국) 기준의 평균/상위권과 비교한다.

예:
- "우리 학원 매출이 이 구 전체 학원 평균의 120%"
- "원생 수가 동 단위 기준 상위 25%"

지도 기반 분포 + 지역 통계:

"지도 위에 매장 분포 & 지역별 평균 KPI(색상/히트맵)"를 올려서 시장 포화도, 성장 구역, 매출 센터 등을 시각화.

멀티테넌트 보안 + 익명화:

다른 매장의 raw 데이터는 절대 노출 안 됨.

매장이 볼 수 있는 것은:
- 자기 매장 raw KPI
- 지역·업종별로 집계·익명 처리된 통계 값(평균, 중앙값, 분위수, 매장 수)

→ 이 세 가지 원칙이 모든 Analytics 설계의 기반이 됩니다.

15-8. 이벤트 소스 정의

이벤트 타입 예시:

attendance.check_in

attendance.check_out

invoice.created

payment.completed

payment.failed

class.subscription

login.success

login.failed

feature.used

각 이벤트는 공통 필드 포함:

tenant_id

user_id (가능 시)

occurred_at (UTC 저장, 표현은 KST)

payload (jsonb)

15-2. 이벤트 테이블 & 파티셔닝

원시 이벤트 (Phase 1 기본 구조):

CREATE TABLE analytics.events (
  id bigserial primary key,
  tenant_id uuid not null,
  user_id uuid,
  event_type text not null,
  occurred_at timestamptz not null,
  payload jsonb
) PARTITION BY RANGE (occurred_at);

파티션(예: 연 단위 혹은 월 단위):

CREATE TABLE analytics.events_2025
  PARTITION OF analytics.events
  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');

CREATE INDEX ON analytics.events_2025 (tenant_id, occurred_at DESC);

15-2-1. 이벤트 테이블 확장 (지역 벤치마킹용)

⚠️ 중요: 기본 지역 통계는 Phase 1 (MVP)에 포함되며, 이 컬럼들은 Phase 1에서 필수입니다.

지역 벤치마킹을 위해 analytics.events에 다음 필드를 추가합니다:

ALTER TABLE analytics.events
  ADD COLUMN store_id uuid REFERENCES core_stores(id),
  ADD COLUMN region_id uuid REFERENCES core_regions(id),  -- core_stores.region_id 복사
  ADD COLUMN industry_type text NOT NULL DEFAULT 'academy',  -- core_stores.industry_type 복사
  ADD COLUMN event_date_kst date;  -- KST 기준 일자 (toKST()로 파생)

⚠️ 중요: Phase 1 (MVP)에서 지역 통계 기능을 사용하므로 이 컬럼들은 Phase 1에서 필수입니다.

→ store_id, region_id, industry_type, event_date_kst는 Phase 1부터 필수입니다.

CREATE INDEX ON analytics.events_2025 (tenant_id, store_id, occurred_at DESC);
CREATE INDEX ON analytics.events_2025 (industry_type, region_id, event_date_kst);
CREATE INDEX ON analytics.events_2025 (event_date_kst, industry_type, region_id);

→ region_id + industry_type를 넣어두면 나중에 "동/구/시/전국 × 업종별 집계"가 쉬워집니다.

→ event_type은 업종별 매핑 설계를 Industry Layer 문서에 따로 정의합니다.

이벤트 타입 예시 (업종별):

학원(academy):
- tuition_paid (수강료 납부)
- lesson_attended (수업 출석)
- student_enrolled (원생 등록)
- student_dropped (원생 이탈)

부동산(real_estate):
- contract_closed (계약 체결)
- listing_created (매물 등록)
- viewing_scheduled (방문 예약)

미용/네일(salon):
- service_completed (시술 완료)
- appointment_booked (예약)
- membership_purchased (회원권 구매)

→ 각 이벤트는 공통 필드(tenant_id, store_id, region_id, industry_type, event_date_kst) + 업종별 payload(jsonb)를 포함합니다.

15-3. 일/월 집계 테이블

15-3-1. 테넌트 단위 일/월 집계 (Phase 1 기본)

CREATE TABLE analytics.daily_metrics (
  tenant_id uuid,
  date date,                -- KST 기준 날짜
  total_revenue numeric,
  total_attendance int,
  no_show_count int,
  new_students int,
  primary key (tenant_id, date)
);

CREATE TABLE analytics.monthly_revenue (
  tenant_id uuid,
  year int,
  month int,                -- KST 기준 월
  revenue numeric,
  primary key (tenant_id, year, month)
);

15-3-2. 매장 단위 일별 KPI (지역 벤치마킹용)

⚠️ 중요: 이 섹션은 Phase 1 (MVP)에 포함되는 기본 기능입니다.

CREATE TABLE analytics.daily_store_metrics (
  tenant_id          uuid NOT NULL,
  store_id           uuid NOT NULL REFERENCES core_stores(id),
  region_id          uuid NOT NULL REFERENCES core_regions(id),
  industry_type      text NOT NULL,
  date_kst           date NOT NULL,

  -- 공통 Core KPI (모든 업종 공통)
  revenue_total      numeric(18,2) NOT NULL DEFAULT 0,
  revenue_refund     numeric(18,2) NOT NULL DEFAULT 0,
  active_members     integer       NOT NULL DEFAULT 0,
  new_members        integer       NOT NULL DEFAULT 0,
  churned_members    integer       NOT NULL DEFAULT 0,
  visit_count        integer       NOT NULL DEFAULT 0,

  -- 업종별 확장 KPI (nullable, Industry Layer에서 채움)
  lesson_count       integer       NULL,   -- 학원: 수업 수
  class_fill_rate    numeric(5,2) NULL,   -- 학원: 반 정원 대비 채움률
  contract_count     integer       NULL,   -- 부동산: 체결 계약 수
  listing_count      integer       NULL,   -- 부동산: 등록 매물 수
  attendance_count   integer       NULL,   -- 체육관: 출석 횟수

  created_at         timestamptz NOT NULL DEFAULT now(),
  PRIMARY KEY (tenant_id, store_id, date_kst)
);

CREATE INDEX idx_daily_store_metrics_region ON analytics.daily_store_metrics(industry_type, region_id, date_kst);
CREATE INDEX idx_daily_store_metrics_tenant ON analytics.daily_store_metrics(tenant_id, date_kst);

→ analytics.daily_store_metrics는 RLS + tenant_id 필터가 적용되는 "자기 매장 전용 KPI" 테이블입니다.

15-3-3. 지역 단위 집계 KPI (지역 벤치마킹용)

⚠️ 중요: 기본 지역 집계는 Phase 1 (MVP)에 포함되며, 고급 집계 기능은 Phase 2+에서 도입합니다.

"동·구·시·전국 단위 평균/분포"를 저장하는 테이블:

CREATE TABLE analytics.daily_region_metrics (
  industry_type      text NOT NULL,         -- 'academy', 'real_estate', ...
  region_level       text NOT NULL CHECK (region_level IN ('dong', 'gu_gun', 'si', 'nation')),
  region_code        text NOT NULL,         -- core_regions.code
  date_kst           date NOT NULL,

  store_count        integer NOT NULL,      -- 해당 지역/업종의 매장 수

  -- 공통 KPI의 통계 값들
  revenue_avg        numeric(18,2) NOT NULL,
  revenue_median     numeric(18,2) NOT NULL,
  revenue_p25        numeric(18,2) NOT NULL,
  revenue_p75        numeric(18,2) NOT NULL,

  active_members_avg    numeric(18,2) NOT NULL,
  active_members_median numeric(18,2) NOT NULL,
  active_members_p25    numeric(18,2) NOT NULL,
  active_members_p75    numeric(18,2) NOT NULL,

  -- 필요 시 업종별 KPI 요약
  lesson_count_avg      numeric(18,2) NULL,
  contract_count_avg    numeric(18,2) NULL,

  created_at         timestamptz NOT NULL DEFAULT now(),
  PRIMARY KEY (industry_type, region_level, region_code, date_kst)
);

15-3-3-1. KPI별 지역 레벨 지원 정책

⚠️ 중요: 모든 KPI가 모든 지역 레벨을 지원하는 것은 아닙니다. KPI별로 적합한 지역 레벨을 제공합니다.

KPI	지역 레벨	비고

revenue_total	dong / gu_gun / si / nation	기본 제공 (모든 레벨)

active_members	dong / gu_gun / si	nation 레벨은 선택적 (의미 희석)

visit_count	dong / gu_gun	si/nation은 노이즈 증가

lesson_count (학원)	dong / gu_gun	학원 중심, 상위 레벨로 갈수록 왜곡 커짐

class_fill_rate (학원)	dong / gu_gun	동/구 단위가 가장 정확

contract_count (부동산)	gu_gun / si	dong은 노이즈↑, 구/시 단위가 적합

listing_count (부동산)	gu_gun / si	dong 단위는 데이터 부족 가능

→ 지역 단위별 정합성을 보장하려면 KPI마다 제공 레벨을 구분해야 합니다.

→ 집계 배치에서 KPI별로 적합한 region_level만 계산하여 저장합니다.

CREATE INDEX idx_daily_region_metrics_date ON analytics.daily_region_metrics(date_kst, industry_type, region_level);

→ 이 테이블은 멀티테넌트 공용이지만, 개별 매장 정보는 모두 익명화된 통계만 남습니다.

→ 테넌트가 조회할 때는 항상: 본인 store의 industry_type / region_code / region_level로 필터 → 자기 그룹의 통계만 봅니다.

→ analytics.daily_region_metrics는 집계·익명화된 region-level 통계 테이블이라, 일반 매장 사용자는 "자기 업종 + 자기 지역의 통계만" 볼 수 있고, Super Admin은 모든 region을 조회할 수 있습니다.

15-3-3-2. 익명화(Privacy) 보안 정책 (반드시 적용)

⚠️ Critical: 지역 통계는 다음 조건을 만족할 때만 사용자에게 제공합니다.

store_count ≥ 3 (해당 industry_type + region_level + region_code 조합)

조건 미충족 시:

평균만 노출하거나

"해당 지역의 통계는 매장 수 부족으로 제공되지 않습니다" 출력

// 서비스 레이어 예시
export async function getRegionMetrics(industryType: string, regionLevel: string, regionCode: string, dateKst: string) {
  const metrics = await supabase
    .from('analytics.daily_region_metrics')
    .select('*')
    .eq('industry_type', industryType)
    .eq('region_level', regionLevel)
    .eq('region_code', regionCode)
    .eq('date_kst', dateKst)
    .single();

  if (!metrics || metrics.store_count < 3) {
    return {
      error: 'INSUFFICIENT_SAMPLE',
      message: '해당 지역의 통계는 매장 수 부족으로 제공되지 않습니다.',
    };
  }

  return metrics;
}

→ 법/보안 기준 필수 항목입니다. 개별 매장의 민감 KPI 노출을 방지합니다.


중요

date/year/month는 모두 KST 기준으로 계산

저장 시 내부적으로는 UTC → KST 변환 후 date 추출

analytics 집계 시 KST 기준 date/year/month 계산은 외부 런타임(Lambda/Cloudflare Workers)에서 수행하며, DB 내부 쿼리는 UTC로 작동한다.

15-4. Edge Function vs 배치 작업 구분 (Critical)

⚠️ 중요: 출결-수납-정산 시스템 특성상 대량 알림 발송, 월말 정산 집계, 통계/리포트 생성은 Edge Function에서 synchronous로 처리하기엔 위험합니다.

[불변 규칙] 실시간 요청 처리용 Edge Function과 스케줄 배치용 작업을 명확히 구분합니다.

실시간 요청 처리용 Edge Function:
- 짧은 요청/응답 (Timeout 제한 내)
- Webhook 검증
- Public Gateway 검증
- 간단한 단일 테넌트 조회/수정

스케줄 배치용 작업:
- 대량 알림 발송
- 월말 정산 집계
- 통계/리포트 생성
- Supabase cron + queue/작업 테이블 패턴 사용

배치 작업 패턴:

옵션 1: Supabase cron + 작업 테이블 (Phase 1)

CREATE TABLE batch_jobs (
  id uuid PRIMARY KEY,
  job_type text NOT NULL,
  status text NOT NULL DEFAULT 'pending',
  tenant_id uuid,
  params jsonb,
  created_at timestamptz NOT NULL DEFAULT now(),
  started_at timestamptz,
  completed_at timestamptz,
  error_message text
);

-- Supabase cron이 작업 테이블을 주기적으로 확인
-- pending 작업을 찾아서 Edge Function으로 트리거
-- Edge Function은 작업을 큐에 넣고 즉시 반환
-- 실제 처리는 외부 Worker에서 수행

옵션 2: Supabase cron → 외부 Worker (Phase 2+ 권장)

Supabase cron → 트리거 역할만 수행 (webhook 호출)

외부 Worker (Lambda/Cloudflare Workers)에서 실제 집계 수행

→ Phase 1에서는 옵션 1, Phase 2+에서는 옵션 2를 사용합니다.

15-4-1. 집계 배치 작업 (Phase 2+ 전용)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

MVP/Phase 1에서는 Supabase Edge Function + 간단한 집계만으로 충분합니다.

중요: Analytics 집계는 Phase 2+부터는 Supabase Edge Function이 아닌 외부 런타임(AWS Lambda/Cloudflare Workers)을 사용하는 것을 권장합니다.

Supabase Edge Functions는 timeout 구조 때문에 대규모 Analytics에 부적합하므로, Phase 2+에서는 Lambda/Workers를 사용해야 합니다.

→ MVP에서는 간단한 집계만 Supabase Edge Function으로 처리하고, 데이터량이 증가하면 외부 런타임으로 전환합니다.

15-4-0. Analytics Worker 전환 기준 (Critical)

⚠️ 중요: 다음 기준 중 하나라도 도달하면 반드시 Lambda/Workers로 전환해야 합니다.

전환 기준:
- 이벤트 월 500~700만건 돌파
- analytics.events 테이블 100M rows 도달
- Edge Cron timeout 발생률 증가 (집계 작업 실패율 5% 이상)

→ 이 시점에서 반드시 Lambda/Worker 전환해야 하며, 전환 지연 시 데이터 누락 및 성능 저하가 발생할 수 있습니다.

15-4-3. Supabase Edge Function 제약사항 상세 (Critical)

Supabase Edge Functions는 다음 제약사항이 있어 장시간/대규모 작업에 부적합:

**Timeout 제한 (예시 값, 문서 작성 시점 기준):**

⚠️ **아래 수치는 예시이며, 실제 값은 Supabase 공식 문서 재확인 필요**

- HTTP Function: **5초 기본, 최대 15초까지 설정 가능** (예시)
- Scheduled cron: **기본 동일 15초** (예시)
- 외부 HTTP 호출 포함 시 더 짧아짐

⚠️ 중요: 이 값은 Supabase 정책에 따라 변동될 수 있으므로 항상 최신 공식 문서 기준으로 다시 확인해야 합니다.

→ Edge Cron에서 대규모 집계는 절대 불가능하며 External Worker 필수

Cold Start 영향:

첫 요청 시 런타임 초기화로 인한 지연 발생

50MB payload 제한:

요청/응답 크기가 50MB를 초과할 수 없음

Output streaming 미지원:

대용량 데이터 스트리밍 불가능

→ 수천만 row 대상 작업은 절대 Edge에서 불가능하며, 반드시 외부 런타임(Lambda/Workers) 사용

Supabase Edge Functions = Real-time API/Webhook 용도

Batch/Analytics = AWS Lambda or Cloudflare Workers 필수

구조:

Supabase cron → 트리거 역할만 수행 (webhook 호출)

외부 서비스 → 실제 집계 작업 수행

스케줄

매일 04:00 KST에 실행
(Supabase cron 설정 시 UTC 기준으로 환산하여 등록하되, 문서와 설정 주석에는 명시적으로 KST 04:00 기재)

동작

어제 날짜(기준: KST)를 계산

해당 날짜의 이벤트를 analytics.events에서 조회

테넌트별 매출/출석/미납 등 집계

analytics.daily_metrics에 upsert

필요 시 monthly_revenue를 같이 업데이트

15-4-4. 배치 작업 리스크 대응 (Critical)

문제점: Supabase Edge Functions는 "장시간 실행"에 적합하지 않음. 대규모 이벤트 집계 시 시간 초과 가능

⚠️ 중요: Supabase Edge Functions는 Timeout 제한으로 인해 장시간 배치 작업에 부적합합니다.

→ Edge Functions는 장시간 Batch에 부적합하므로 Lambda/Workers 필수입니다.

→ 상세 Timeout 제약사항은 15-4-3 "Supabase Edge Function 제약사항 상세" 섹션 참조

제한사항:

Timeout 제한으로 인해 대규모 데이터 처리 불가능

복잡한 집계 쿼리 실행 시 타임아웃 발생 가능

해결책: 04:00 KST 집계 배치를 외부 서비스로 분리

옵션 1: Cloudflare Workers (권장)

장점: 긴 실행 시간 지원, 자동 스케일링

옵션 2: AWS Lambda / GCP Cloud Run

장점: 더 긴 타임아웃, 메모리 조정 가능

구조:

Supabase cron → 트리거 역할만 수행 (webhook 호출)

외부 서비스 → 실제 집계 작업 수행

예시 흐름:

[Supabase Cron 04:00 KST]
  ↓
[Webhook 호출] → Cloudflare Workers / Lambda
  ↓
[대규모 이벤트 집계] (수백~수천만 건 처리)
  ↓
[결과를 Supabase에 upsert]


→ 수백~수천만 건 이벤트 집계 시 필수적입니다.

15-4-2. 배치 실패 시 Backfill 스크립트 (Phase 2+ 전용, Analytics 고도화 시 도입)

⚠️ 중요: Backfill 절차 및 정합성 검증 상세 정책은 15-4-2-1 "Analytics Pipeline Backfill 정합성 검증" 섹션을 참조하세요.

문제점: 배치 작업 실패 시 누락된 기간의 데이터를 수동으로 재처리해야 함

해결책: Backfill 스크립트 제공

기능:

특정 날짜 범위의 집계 데이터 재생성

실패한 배치 작업 자동 재시도

수동 Backfill 실행 인터페이스 제공

부분 기간 재집계 idempotent 보장:

지표 중복 합산 금지 (멱등성 키 기반)

테넌트 단위 제한:

모든 analytics 집계 함수는 _tenant_ids 배열 파라미터를 받는 버전과, all-tenants용 내부 전용 버전을 명확히 구분한다.

공개된 Analytics 함수는 항상 _tenant_ids 파라미터를 받도록 하고, 전체 테넌트 대상 집계는 운영자 전용 백필 스크립트에서만 호출한다.

→ 멀티테넌트 환경에서 실수로 "전체 테넌트 풀스캔" 쿼리가 나가는 상황을 차단하는 가드레일

→ 모든 analytics 집계 쿼리는 tenant_id 기반 필터링을 필수로 적용하며, 전체 테넌트 대상 쿼리는 운영자 전용 함수에서만 허용

15-5. 멀티테넌트/RLS & 익명화 전략

⚠️ 중요: 기본 RLS 및 익명화는 Phase 1 (MVP)에 포함되며, 고급 익명화 전략은 Phase 2+에서 도입합니다.

15-5-1. 매장 데이터 보호 (RLS)

매장 자신 데이터는 analytics.daily_store_metrics에서 tenant_id + store_id + RLS로 보호합니다.

CREATE POLICY tenant_isolation_daily_store_metrics ON analytics.daily_store_metrics
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
);

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, JWT claim 기반 RLS를 사용해야 합니다. set_config 기반 RLS는 Session Pooling 또는 전용 커넥션 전용입니다.

→ 매장은 자신의 tenant_id에 속한 store_id 데이터만 조회 가능합니다.

15-5-2. 지역 벤치마크 접근 제어

지역 벤치마크는 analytics.daily_region_metrics에서 제공하되:

일반 매장 사용자는:
- 자기 tenant의 store → store.region_id → region_code 추출
- 동일 industry_type + region_code만 조회

Super Admin만 모든 region/industry_type 조회 가능.

RLS 정책 예시:

-- 일반 사용자: 자기 업종 + 자기 지역만 조회
CREATE POLICY region_metrics_industry_region_filter ON analytics.daily_region_metrics
FOR SELECT TO authenticated
USING (
  industry_type = (
    SELECT industry_type FROM core_stores
    WHERE id IN (
      SELECT store_id FROM analytics.daily_store_metrics
      WHERE tenant_id = (auth.jwt() -> 'tenant_id')::uuid
      LIMIT 1
    )
  )
  AND region_code IN (
    SELECT r.code FROM core_regions r
    WHERE r.id IN (
      SELECT region_id FROM core_stores
      WHERE tenant_id = (auth.jwt() -> 'tenant_id')::uuid
    )
  )
);

⚠️ 중요: PgBouncer Transaction Pooling을 사용하는 경우, JWT claim 기반 RLS를 사용해야 합니다. set_config 기반 RLS는 Session Pooling 또는 전용 커넥션 전용입니다.

-- Super Admin: 모든 region 조회 가능
CREATE POLICY region_metrics_superadmin ON analytics.daily_region_metrics
FOR SELECT TO role_superadmin
USING (true);

15-5-3. 서비스 레이어 예시

// packages/services/analytics-service.ts
export const analyticsService = {
  async getStoreDashboard(tenantId: string, storeId: string, range: { from: string; to: string }) {
    // 1) 내 매장 KPI
    const myMetrics = await withTenant(
      supabase
        .from('analytics.daily_store_metrics')
        .select('*')
        .eq('store_id', storeId)
        .gte('date_kst', range.from)
        .lte('date_kst', range.to),
      tenantId,
    );

    // 2) 내 매장의 region / industry 정보 조회
    const store = await withTenant(
      supabase
        .from('core_stores')
        .select('region_id, industry_type')
        .eq('id', storeId)
        .single(),
      tenantId,
    );

    // 3) region_id → region_code, level 매핑
    const region = await supabase
      .from('core_regions')
      .select('level, code')
      .eq('id', store.region_id)
      .single();

    // 4) 동일 업종 + 동일 지역 벤치마크
    const benchmarks = await supabase
      .from('analytics.daily_region_metrics')
      .select('*')
      .eq('industry_type', store.industry_type)
      .eq('region_level', region.level)        // 동 기준 or 구 기준 등
      .eq('region_code', region.code)
      .gte('date_kst', range.from)
      .lte('date_kst', range.to);

    return { myMetrics, benchmarks };
  },

  async getStoreComparison(tenantId: string, storeId: string, monthKst: string) {
    // 전월 대비 비교
    const current = await withTenant(
      supabase
        .from('analytics.daily_store_metrics')
        .select('date_kst, revenue_total, active_members')
        .eq('store_id', storeId)
        .gte('date_kst', startOfMonth(monthKst))
        .lte('date_kst', endOfMonth(monthKst)),
      tenantId,
    );

    const prev = await withTenant(
      supabase
        .from('analytics.daily_store_metrics')
        .select('date_kst, revenue_total, active_members')
        .eq('store_id', storeId)
        .gte('date_kst', startOfPrevMonth(monthKst))
        .lte('date_kst', endOfPrevMonth(monthKst)),
      tenantId,
    );

    // 합산/평균 후 증감률 계산 (서버에서)
    const currentSummary = {
      revenue: sum(current.data, 'revenue_total'),
      members: avg(current.data, 'active_members'),
    };

    const prevSummary = {
      revenue: sum(prev.data, 'revenue_total'),
      members: avg(prev.data, 'active_members'),
    };

    const diffRate = {
      revenue: ((currentSummary.revenue - prevSummary.revenue) / prevSummary.revenue) * 100,
      members: ((currentSummary.members - prevSummary.members) / prevSummary.members) * 100,
    };

    return { currentSummary, prevSummary, diffRate };
  },
};

→ 모든 "전월 대비"/"전년 동월 대비"는 analytics.daily_store_metrics/analytics.daily_region_metrics를 기간별 집계한 뒤 서비스 레이어가 증감률을 계산하는 구조로 통일합니다.

→ SQL 레벨에서 복잡한 윈도우 함수로 직접 비교하지 않고, 서비스 코드에서 명시적으로 "current vs previous" 두 번 조회 후 계산합니다.

15-6. 지도(Geo) 기반 Analytics / 매장 분포 시각화 (Kakao Maps API)

⚠️ 중요: 기본 지도 기능은 Phase 1 (MVP)에 포함되며, 고급 지도 시각화는 Phase 2+에서 도입합니다.

Phase 1 (MVP) 기본 기능:
- 기본 지도 표시
- 행정동 기준 기본 히트맵
- 매장 위치 마커 표시

Phase 2+ 고급 기능:
- 고급 히트맵 (다중 지표, 시계열)
- 폴리곤 오버레이
- 고급 필터링 및 분석

DearSaaS의 모든 지도 및 지역 기반 통계는 카카오맵 JavaScript API + 자체 지역 경계 GeoJSON + Supabase Analytics Layer 조합으로 구현합니다.

15-6-0. 카카오맵 API 필수 요소

15-6-0-1. 주소 → 좌표 변환(Geocoding) 절차 (Critical)

⚠️ 중요: 매장 등록 시 주소를 좌표로 변환하는 공식 절차입니다.

Kakao Local API — 주소검색(Geocoding) 사용 필수:

[불변 규칙] 주소 → 좌표 변환은 반드시 Kakao Local API를 사용합니다.

API 엔드포인트:

GET https://dapi.kakao.com/v2/local/search/address.json?query={주소}

헤더:
- Authorization: KakaoAK {KAKAO_REST_API_KEY}

⚠️ Critical: Kakao API 키 분리 전략

[불변 규칙] Kakao는 JavaScript SDK용 JavaScript 키와 REST API용 REST API 키를 분리해서 사용합니다.

Kakao API 키 분리:

프론트엔드(React): NEXT_PUBLIC_KAKAO_JS_KEY만 사용
- 지도 렌더링 (JavaScript SDK)
- 주소 검색 UI (JavaScript SDK Geocoder)
- 클라이언트 번들에 포함되어도 안전 (공개 키)

백엔드/Edge Function: KAKAO_REST_API_KEY만 사용
- Local API (주소 검색, 좌표 변환)
- 서버에서만 사용, 클라이언트에 노출 금지

환경변수 설정:

// packages/env-registry/src/schema.ts

// 클라이언트용 (JavaScript SDK)
const envClientSchema = z.object({
  NEXT_PUBLIC_KAKAO_JS_KEY: z.string().min(1).optional(),  // Phase 2+ 지도 기능용
  // ...
});

// 서버용 (REST API)
const envServerSchema = z.object({
  KAKAO_REST_API_KEY: z.string().min(1).optional(),  // Phase 2+ 지도 기능용 (서버 전용)
  // ...
});

사용 예시:

// 프론트엔드 (지도 렌더링)
import { envClient } from '@env-registry/client';

<script
  src={`//dapi.kakao.com/v2/maps/sdk.js?appkey=${envClient.NEXT_PUBLIC_KAKAO_JS_KEY}&libraries=services,clusterer&autoload=false`}
/>

// 서버/Edge Function (Geocoding)
import { envServer } from '@env-registry/server';

export async function geocodeAddress(address: string) {
  const response = await fetch(
    `https://dapi.kakao.com/v2/local/search/address.json?query=${encodeURIComponent(address)}`,
    {
      headers: {
        'Authorization': `KakaoAK ${envServer.KAKAO_REST_API_KEY}`,  // REST API Key 사용
      },
    }
  );
  // ...
}

❌ 금지 예시:
// REST API Key를 클라이언트에 노출
const NEXT_PUBLIC_KAKAO_REST_API_KEY = ...;  // 절대 금지

// JavaScript Key를 서버에서 REST API 호출에 사용
Authorization: KakaoAK ${envClient.NEXT_PUBLIC_KAKAO_JS_KEY}  // REST API에는 사용 불가

응답 구조:

{
  "documents": [
    {
      "x": "127.1234567",      // longitude (경도)
      "y": "37.1234567",       // latitude (위도)
      "address": {
        "b_code": "11200530",  // 법정동 코드 (행정안전부 코드)
        "address_name": "서울특별시 강남구 역삼동"
      }
    }
  ]
}

좌표 저장 구조:

[불변 규칙] 좌표는 Kakao 기준 (WGS84) 그대로 사용합니다.

Supabase/PostgreSQL 저장 구조:

→ core_stores 테이블의 완전한 정의는 PART 1의 "2-2-2. 매장(Store) 및 지역(Region) 모델" 섹션을 참조합니다.

→ 좌표는 double precision 또는 numeric(10,7) 사용합니다.

region_id 매핑 절차 (표준 프로세스):

Step 1: 주소 입력 → Kakao Geocoding 호출

// services/store-service.ts
import { envClient } from '@env-registry/client';

export async function geocodeAddress(address: string) {
  const response = await fetch(
    `https://dapi.kakao.com/v2/local/search/address.json?query=${encodeURIComponent(address)}`,
    {
      headers: {
        'Authorization': `KakaoAK ${envServer.KAKAO_REST_API_KEY}`,
      },
    }
  );

  const data = await response.json();
  if (!data.documents || data.documents.length === 0) {
    throw new Error('주소를 찾을 수 없습니다.');
  }

  const result = data.documents[0];
  return {
    longitude: parseFloat(result.x),
    latitude: parseFloat(result.y),
    bCode: result.address.b_code,  // 법정동 코드
  };
}

Step 2: Kakao 응답의 b_code(법정동 코드) 획득

Step 3: core_regions.code = b_code 찾기

const region = await supabase
  .from('core_regions')
  .select('id, level, code')
  .eq('code', bCode)
  .eq('level', 'dong')
  .single();

if (!region) {
  throw new Error(`법정동 코드 ${bCode}에 해당하는 지역을 찾을 수 없습니다.`);
}

Step 4: store.region_id로 저장

await supabase.from('core_stores').insert({
  tenant_id: tenantId,
  address,
  latitude: geocodeResult.latitude,
  longitude: geocodeResult.longitude,
  region_id: region.id,
});

→ 이 절차가 표준 프로세스이며, 모든 매장 등록/수정 시 반드시 따라야 합니다.

트래픽 보호 전략 (쿼터 관리):

⚠️ Critical: Kakao Local API는 무료 쿼터가 제한됩니다.

기능	무료 쿼터

주소검색	3만건/일

좌표검색	3만건/일

→ 학원 1만개, 지역 업데이트 반복 시 초과 가능성이 매우 높습니다.

트래픽 보호 전략:

1. 테넌트가 주소를 변경했을 때만 geocoding 호출

// 주소 변경 감지
const existingStore = await getStore(storeId);
if (existingStore.address === newAddress && existingStore.latitude && existingStore.longitude) {
  // 주소가 변경되지 않았고 좌표가 이미 있으면 geocoding 생략
  return existingStore;
}

2. cron job으로 전체 매장 재스캔 금지

[불변 규칙] 배치 작업에서 전체 매장의 geocoding을 재수행하는 것은 금지됩니다.

3. geocoding 요청 결과 캐싱 (Edge KV/Redis)

// 캐싱 전략
const cacheKey = `geocode:${address}`;
const cached = await kv.get(cacheKey);
if (cached) {
  return cached;
}

const result = await geocodeAddress(address);
await kv.set(cacheKey, result, { ex: 86400 }); // 24시간 캐시

return result;

→ 주소 → 좌표 매핑은 거의 변하지 않으므로 캐싱으로 쿼터 절약이 가능합니다.

15-6-0-2. 지역 경계 데이터(동/구/시) 처리 방식 (Geo Boundary/Polygons)

⚠️ 중요: 지역 통계 히트맵을 구현하려면 행정구역 경계(폴리곤 데이터)가 필요합니다.

카카오 지도는 행정구역 경계 API를 지원하지 않기 때문에 아래 방식으로 구현합니다.

선택 옵션 2가지 중 1개를 선택합니다:

옵션 A — 외부 GeoJSON 데이터 사용 (권장)

행안부·국토지리정보원(KAI/Kakao) 기반 법정동 경계 GeoJSON을 DB 또는 CDN에 저장하고 지도에 로드

장점:
- 자유도 높음
- 정확한 행정구역 경계 데이터
- 커스터마이징 가능

단점:
- 데이터 용량 큼 (수 MB)
- 초기 데이터 구축 필요

구현 방식:

1. GeoJSON 데이터를 S3/CDN에 보관

예:
- /regions/si.json (시/도 경계)
- /regions/gu.json (구/군 경계)
- /regions/dong.json (동/읍/면 경계)

2. 지도 로드 시 region_level에 따라 해당 GeoJSON만 로드

⚠️ 중요: GeoJSON 좌표 순서와 Kakao Maps 좌표 순서 변환

[불변 규칙] GeoJSON은 [lng, lat] 배열이므로 Kakao Polygon 생성 시 반드시 (lat, lng)로 변환해야 합니다.

GeoJSON 표준: [longitude, latitude] 순서

Kakao Maps LatLng: LatLng(latitude, longitude) 순서

→ 변환이 필수입니다.

// RegionPolygonLayer.tsx
const loadRegionPolygons = async (regionLevel: 'dong' | 'gu_gun' | 'si') => {
  const geoJsonUrl = `/regions/${regionLevel}.json`;
  const response = await fetch(geoJsonUrl);
  const geoJson = await response.json();

  // Kakao Maps Polygon으로 변환
  geoJson.features.forEach((feature: any) => {
    // ⚠️ 중요: GeoJSON은 [lng, lat] 순서이므로 Kakao LatLng(lat, lng)로 변환
    const polygon = new kakao.maps.Polygon({
      path: feature.geometry.coordinates[0].map(([lng, lat]: [number, number]) =>
        new kakao.maps.LatLng(lat, lng)  // 순서 변환: [lng, lat] → LatLng(lat, lng)
      ),
      strokeWeight: 2,
      strokeColor: '#004c80',
      strokeOpacity: 0.8,
      fillColor: '#fff',
      fillOpacity: 0.5,
    });

    polygon.setMap(map);

    // 클릭 이벤트: region_code 전달 → Analytics API 호출
    kakao.maps.event.addListener(polygon, 'click', () => {
      const regionCode = feature.properties.code;
      onRegionClick(regionCode, regionLevel);
    });
  });
};

3. Polygon Overlay로 지도에 표시

4. 각 Polygon 클릭 시 region_code 전달 → Analytics API 호출

옵션 B — Kakao Maps Polygon Draw API 사용

https://apis.map.kakao.com

프론트에서 polygon을 직접 생성

장점:
- 빠른 구현
- 실시간 polygon 생성 가능

단점:
- 공식적으로 자동 polygon 제공 없음 → 사전 데이터 필요
- 정확도가 옵션 A보다 낮을 수 있음

→ 권장: 옵션 A (외부 GeoJSON 데이터 사용)

→ Phase 1에서는 polygon 없이 마커만 표시, Phase 2+에서 polygon 오버레이 도입

15-6-0-3. 지도 줌 레벨 ↔ 지역 레벨 자동 전환 (불변 규칙)

⚠️ 중요: 카카오맵에서 지도 줌을 바꿀 때 어떤 region_level을 보여줄지 정의가 필요합니다.

[불변 규칙] 지도 줌 레벨에 따라 자동으로 지역 단위를 변경합니다.

Kakao Zoom Level	표시 Region Level	설명

1–5	nation	전국 시각화

6–8	si	시/도 단위

9–11	gu_gun	구/군 단위

12–14	dong	동/읍/면 단위

15+	매장 점(Point) 레벨	개별 매장 마커 표시

// 구현 예시
map.addListener("zoom_changed", () => {
  const zoom = map.getLevel();
  const regionLevel = resolveRegionLevel(zoom);
  loadRegionPolygons(regionLevel);
  updateRegionMetrics(regionLevel); // 해당 레벨의 통계 데이터 로드
});

function resolveRegionLevel(zoom: number): 'dong' | 'gu_gun' | 'si' | 'nation' | null {
  if (zoom >= 15) return null; // Point 레벨 (매장 마커만)
  if (zoom >= 12) return 'dong';
  if (zoom >= 9) return 'gu_gun';
  if (zoom >= 6) return 'si';
  return 'nation';
}

→ 이 매핑 규칙을 문서에 명시하여 지도 UX가 일관되도록 합니다.

15-6-0-4. Kakao Maps API Key 규칙 및 스크립트 로딩 전략

API Key 관리:

[불변 규칙] Kakao Maps API Key는 용도별로 분리하여 사용합니다.

- NEXT_PUBLIC_KAKAO_JS_KEY: JavaScript SDK용 (프론트엔드 전용)
- KAKAO_REST_API_KEY: REST API용 (서버/Edge Function 전용)

→ 상세 규칙은 기술문서 PART 3의 "15-6-0-1. 주소 → 좌표 변환(Geocoding) 절차" 섹션 참조

서버키(REST API Key)는 사용하지 않음 (지도는 클라이언트용)

envServer에 절대 저장 금지

Key rotation 주기: 6개월

SDK 로딩 전략:

[불변 규칙] Kakao Map은 JavaScript SDK를 <script>로 불러오는 방식입니다.

Next.js에서의 로딩 방법:

옵션 1: next/script 사용 (권장)

// components/KakaoMapWrapper.tsx
import Script from 'next/script';
import { envClient } from '@env-registry/client';

export function KakaoMapWrapper({ children }: { children: React.ReactNode }) {
  const [isLoaded, setIsLoaded] = useState(false);

  return (
    <>
      <Script
        src={`//dapi.kakao.com/v2/maps/sdk.js?appkey=${envClient.NEXT_PUBLIC_KAKAO_JS_KEY}&libraries=services,clusterer&autoload=false`}
        strategy="lazyOnload"
        onLoad={() => {
          setIsLoaded(true);
        }}
      />
      {isLoaded && children}
    </>
  );
}

옵션 2: Custom Hook 사용

// hooks/useKakaoMap.ts
import { useEffect, useState } from 'react';
import { envClient } from '@env-registry/client';

export function useKakaoMap() {
  const [isLoaded, setIsLoaded] = useState(false);

  useEffect(() => {
    if (typeof window === 'undefined') return;

    // 중복 로드 방지
    if (window.kakao && window.kakao.maps) {
      setIsLoaded(true);
      return;
    }

    const script = document.createElement('script');
    script.src = `//dapi.kakao.com/v2/maps/sdk.js?appkey=${envClient.NEXT_PUBLIC_KAKAO_JS_KEY}&libraries=services,clusterer&autoload=false`;
    script.async = true;
    script.onload = () => {
      setIsLoaded(true);
    };
    document.head.appendChild(script);

    return () => {
      // cleanup (필요 시)
    };
  }, []);

  return { isLoaded };
}

페이지 전환 시 중복 로드 방지:

[불변 규칙] 페이지 전환 시 Kakao Maps SDK를 중복 로드하지 않습니다.

window.kakao 객체를 체크하여 이미 로드된 경우 재로드하지 않습니다.

// 중복 로드 방지 체크
if (window.kakao && window.kakao.maps) {
  // 이미 로드됨
  return;
}

→ SDK는 전역적으로 한 번만 로드되도록 관리합니다.

15-6-1. MapView 컴포넌트 (core-ui)

// packages/ui-core/src/... (예시)
type MapMetricMode =
  | 'store-density'      // 매장 수
  | 'revenue-avg'        // 평균 매출
  | 'members-avg';       // 평균 회원수

interface MapViewProps {
  center?: { lat: number; lng: number };
  zoom?: number;
  metricMode: MapMetricMode;
  // region 단위 히트맵 데이터 (region_code별 값)
  regionMetrics?: Array<{
    regionCode: string;
    value: number;
  }>;
  // 내 매장 위치 표시용
  myStores?: Array<{
    storeId: string;
    lat: number;
    lng: number;
  }>;
}

15-6-2. 반응형 레이아웃

Desktop: 지도 + 우측 KPI 카드/테이블 (Split layout)

Tablet: 지도 상단 / KPI 하단 (vertical split)

Mobile:
- 기본은 KPI 카드 리스트
- 지도는 "지도 보기" 버튼으로 풀스크린 모달로 전환

→ useResponsiveMode()와 함께 레이아웃 패턴을 명시합니다.

15-6-3. 지도 데이터 소스

지도에서 사용하는 색상/히트맵 값은 analytics.daily_region_metrics의 최근 N일 평균 혹은 선택 기간 평균.

매장 위치 마커는 core_stores.latitude/longitude.

// services/analytics-service.ts
export const analyticsService = {
  async getRegionHeatmap(industryType: string, dateKst: string, regionLevel: 'dong' | 'gu_gun' | 'si' = 'dong') {
    return supabase
      .from('analytics.daily_region_metrics')
      .select('region_level, region_code, revenue_avg, active_members_avg, store_count')
      .eq('industry_type', industryType)
      .eq('date_kst', dateKst)
      .eq('region_level', regionLevel);
  },

  async getStoreLocations(tenantId: string) {
    return withTenant(
      supabase
        .from('core_stores')
        .select('id, name, latitude, longitude, region_id')
        .eq('status', 'active'),
      tenantId,
    );
  },
};

15-7. 업종별 KPI 확장 방식 (Core vs Industry Layer 역할 분리)

15-7-1. 공통 Core KPI vs 업종별 확장 KPI

공통 Core KPI (모든 업종 공통):

revenue_total: 총 매출/수납액

active_members: 활성 고객 수(원생, 회원, 세입자 등)

new_members: 신규 고객 수

churned_members: 이탈 고객 수

visit_count: 방문/이용 횟수

업종별 확장 KPI (Industry Layer):

학원(academy):
- lesson_count (수업 수)
- class_fill_rate (반 정원 대비 채움률)

부동산(real_estate):
- listing_count (등록 매물 수)
- contract_count (체결 계약 수)

체육관(gym):
- attendance_count (출석 횟수)
- membership_type 별 구성비

15-7-2. 확장 방식 설계 원칙

Core Layer는 analytics.events / analytics.daily_store_metrics / analytics.daily_region_metrics에 공통 컬럼만 정의합니다.

업종별 추가 지표는 각 Industry 패키지에서 Mapper/Helper를 통해 payload 또는 별도 확장 컬럼으로 관리합니다.

새로운 업종이 추가되어도 Core 스키마는 유지되며, Industry Layer만 확장됩니다.

// packages/industry/industry-academy/src/analytics-mapper.ts
export const academyAnalyticsMapper = {
  calculateDailyMetrics(events: AnalyticsEvent[]): DailyStoreMetrics {
    const baseMetrics = defaultAnalyticsMapper.calculateDailyMetrics(events);

    // 업종별 KPI 계산
    const lessonCount = events.filter(e => e.event_type === 'lesson_attended').length;
    const classFillRate = calculateClassFillRate(events);

    return {
      ...baseMetrics,
      lesson_count: lessonCount,
      class_fill_rate: classFillRate,
    };
  },
};

→ Core Layer는 공통 KPI만 관리하고, 업종별 특화 지표는 Industry Layer에서 계산하여 확장 컬럼에 저장합니다.

Backfill 함수 정의:

CREATE OR REPLACE FUNCTION analytics.fn_backfill_daily_metrics(
  tenant_ids uuid[],
  start_date date,
  end_date date
) RETURNS void
LANGUAGE plpgsql SECURITY DEFINER AS $$
BEGIN
  -- tenant_id IN (tenant_ids) 강제 필터링
  -- statement_timeout, row limit 필수
  -- 멱등성 키 기반 중복 합산 방지
  -- analytics.events에서 해당 기간 데이터 재집계
  -- analytics.daily_metrics에 upsert
END; $$;

15-4-2-1. Analytics Pipeline Backfill 정합성 검증 (Critical, Phase 2+ 전용)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

MVP/Phase 1에서는 KST 기준 집계 + daily_metrics / monthly_revenue 테이블까지만 구현하고, Backfill + 정합성 검증 풀 패키지는 Phase 2 Analytics 확장으로 미룹니다.

정확한 pipeline의 완결은 다음 단계가 모두 필요 (Phase 2+):

1. 이벤트 → 집계

2. 집계 → DB 기록

3. 집계 전후 불일치 탐지 (정합성 검증):

```sql
-- 집계 전후 데이터 비교
WITH source_data AS (
  SELECT
    tenant_id,
    date,
    SUM(amount) as source_total
  FROM analytics.events
  WHERE occurred_at >= _start_date AND occurred_at < _end_date
  GROUP BY tenant_id, date
),
aggregated_data AS (
  SELECT
    tenant_id,
    date,
    total_revenue as agg_total
  FROM analytics.daily_metrics
  WHERE date >= _start_date AND date < _end_date
)
SELECT
  s.tenant_id,
  s.date,
  s.source_total,
  a.agg_total,
  ABS(s.source_total - a.agg_total) as diff
FROM source_data s
LEFT JOIN aggregated_data a ON s.tenant_id = a.tenant_id AND s.date = a.date
WHERE ABS(s.source_total - a.agg_total) > 0.01; -- 허용 오차
```

4. 자동 보정 또는 알람:

불일치 발견 시 자동 재집계 또는 운영자 알람

구현 예시:

```typescript
async function validateBackfill(tenantIds: string[], startDate: Date, endDate: Date) {
  const discrepancies = await db.query(`
    SELECT tenant_id, date, source_total, agg_total, diff
    FROM validate_aggregation($1, $2, $3)
    WHERE diff > 0.01
  `, [tenantIds, startDate, endDate]);

  if (discrepancies.length > 0) {
    // 알람 발송
    await sendAlert('Analytics aggregation mismatch', discrepancies);

    // 자동 재집계 (선택적)
    if (autoFix) {
      await backfillDailyMetrics(tenantIds, startDate, endDate);
    }
  }
}
```

예시:

-- 특정 기간 Backfill (특정 테넌트만)
SELECT analytics.fn_backfill_daily_metrics(
  tenant_ids => ARRAY['tenant-uuid-1', 'tenant-uuid-2'],
  start_date => '2025-01-01',
  end_date => '2025-01-31'
);


→ 운영 효율성 향상을 위한 보완 사항

15-9. 대시보드 View / Materialized View

analytics.v_tenant_dashboard

analytics.mv_tenant_dashboard (머뷰, 일정 주기 리프레시)

주요 지표:

오늘/이번달 매출 (KST 기준)

출석률/결석률

미납 금액

신규 가입자 수

사용량(문자, 푸시, 통화 등)

머뷰 리프레시는 하루 1~4회 (예: 01:00, 07:00, 13:00, 19:00 KST) 정책 등으로 조정.

15-9-1. Analytics/Replica 일관성 고지 (Optional)

리드 레플리카 사용 화면에 "최근 동기화 시각(KST)" 배지 표기 (복제 지연 혼선 방지)

대시보드 각 위젯에 data_freshness_kst 표준 필드 제공

→ 데이터 신선도 표기는 사용자 혼란 방지에 중요

📘 PART 4
테넌트 프로비저닝 / SaaS 생성 / DevOps & 운영 / Cursor 규칙
16. 테넌트 프로비저닝 & SaaS 생성
16-1. 새 테넌트 생성 플로우

[불변 규칙] 테넌트 생성 및 온보딩은 core-tenancy/onboarding.ts에서 공통으로 관리합니다.

플로우:

1. 사용자 회원가입 (core-auth/signup.ts)
   - Super Admin 콘솔 혹은 Public Sign-up 폼에서 신청
   - Supabase Auth를 통한 사용자 계정 생성
   - 이메일 인증 (선택적)

2. 테넌트 생성 및 초기화 (core-tenancy/onboarding.ts)
   - tenants에 row 생성
   - tenant_settings에 업종별 기본값 저장 (timezone: Asia/Seoul, locale: ko-KR 등)
   - tenant_features에 플랜/기능 ON/OFF 설정
   - owner 유저를 user_tenant_roles에 연결 (role: 'owner')
   - 추천인 코드 처리 (선택적, core-tenancy-referral 연동)

3. 업종별 초기 데이터 시드 (Industry Layer)
   - 업종별 seed 실행 (예: 학원 기본 반, 미용실 기본 서비스, 요금 항목)
   - Industry Layer의 각 모듈에서 별도로 처리
   - 예: industry-academy에서 기본 반, 기본 강사 등 생성

시간 처리:

테넌트 생성 시간 created_at은 timestamptz로 UTC 저장

UI/Super Admin 화면에는 항상 KST로 변환하여 표기

구현 예시:

```typescript
// 1. 사용자 회원가입
import { signupService } from '@core/auth/signup';
const { user } = await signupService.signupWithEmail({
  email: 'owner@example.com',
  password: 'password123',
  name: '홍길동',
});

// 2. 테넌트 생성 및 온보딩
import { tenantOnboardingService } from '@core/tenancy/onboarding';
const { tenant, user_tenant_role } = await tenantOnboardingService.createTenant({
  name: '우리 학원',
  industry_type: 'academy',
  owner_user_id: user.id,
  plan: 'basic',
  referral_code: 'REF123', // 선택적
});

// 3. 업종별 초기 데이터 시드 (Industry Layer)
import { academyService } from '@industry/academy/service';
await academyService.initializeTenantData(tenant.id);
```

16-2. 새로운 업종 SaaS 추가 과정

/packages/industry/industry-<업종> 생성

도메인 모델 정의 (테이블/뷰/서비스)

Core Billing/Payment에 매핑 구성

업종 전용 앱 필요 시 /apps/<industry>-admin 추가

Super Admin에서 업종 활성화 → 신규 테넌트 생성 시 선택 가능

16-2-1. Industry 모듈 마이그레이션 격리 정책 (Critical)

Industry 모듈의 마이그레이션은 Core 마이그레이션과 충돌하지 않도록 테이블명 접두어 또는 별도 폴더 구조로 분리한다.

구조 예시:

infra/supabase/migrations/
  ├─ core/              # Core 마이그레이션
  │  └─ 20250101_0000_kst_create_students.sql
  ├─ industry-academy/   # 업종별 마이그레이션
  │  └─ 20250101_0100_kst_create_academy_classes.sql
  └─ industry-salon/
     └─ 20250101_0200_kst_create_salon_services.sql

또는 테이블명 접두어 사용:

academy_students, academy_classes (Industry 전용)

salon_customers, salon_services (Industry 전용)

권장 전략:

폴더 분리 방식을 기본 권장안으로 사용하고, 레거시 연동 등 특수 케이스에서만 접두어 전략을 보조적으로 사용한다.

→ 대규모 팀 개발 시 충돌 방지에 중요

17. DevOps & 운영
17-1. 마이그레이션 관리

모든 스키마 변경은 infra/supabase/migrations에 SQL 파일로 관리

파일명 규칙:

YYYYMMDD_HHMM_kst_<description>.sql

예: 20251205_2300_kst_add_attendance_partition.sql

적용 순서:

dev

staging

prod

배포 윈도우 예:

야간(트래픽 최소) 기준 금요일 23:00~24:00 KST

17-2. 모니터링 체계
DB

쿼리 응답 시간

슬로우 쿼리 로그

RLS 실패 이벤트

연결 수/replica lag

애플리케이션

요청 수/에러율

Edge Function 응답 시간

주요 비즈니스 지표(결제 성공률, 출결 처리 성공률)

로그 시간은 모두 KST 표기로 집계 대시보드 구성
(저장시에는 UTC, 시각화·분석·알람 문구는 KST)

17-3. KST / UTC 이중 표기 규칙

배치 : 매일 04:00 KST 실행
# Supabase cron 설정값 : 19:00 UTC (KST-9)


모든 운영 문서·로그·알람 : KST 표기 기준

대시보드 필수 지표 추가 : RLS 실패율 / 캐시 미스율 / replica lag / Webhook 재시도율

17-4. 성능/확장 체크리스트

대형 테이블:

tenant_id 인덱스 존재

파티셔닝 도입 여부

모든 조회 쿼리에 tenant_id 조건 필수

N+1 없는지 확인

heavy read 쿼리는 Read Replica로 라우팅

집계/리포트용 쿼리는 가능한 한 analytics 테이블/뷰 사용

18. Cursor AI / 코드 생성 규칙

18-0. Naming Convention 전면 가이드 (Critical)

SQL 명명 규칙:

테이블/컬럼: snake_case (예: tenant_id, created_at)

함수/프로시저: snake_case (예: fn_aggregate_daily)

인덱스: idx_<table>_<column> 또는 ux_<table>_<unique_column> (예: idx_students_tenant_id, ux_payment_idem)

TypeScript 파일명:

일반 파일: kebab-case (예: payment-service.ts, tenant-utils.ts)

컴포넌트: PascalCase (예: StudentList.tsx, PaymentForm.tsx)

Edge Function 이름:

kebab-case (예: payment-webhook, public-gateway-verify)

Industry prefix 규칙:

Industry 모듈: industry-<업종> (예: industry-academy, industry-salon)

Industry 테이블 접두어: <업종>_<table> (예: academy_classes, salon_customers) - 선택적 사용

변수명:

TypeScript/JavaScript: camelCase (예: tenantId, createdAt)

SQL 변수: snake_case (예: _tenant_id, _start_date)

18-1. UI

⚠️ 중요: UI/UX 규약의 정식 출처는 〈UI/UX Technical Architecture〉 문서입니다.

기본 원칙:
- 모든 UI는 core-ui 컴포넌트 사용
- CSS/MQ 직접 작성 금지 → useResponsiveMode() 사용
- 모바일/태블릿/PC 레이아웃은 DataTable / TableCardView / SplitTableLayout 조합

→ 상세 규칙은 UI/UX 문서의 "6. Responsive UX — Enterprise Version" 및 "4. Multi-Tenant Theme Engine" 섹션 참조

11-1. 테넌트별 Theme Override 규칙 (Critical)

⚠️ 중요: 테넌트별 Theme Override는 UI 문서의 "4. Multi-Tenant Theme Engine" 섹션과 동일한 우선순위를 따릅니다.

Theme Merge Priority (우선순위 순서):

1. system default tokens (시스템 기본 토큰)
2. industry tokens (업종별 토큰) - `industry_themes` 테이블에서 조회
3. tenant theme override (테넌트별 오버라이드) - `tenant_theme_overrides` 테이블에서 조회
4. dark mode (다크모드) - 시스템 설정 자동 감지 (`prefers-color-scheme: dark`)
5. high contrast (forced-colors, 접근성) - 시스템 설정 자동 감지 (`prefers-contrast: high`) 또는 수동 설정

→ UI는 위 레이어에서 순차적으로 override되어 최종 Token Set을 사용합니다.

**Backend와 Frontend 역할 분리**:
- **Backend의 `getTenantTheme()`**: light 기준 neutral 토큰만 병합 (1-3번 레이어)
  - 시스템 기본 토큰 + 업종별 토큰 + 테넌트 오버라이드를 병합하여 반환
  - 다크모드/High Contrast 적용은 하지 않음
- **Frontend의 `ThemeEngine`**: Backend 토큰 + 다크모드/High Contrast 적용 (4-5번 레이어)
  - Backend에서 받은 토큰에 다크모드/High Contrast 변환을 적용하여 최종 토큰 생성
  - 시스템 설정 자동 감지 및 CSS 변수 적용까지 담당

**다크모드 및 High Contrast 자동 감지**:
- `mode: 'auto'`일 때 시스템 다크모드 설정 자동 감지 (`prefers-color-scheme: dark`)
- `highContrast: false`일 때 시스템 High Contrast 설정 자동 감지 (`prefers-contrast: high`)
- 시스템 설정 변경 시 자동으로 테마 재적용
- **브라우저 지원 fallback**: `prefers-contrast` / `forced-colors`를 지원하지 않는 브라우저에서는 사용자 설정(수동 토글) 우선, 접근성 설정 페이지에서 수동 토글 가능

업종별 Theme Tokens 저장 위치:

**⚠️ 중요: Industry 타입 표준**
- 전체 시스템에서 사용하는 Industry 타입 표준: `'academy'`, `'salon'`, `'real_estate'`, `'gym'`, `'ngo'`
- `industry_themes` 테이블의 CHECK 제약도 이 표준을 따름
- 다른 테이블(`tenants`, `schema_registry` 등)의 `industry_type` 컬럼도 동일한 표준 사용

```sql
CREATE TABLE IF NOT EXISTS industry_themes (
  industry_type text PRIMARY KEY CHECK (industry_type IN ('academy', 'salon', 'real_estate', 'gym', 'ngo')),
  theme_tokens jsonb NOT NULL,  -- 업종별 테마 토큰
  updated_at timestamptz NOT NULL DEFAULT now(),
  updated_by uuid REFERENCES auth.users(id)
);

CREATE INDEX IF NOT EXISTS idx_industry_themes_type ON industry_themes(industry_type);
```

테넌트별 Theme Override 저장 위치:

```sql
CREATE TABLE IF NOT EXISTS tenant_theme_overrides (
  tenant_id uuid PRIMARY KEY REFERENCES tenants(id),
  theme_tokens jsonb NOT NULL,  -- 테넌트별 오버라이드 토큰
  updated_at timestamptz NOT NULL DEFAULT now(),
  updated_by uuid REFERENCES auth.users(id)
);

CREATE INDEX IF NOT EXISTS idx_tenant_theme_overrides_tenant ON tenant_theme_overrides(tenant_id);
```

테넌트별 Theme Override 예시:

**⚠️ 중요: v1.0 정책**
- 업종/테넌트 테마 오버라이드는 **colors만 지원**
- typography/spacing은 시스템 공통 토큰 사용 (업종/테넌트별 커스터마이징 불가)
- 향후 버전에서 typography/spacing 오버라이드 지원 가능

```json
{
  "colors": {
    "primary": {
      "light": "#60a5fa",
      "DEFAULT": "#3b82f6",
      "dark": "#2563eb"
    },
    "secondary": {
      "light": "#a78bfa",
      "DEFAULT": "#8b5cf6",
      "dark": "#7c3aed"
    }
  }
}
```

참고: 테이블 스키마는 향후 확장을 위해 `theme_tokens jsonb`로 설계되었으나, v1.0에서는 colors만 사용합니다.

Frontend에서 Theme Token 적용 (실제 구현):

```typescript
// packages/ui-core/src/hooks/useTheme.ts
export function useTheme(options: {
  mode?: ThemeMode;
  highContrast?: boolean;
} = {}) {
  const context = getApiContext();
  const tenantId = context.tenantId;
  const industryType = context.industryType;

  // 다크모드 자동 감지 (options.mode + 시스템 설정)
  const [isDarkMode, setIsDarkMode] = useState(() => {
    if (options.mode === 'dark') return true;
    if (options.mode === 'light') return false;
    return window.matchMedia('(prefers-color-scheme: dark)').matches;
  });

  // High Contrast 자동 감지 (options.highContrast + 시스템 설정)
  const [isHighContrast, setIsHighContrast] = useState(() => {
    if (options.highContrast) return true;
    return window.matchMedia('(prefers-contrast: high)').matches;
  });

  // actualMode / actualHighContrast는 options + 시스템 설정 자동 감지 결과
  const actualMode: ThemeMode = options.mode === 'auto'
    ? (isDarkMode ? 'dark' : 'light')
    : (options.mode || 'auto');
  const actualHighContrast = options.highContrast || isHighContrast;

  // 1. 업종별 테마 토큰 조회 (industry_themes 테이블)
  const { data: industryThemeOverride } = useQuery({
    queryKey: ['industry-theme', industryType],
    queryFn: async () => {
      if (!industryType) return null;
      const response = await apiClient.get('industry_themes', {
        filters: { industry_type: industryType },
      });
      return response.data?.[0]?.theme_tokens || null;
    },
    enabled: !!industryType,
    staleTime: 10 * 60 * 1000, // 10분
  });

  // 2. 테넌트별 테마 오버라이드 조회 (tenant_theme_overrides 테이블)
  const { data: tenantThemeOverride } = useQuery({
    queryKey: ['tenant-theme', tenantId],
    queryFn: async () => {
      if (!tenantId) return null;
      const response = await apiClient.get('tenant_theme_overrides', {
        filters: { tenant_id: tenantId },
      });
      return response.data?.[0]?.theme_tokens || null;
    },
    enabled: !!tenantId,
    staleTime: 5 * 60 * 1000, // 5분
  });

  // 3. ThemeEngine으로 병합 (우선순위 순서)
  // v1.0 정책: colors만 지원 (typography/spacing은 시스템 공통)
  const themeEngine = createTheme({
    mode: actualMode,
    industry: industryType,
    tenantId,
    industryTheme: industryThemeOverride?.colors ? {
      industry: industryType!,
      tokens: { colors: industryThemeOverride.colors },
    } : undefined,
    tenantTheme: tenantThemeOverride?.colors ? {
      tenantId,
      tokens: { colors: tenantThemeOverride.colors },
    } : undefined,
    highContrast: actualHighContrast,
  });

  // 4. CSS 변수로 적용
  const mergedTokens = themeEngine.getTokens();
  applyThemeToCSS(mergedTokens);
}
```

**Graceful Fallback 동작**:
- 각 레이어에서 정의되지 않은 토큰은 하위 레이어(system/industry)의 값이 유지됨
- `industry_themes` 또는 `tenant_theme_overrides` 레코드가 없어도 system-only로 정상 렌더링됨
- API 오류 발생 시에도 기본 테마로 fallback하여 UI가 깨지지 않음

Backend에서 Theme Token API 공급 (참고용):

**⚠️ 중요: Backend 역할 제한**
- Backend의 `getTenantTheme()`는 **light 기준 neutral 토큰만 병합** (1-3번 레이어)
- 다크모드/High Contrast 적용은 하지 않음 (4-5번 레이어는 Frontend에서 처리)
- Backend는 토큰 데이터만 제공하고, 모드 변환은 Frontend ThemeEngine에서 수행

```typescript
// services/theme-service.ts
export const themeService = {
  async getTenantTheme(tenantId: string) {
    // 1. 시스템 기본 토큰 (light 모드 기준)
    const systemTokens = getSystemDefaultTokens();

    // 2. 업종별 토큰 (industry_themes 테이블에서 조회)
    const tenant = await getTenant(tenantId);
    const industryTheme = await supabase
      .from('industry_themes')
      .select('theme_tokens')
      .eq('industry_type', tenant.industry_type)
      .single();
    const industryTokens = industryTheme?.theme_tokens || {};

    // 3. 테넌트별 오버라이드
    const override = await supabase
      .from('tenant_theme_overrides')
      .select('theme_tokens')
      .eq('tenant_id', tenantId)
      .single();

    // 4. 병합 (우선순위 순서: system → industry → tenant)
    // 다크모드/High Contrast는 적용하지 않음 (Frontend에서 처리)
    return mergeThemeTokens([
      systemTokens,
      industryTokens,
      override?.theme_tokens || {}
    ]);
  }
};
```

RLS/테넌트 Isolation 기준:

- 테넌트는 자신의 테마 오버라이드만 조회/수정 가능
- Super Admin은 모든 테넌트의 테마 오버라이드를 조회/수정 가능
- 테마 오버라이드는 RLS로 보호되며, tenant_id 기반 격리 적용

```sql
CREATE POLICY tenant_isolation_theme_overrides ON tenant_theme_overrides
FOR ALL TO authenticated
USING (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
  OR EXISTS (
    SELECT 1 FROM auth.users
    WHERE id = auth.uid()
    AND role = 'super_admin'
  )
)
WITH CHECK (
  tenant_id = (auth.jwt() -> 'tenant_id')::uuid
  OR EXISTS (
    SELECT 1 FROM auth.users
    WHERE id = auth.uid()
    AND role = 'super_admin'
  )
);
```

11-2. Super Admin 테넌트 테마 관리 메뉴 정의

Super Admin 앱에서 테넌트별 테마 관리 기능:

메뉴 위치: `/super-admin/tenants/:tenantId/theme`

기능:

1. 테넌트 테마 오버라이드 조회
   - 현재 적용된 테마 토큰 표시
   - 시스템 기본 / 업종 토큰 / 테넌트 오버라이드 구분 표시

2. 테넌트 테마 오버라이드 수정
   - 색상, 타이포그래피, 간격 등 토큰 수정
   - 실시간 미리보기 제공
   - 변경 사항 저장 시 즉시 적용

3. 테마 오버라이드 초기화
   - 테넌트 오버라이드를 삭제하여 기본 테마로 복원
   - 확인 다이얼로그 필수

4. 테마 버전 관리
   - 테마 변경 이력 조회 (audit.events 기반)
   - 특정 시점으로 롤백 가능

구현 예시:

```typescript
// apps/super-admin/pages/tenants/[tenantId]/theme.tsx
export function TenantThemeManagementPage({ tenantId }: { tenantId: string }) {
  const { data: theme, mutate } = useTenantTheme(tenantId);
  const [preview, setPreview] = useState(theme);

  const handleSave = async (newTheme: ThemeTokens) => {
    await updateTenantTheme(tenantId, newTheme);
    mutate();
    showSuccess('테마가 업데이트되었습니다.');
  };

  return (
    <ThemeEditor
      initialTheme={theme}
      preview={preview}
      onPreviewChange={setPreview}
      onSave={handleSave}
      onReset={() => resetTenantTheme(tenantId)}
    />
  );
}
```

→ 테넌트별 Theme Override는 Backend에서 API로 공급하며, RLS/테넌트 isolation 기준을 준수합니다.
→ Super Admin 앱에서 테넌트별 테마 관리 메뉴를 제공하여 운영자가 테넌트 테마를 관리할 수 있습니다.

18-2. 데이터 접근

React 컴포넌트에서 Supabase 직접 호출 금지

services/ → DB 접근

hooks/ → React Query 래핑

Edge Function 호출은 lib/supabase-client에서 wrapper로 관리

18-3. 아키텍처

새로운 업종은 반드시 /packages/industry/*에 구현

Core Layer는 Industry 레이어를 import 하지 않는다 (Industry → Core 단방향 의존성 유지)

→ Industry 모듈은 Core를 import할 수 있지만, Core는 Industry를 import할 수 없습니다.

18-4. Monorepo 빌드 성능 최적화 (Critical)

문제점: 업종이 수십 개 이상 규모로 늘어날 경우 빌드 시간 급격히 증가, 테스트 전체 실행 시 CI 시간 폭증

해결책: Turborepo or Nx 기반 incremental build + remote cache 필수화

구조:

/packages/
  ├─ core/              # 변경 빈도 낮음
  ├─ industry-academy/  # 독립 빌드
  ├─ industry-salon/    # 독립 빌드
  └─ ...


빌드 규칙:

변경 없는 패키지 재빌드 금지

업종별 test pipeline 분리 (병렬 실행)

Remote cache 활용 (CI/CD 간 캐시 공유)

빌드 캐싱 전략:

빌드 캐싱의 80%는 Turborepo Remote Cache/Nx Cloud에서 해결되며, Vercel의 VERCEL_BUILD_IGNORED는 보조적인 최적화로만 사용한다.

이유:

Vercel의 VERCEL_BUILD_IGNORED는 "프로젝트 단위"에만 작동하여 앱 단위의 fine-grained 캐싱을 지원하지 못함

Vercel의 Monorepo 빌드 캐싱은 Git 변경 감지 기반으로 dependency 트리를 자동 분석하지 못함

Turborepo Remote Cache/Nx Cloud는 dependency 트리를 정확히 분석하여 더 정확한 캐싱 제공

Supabase Functions는 별도 파이프라인이므로 Vercel 캐시와 완전 분리된 빌드 흐름 필요

예시 설정 (Turborepo):

{
  "pipeline": {
    "build": {
      "dependsOn": ["^build"],
      "outputs": ["dist/**"]
    },
    "test": {
      "dependsOn": ["build"],
      "outputs": []
    }
  }
}


→ 실제 SaaS 플랫폼으로 운영하려면 반드시 반영해야 합니다.

18-5. Timezone 변환 강제 규칙(Lint) (Optional)

UTC 저장 → KST 표현은 매우 훌륭하나, 실수 방지를 위해 표준화된 함수 사용을 lint 규칙으로 강제

규칙:

모든 날짜/시간 표시는 toKST() 함수 사용 필수

DB 쿼리에서 날짜 비교 시 toUTC() 함수 사용 필수

Lint 규칙 예시 (ESLint):

{
  "rules": {
    "no-direct-date-format": "error",
    "require-timezone-conversion": "error"
  }
}


허용 예시:

const kstDate = toKST(utcTimestamp);
const utcDate = toUTC(kstDate);

금지 예시:

const date = new Date().toLocaleString(); // ❌
const date = moment().format(); // ❌

DB 레이어 책임 명시:

파티셔닝 및 인덱싱 기준은 반드시 UTC 컬럼을 기준으로 수행하며, KST 변환은 App Layer(React/Edge Function)에서만 담당한다.

18-6. 데이터 생성 및 콘텐츠 정책 (Critical)

더미 데이터 생성 금지:

운영 DB/실서비스 환경에 의미 없는 임의 더미데이터를 남기지 않는다.

실제 데이터 구조와 스키마만 사용한다.

테스트 데이터 정책:

테스트/시연/문서용 예시는 허용하되, 항상 'test용/샘플'임이 명확하게 드러나게 작성한다.

테스트는 seed/migration 기반의 통제된 테스트 데이터로 수행한다.

운영 환경과 테스트 환경을 명확히 구분한다.

이모지 생성 금지:

운영 코드/사용자 노출 UI 텍스트에는 이모지를 사용하지 않는다.

기술 설계 문서/프레젠테이션/아키텍처 설명에는 이모지 사용 가능 (가독성 향상 목적).

→ 코드는 금지, 문서는 허용

예시:

❌ 금지 (코드): console.log("✅ 성공!");

✅ 허용 (코드): console.log("Success");

✅ 허용 (문서): PART 1, 최종 목표 등 문서 구조 표시용 이모지

→ 코드베이스의 일관성 및 유지보수성 보장

18-7. Cursor/AI 코드 생성 시 변수명 일관성 유지 (Critical)

RLS / set_config / tenant_id 관련 예제들은 변수명과 패턴을 그대로 재사용하게 강제한다.

18-2-1. Core 레이어에서 Industry import 금지 규칙 (Critical)

Core 레이어에서 Industry 모듈 import 금지 규칙을 lint로 강제:

```json
// .eslintrc.json
{
  "rules": {
    "no-restricted-imports": [
      "error",
      {
        "paths": [],
        "patterns": [
          {
            "group": ["@industry/*", "packages/industry/**"],
            "message": "Core 레이어에서는 Industry 모듈을 import 할 수 없습니다."
          }
        ]
      }
    ]
  }
}
```

→ Industry 모듈은 Core를 import할 수 있지만, Core는 Industry를 import할 수 없음 (Industry → Core 단방향 구조)

Cursor/AI가 SQL/코드를 생성할 때, 다음 항목은 변경하지 않는다:

tenant_id 컬럼명

app.current_tenant_id 키 이름

withTenant() 유틸 함수 이름

표준 RLS 정책 패턴 (NULLIF(current_setting(..., true), '') 형식)

→ 일관된 보안/성능 패턴 유지를 위해 필수

예시:

❌ 금지: app.tenant, current_tenant, withTenantFilter()

✅ 허용: app.current_tenant_id, tenant_id, withTenant()

📘 PART 5
보안 & 개인정보 보호 강화 (KST 표준 / 멀티테넌트 RLS / PII / 키 관리 / 웹훅 보안)

이 파트는 기존 아키텍처 위에 보안·개인정보 보호·타임존(KST) 표준을 명시적으로 얹는 섹션이다.

⚠️ 중요: Phase별 보안 구현 우선순위

본 문서의 Phase 3+ 항목(PII AEAD 암호화, KMS 키 회전 등)은 2~3만 테넌트 + 금융/법적 요구사항이 명확해진 이후에만 도입합니다.

Phase 1-2에서는 기본 보안(RLS, 마스킹, Webhook 서명 검증)만으로 충분하며, Phase 3+ 고급 보안 기능은 실제 필요성이 확인된 후에만 구현합니다.

19. 보안 & 개인정보 보호 기본 원칙

모든 시간은 KST 기준으로 표시·설계

DB에는 UTC로 저장하되,
UI·리포트·로그·알람·문서 상 시간 표기는 모두 "KST" 기준/표기.

멀티테넌트 완전 격리

RLS + tenant_id + app.current_tenant_id 사용.

PII(개인정보)는 최소 수집·필요 시 암호화·마스킹.

서비스 키/비밀은 Edge Function/서버에서만 사용 (클라이언트 노출 금지).

모든 외부 Webhook은 서명 검증 + 멱등성 처리 + 시간 윈도우 검증.

감사 로그(audit)로 주요 접근·변경 추적, 일정 기간 이후 파기.

19-0. 보안 구현 Phase별 우선순위

MVP / Phase 1 (필수):

규모 레벨: 학원 100~300개 수준

RLS + tenant_id 격리

Service Role Key 프론트 미노출

Webhook 서명 검증 + 멱등성

기본 Rate Limiting

19-9-1. API Abuse 방지 정책 (Critical)

레이트리밋만으로는 부족하므로, 다음 보안 정책을 추가로 적용:

Bot/스크래핑 방지:

Cloudflare Turnstile 또는 reCAPTCHA v3 사용

의심스러운 트래픽 패턴 감지 시 추가 인증 요구

파일 업로드 virus scan:

업로드된 파일은 ClamAV 또는 AWS GuardDuty로 스캔

악성 파일 감지 시 즉시 차단 및 알림

대량 export 시 CAPTCHA 요구:

데이터 export 요청 시 CAPTCHA 인증 필수

IP 기반 이상 탐지:

같은 IP에서 짧은 시간 내 다수 요청 시 임시 차단

구현 예시:

```typescript
// Cloudflare Turnstile 통합
import { verifyTurnstileToken } from '@/lib/turnstile';

export async function POST(req: Request) {
  const token = req.headers.get('cf-turnstile-response');
  if (!await verifyTurnstileToken(token)) {
    return new Response('Unauthorized', { status: 401 });
  }
  // ... 처리
}
```

Phase 2 (중요):

규모 레벨: 1~3k 테넌트

PII 마스킹

audit.events 로깅

Public Gateway 토큰 검증

Rate Limiting 세분화

Analytics 외부 워커 (Lambda/Workers) 도입

Edge Function Role 분리 (최소 권한 원칙)

Custom Domain 자동화 (헬스체크, SSL 알람)

Critical Path 캐시 무효화

마스터 데이터 변경 시 캐시 invalidation

Phase 3 (고급):

규모 레벨: 20k+ 테넌트

PII AEAD 암호화

KMS 기반 키 회전

MFA + SSO

Hot Tenant 수직 분리 (수동)

업종별 스키마 분리 검토

이중 파티셔닝 검토

19-3-1. WebAuthn / Passkey 지원 (향후 필요)

SUPER-ADMIN 콘솔에서는 MFA만으로는 부족할 수 있으므로, 향후 Passkey/WebAuthn 옵션을 고려한다.

WebAuthn 장점:

비밀번호 없이 생체 인증 또는 하드웨어 키 사용

피싱 공격에 강함

구현 방법:

Supabase Auth의 WebAuthn 확장 또는 별도 인증 레이어 구축

Phase 4 (고급 보안)에서 도입 검토

DLQ + 재처리 고도화

→ 초기에는 필수 보안만 구현하고, 점진적으로 확장한다.

19-1. 타임존(KST) 표준

19-1-1. 저장/표시 원칙

[불변 규칙] 모든 타임스탬프는 DB에 UTC로 저장하되, 비즈니스 로직·표시·집계는 KST 기준으로 처리합니다.

DB 저장: timestamptz(UTC)

이벤트 발생 시 서버/Edge Function에서 now() 사용

UI·리포트·로그·알람: 항상 KST로 변환해서 표시

19-1-2. KST 기준 날짜 처리 규칙 (Critical)

⚠️ 중요: DB에서 날짜 기준 로직에 CURRENT_DATE를 그대로 사용하면 안 됩니다.

[불변 규칙] DB에서 KST 기준 날짜가 필요하면 반드시 timezone('Asia/Seoul', now())::date를 사용합니다.

❌ 금지 예시:
-- UTC 기준 날짜가 반환되어 KST와 하루 차이 발생 가능
SELECT * FROM invoices WHERE date = CURRENT_DATE;

-- 잘못된 패턴
WHERE date BETWEEN CURRENT_DATE - INTERVAL '30 days' AND CURRENT_DATE;

✅ 허용 예시:
-- KST 기준 날짜 사용
SELECT * FROM invoices
WHERE date = (timezone('Asia/Seoul', now()))::date;

-- KST 기준 기간 조회
WHERE date BETWEEN
  (timezone('Asia/Seoul', now()) - INTERVAL '30 days')::date
  AND (timezone('Asia/Seoul', now()))::date;

[불변 규칙] 앱 레이어에서 KST 기준 날짜를 계산해서 파라미터로 넘기는 것이 더 안전합니다.

서비스 레이어 예시:

// services/billing-service.ts
import { toKST } from '@lib/date-utils';

export async function getMonthlyInvoices(tenantId: string, monthKst: string) {
  // KST 기준 날짜를 앱 레이어에서 계산
  const startDate = toKST(`${monthKst}-01`).startOf('month').toDate();
  const endDate = toKST(`${monthKst}-01`).endOf('month').toDate();

  return withTenant(
    supabase
      .from('invoices')
      .select('*')
      .gte('date', startDate.toISOString().split('T')[0])
      .lte('date', endDate.toISOString().split('T')[0]),
    tenantId,
  );
}

19-1-3. KST 기준 영업일 처리 (Critical)

⚠️ 중요: 수납·출결·정산 등에서 "영업일 0시~24시"로 쪼개는 경우는 문서에 명시합니다.

영업일 기준 처리 예시:

// services/attendance-service.ts
import { toKST } from '@lib/date-utils';

export async function getTodayAttendance(tenantId: string) {
  // KST 기준 오늘 0시 ~ 23:59:59
  const todayKst = toKST().startOf('day');
  const tomorrowKst = toKST().add(1, 'day').startOf('day');

  return withTenant(
    supabase
      .from('attendance_logs')
      .select('*')
      .gte('occurred_at', todayKst.toISOString())
      .lt('occurred_at', tomorrowKst.toISOString()),
    tenantId,
  );
}

→ 영업일 기준 처리는 반드시 KST 기준으로 계산하여 UTC로 변환 후 쿼리합니다.

DB-level constraint 예제 (참고용):

```sql
-- KST 기준 날짜 검증을 위한 CHECK 제약조건 예시 (참고용)
CREATE TABLE analytics.daily_metrics (
  tenant_id uuid NOT NULL,
  date date NOT NULL,
  total_revenue numeric,
  -- date는 항상 KST 기준이어야 함 (UTC 변환 후 저장)
  -- 타입 캐스팅을 명시적으로 처리 (date vs date 비교)
  CONSTRAINT chk_date_valid CHECK (
    date >= DATE '2020-01-01'
    AND date <= (timezone('Asia/Seoul', now()))::date + INTERVAL '1 day'
  )
);

⚠️ 주의: 위 CHECK 제약조건은 참고용 예시입니다.

⚠️ 주의: CHECK 제약조건은 최소한으로 사용하고, KST 기준 검증은 애플리케이션/배치 레이어에서 처리하는 것을 권장합니다.

→ 실제 DB timezone 세팅이 UTC일 때 CHECK 제약조건이 예상과 다르게 동작할 수 있으므로, 운영 시에는 애플리케이션 레이어에서 KST 기준 검증을 수행합니다.
```

표현

React 전역 DateTimeProvider에서 KST로 변환

import dayjs from 'dayjs';
import utc from 'dayjs/plugin/utc';
import tz from 'dayjs/plugin/timezone';

dayjs.extend(utc);
dayjs.extend(tz);
dayjs.tz.setDefault('Asia/Seoul'); // KST

export const toKST = (d: string | Date | number) =>
  dayjs(d).tz('Asia/Seoul');

배치/크론

Supabase cron 등은 내부적으로 UTC 기준이지만,
문서/설정 주석/대시보드에서는 항상 **“매일 04:00 KST”**처럼 KST 기준으로 명시.

19-2. 멀티테넌트 RLS 가드레일
기본 규칙

모든 도메인 테이블은:

tenant_id NOT NULL

tenant_id 인덱스

RLS ENABLE

POLICY는 SELECT/INSERT/UPDATE/DELETE 전부에 tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid 조건 (표준 패턴 3-2 참조)

예시:

ALTER TABLE public.students ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_students ON public.students
FOR ALL TO authenticated
USING (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
)
WITH CHECK (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
);

→ NULLIF(current_setting(..., true), '') 패턴 사용 (3-2 참조)

→ 위 예시는 3-2의 표준 RLS 패턴 템플릿과 동일한 패턴을 따른다.

Edge Function에서 tenant 설정
SELECT set_config('app.current_tenant_id', :tenant_id::text, true);


주의

클라이언트에서 전달한 tenant_id는 신뢰하지 않고 서버에서 재계산/검증.

VIEW/MATERIALIZED VIEW, SECURITY DEFINER 함수가 RLS를 우회하지 않도록 주의.

집계 / Export 용 우회 정책은 별도 부록으로 분리해 명시.

19-3. 인증/권한 & SUPER-ADMIN 보안
일반 사용자

Supabase Auth 사용

비밀번호 정책(길이/복잡도)

로그인 실패 횟수 제한, 일정 시간 잠금

SUPER-ADMIN (본사 콘솔)

MFA 필수

가능하다면 SSO(IdP 연동)

세션 TTL 12시간, 비활동 30분 후 자동 로그아웃 (KST 기준)

고위험 액션(대량 청구, 데이터 export)은 재인증 요구

Public Gateway 인증 정책:

Public Gateway는 로그인 없이 접근 가능한 공개 페이지이므로 MFA/SSO는 적용하지 않는다.

대신 signed token 기반 접근 제어와 Verification Gateway Pattern을 사용한다 (14-3-1 참조).

→ Admin Console과 Public Gateway는 서로 다른 인증 체계를 사용

19-4. Webhook 보안(알림뱅킹/PG)

고정 전용 엔드포인트 사용

예: /hooks/alimbank

TLS + IP 화이트리스트(가능 시)

서명 검증(HMAC or 공개키)

의사 코드:

const sig = req.headers['x-signature'];
const ts  = req.headers['x-timestamp'];  // ISO / epoch

assert(within5MinKST(ts)); // KST 기준 ±5분 윈도우

const expected = hmacSHA256(secret, ts + rawBody);
if (!timingSafeEqual(sig, expected)) throw new Error('Invalid signature');


멱등성 키

idempotency-key 헤더로 중복 요청 방지

로그

성공/실패/재시도 이벤트를 audit 스키마에 기록 (KST 시각 함께 저장/표시)

19-5. 키/비밀 관리 & 회전

Supabase Service Role Key:

절대 프론트 코드에 포함 금지

Edge Functions/Supabase Server-side에서만 사용

비밀은 Supabase Secrets 또는 CI/CD 시크릿에 저장

키 회전 정책:

분기(3개월) 1회

회전 시간 예: 매 분기 첫째 달 01일 02:00 KST

Git 리포지토리에 비밀이 커밋되지 않도록 스캐너 도입

19-5-1. Service Role Key 최소 권한 원칙(Least Privilege) (Phase 2+ 전용)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

MVP/Phase 1에서는 단일 Service Role Key로 단순화 가능하며, 보안상 우수하지만 초기에는 부담이 클 수 있습니다.

문제점: 모든 Edge Function이 하나의 Super Key를 사용하면 보안 리스크 증가

해결책: 기능별로 최소 권한 원칙 적용 (Phase 2+)

기능별 Role 분리 예시:

payment-webhook role → payments 테이블만 write 권한

billing-batch role → invoices, invoice_items만 write 권한

analytics-role → analytics schema만 read/write 권한

admin-role → 특정 테이블 read only 권한

→ MVP에서는 단일 Service Role Key를 사용하고, Phase 2+에서 Role 분리를 도입합니다.

19-5-1-1. Service Role 권한 매트릭스 및 적용 예시 (Critical)

각 Role의 테이블·권한 정의:

Role 이름	권한 범위	허용 작업
payment_webhook_role	payments 테이블	INSERT, UPDATE (status, paid_at만)
billing_batch_role	invoices, invoice_items 테이블	INSERT, UPDATE, SELECT
analytics_role	analytics 스키마 전체	SELECT, INSERT, UPDATE
public_gateway_role	invoices, payments (read only)	SELECT만
admin_readonly_role	모든 테이블 (읽기 전용)	SELECT만

Edge Function 배포 시 Role 적용 방법:

Supabase UI에서 Role 생성: Database → Roles → Create Role

각 Role에 GRANT 권한 부여:

```sql
-- 예: payment_webhook_role 생성 및 권한 부여
CREATE ROLE payment_webhook_role;
GRANT INSERT, UPDATE ON payments TO payment_webhook_role;
GRANT USAGE ON SCHEMA public TO payment_webhook_role;
```

Edge Function에서 Role 사용:

```typescript
// supabase/functions/payment-webhook/index.ts
const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.PAYMENT_WEBHOOK_ROLE_KEY! // 해당 Role 전용 Key
);
```

RLS 우회 시 허용 범위 제한:

SECURITY DEFINER 함수는 반드시 tenant_id 필터링을 강제해야 함

statement_timeout, row limit 설정 필수

모든 RLS 우회 쿼리는 audit.events에 기록

예시 구조:

fns-payment-alimbank-webhook → payment_webhook_role (payments 테이블만 write)

fns-daily-metrics-aggregation → analytics_role (analytics schema만 read/write)

fns-billing-batch → billing_batch_role (invoices, invoice_items만 write)


→ 기능별 DB Role 분리 + 해당 Role 자격증명을 Edge Function에만 주입하는 방식으로 최소 권한 원칙 적용

19-5-2. PII 암호화 키 회전 절차 (Phase 3+ 전용)

⚠️ 중요: 이 섹션은 Phase 3 (고급 보안) 이상에서만 도입하는 기능입니다.

MVP/Phase 1-2에서는 Supabase Secret만으로 충분하며, 키 회전은 "향후 금융인증 필요 시"로 연기합니다.

문제점: 금융/교육 데이터 처리에서 키 회전은 법적 수준의 요구사항이지만, 초기 단계에서는 부담이 큽니다.

KMS 사용 명시 (Phase 3+):

AWS KMS, GCP KMS, 또는 Supabase Vault 사용

키 버전 관리, 키 폐기, 회전 계획 포함

회전 절차:

Step 1: 새 키 버전 생성 (key_version = 2)

Step 2: 데이터 decrypt → re-encrypt (배치 작업)

Step 3: key_version 컬럼 업데이트

Step 4: 이전 키 버전 폐기 (보관 기간 후)

회전 스케줄 예시:

매년 1월 1일 03:00 KST

KMS 정책: Admin Read Only, Rotation 다중 승인(2FA)

회전 시 데이터 마이그레이션:

-- 배치 스크립트 예시
UPDATE guardians
SET email_enc = encrypt_new_key(email_enc, old_key_version, new_key_version),
    key_version = 2
WHERE key_version = 1;


→ 금융/교육 데이터 처리 시 필수 요구사항이지만, Phase 3 이상에서만 도입합니다.

→ MVP에서는 마스킹(이름/전화번호 일부만 노출) + 기본 서버측 암호화(storage)로 충분합니다.

19-6. PII 데이터 분류·암호화·마스킹
PII 카탈로그 예시

이름

전화번호

이메일

집/직장 주소

결제 관련 식별자(카드 식별 토큰, 계좌번호 일부)

암호화

⚠️ 중요: pgcrypto는 Supabase에서 가급적 사용 금지

이유:

pgcrypto는 CPU 비용 비싸고 Partial Search 불가

전화번호/이메일 검색을 hash로 처리하려고 했으나 pgcrypto + 해시 혼합은 관리 복잡 증가

현대 SaaS에서는 AEAD/Envelope Encryption을 App Layer에서 수행하는 것이 정답

→ 민감 필드는 애플리케이션 레벨 AEAD 사용 (pgcrypto 사용 금지)

암호화 키는 Supabase Secret/KMS에 저장

19-6-1. PII App-Level AEAD 암호화 정책 (Phase 3+ 전용)

⚠️ 중요: 이 섹션은 Phase 3 (고급 보안) 이상에서만 도입하는 기능입니다.

MVP/Phase 1-2에서는 마스킹(이름/전화번호 일부만 노출)만으로 충분합니다.

PII 필드 AES-GCM + key_version + hash 인덱스 구조는 금융기관 급 수준이며, 학원/매장 SaaS 초기에는 굳이 필요 없습니다.

Phase 3+ 도입 시 구조:

ALTER TABLE guardians
  ADD COLUMN email_enc bytea NOT NULL,
  ADD COLUMN email_last4 text,
  ADD COLUMN key_version smallint DEFAULT 1;

PII 검색 전략:

검색키 컬럼 분리(해시/토큰) + 원문 AEAD:

-- 예: guardians
email_enc  bytea NOT NULL,
email_sha  bytea,  -- 애플리케이션에서 복호화 결과를 SHA-256 해시하여 저장
phone_hash bytea;  -- 애플리케이션에서 전화번호를 정규화 후 SHA-256 해시하여 저장

CREATE INDEX ON guardians (email_sha);
CREATE INDEX ON guardians (phone_hash);

해시 생성 방법 (SHA-256 통일):

애플리케이션에서 복호화된 이메일을 lower() 처리 후 SHA-256 해시하여 email_sha에 저장

애플리케이션에서 전화번호를 숫자만 추출(regexp_replace) 후 SHA-256 해시하여 phone_hash에 저장

→ 모든 PII 검색키는 SHA-256 알고리즘을 사용하여 일관성 보장

→ 전화/이메일 검색 시 해시 기반 인덱스 활용, 원문은 암호화 유지

백업 정책:

암호문만 포함, 키는 KMS에 별도 보관

백업 파일은 서버측 암호화 + 접근 로깅

DB 에는 암호문만 저장

복호화 : Edge 또는 App Layer 에서만 수행

키 : Supabase Secret 또는 외부 KMS 관리

운영자(DBA) 평문 접근 불가

→ MVP에서는 마스킹만으로 충분하며, AEAD 암호화는 Phase 3 이상에서 도입합니다.

마스킹

목록/로그/대시보드에는 마스킹된 값만 노출

예시:

export const maskPhone = (s: string) =>
  s.replace(/(\d{3})\d{4}(\d{4})/, '$1****$2');

export const maskEmail = (e: string) =>
  e.replace(/(^.).*(@.*$)/, '$1***$2');

19-7. 감사 로그(audit 스키마) & 모니터링
audit 스키마 테이블 예시
CREATE TABLE audit.events (
  id bigserial primary key,
  tenant_id uuid,
  user_id uuid,
  action text,              -- 'read', 'update', 'delete', 'export' ...
  resource text,
  resource_id text,
  occurred_at timestamptz,  -- UTC
  meta jsonb
);


중요 조회(read), 수정(update), 삭제(delete), export, 권한 변경 등 기록

대시보드에서는 occurred_at을 KST로 변환하여 보여줌

19-7-1. analytics/audit 스키마 RLS 정책 (Critical)

analytics.daily_metrics, analytics.monthly_revenue:

기본: RLS ENABLE + tenant_id 기준 격리

일반 테넌트는 자기 tenant_id만 조회 가능

Super Admin용 role만 cross-tenant 조회 허용

analytics.events:

기본: RLS ENABLE

일반 테넌트는 자기 tenant_id만 조회 가능 (있다면)

Heavy 집계용 Security Definer 함수는 별도 섹션 규칙 준수

audit.events:

기본: RLS OFF 또는 관리자 전용 role만 SELECT 허용

운영자/감사 목적으로만 접근 가능

테넌트별 접근이 필요한 경우 별도 정책 추가

→ analytics/audit 스키마의 보안 전략을 명시적으로 정의

보존/파기 정책

일반 audit: 1년 보존

결제/정산 관련: 3년 보존

파기 배치:

매월 1일 03:00 KST에 오래된 로그 삭제

19-8. Public Gateway/키오스크 보안

CSRF 방어(POST 요청에 CSRF 토큰 사용)

XSS 방지(템플릿 인코딩, CSP)

Clickjacking 방지:

X-Frame-Options: DENY 또는

iframe 필요 시 Content-Security-Policy: frame-ancestors 'self'

Referrer 최소화:

Referrer-Policy: no-referrer

세션/토큰 수명 짧게 유지

키오스크 모드:

일정 시간 무입력 시 자동 잠금 (예: 10분, KST 기준)

잠금 해제 시 PIN/관리자 인증

19-9. 레이트 리밋 & 이상 탐지
레이트 리밋 대상

로그인

비밀번호/인증 코드 전송

결제 요청

Webhook 엔드포인트

구체적 Rate Limiting 정책:

로그인:

IP당 로그인 실패 5회/10분 → 추가 시도 제한

IP당 로그인 성공 20회/시간 → 추가 시도 제한

비밀번호/인증 코드 전송:

IP당 3회/10분 → 추가 시도 제한

테넌트별 10회/시간 → 추가 시도 제한

결제 요청:

테넌트별 30회/분 → 일시 제한 (429 응답)

Burst 허용: 최대 50회/분 (짧은 시간 윈도우)

Webhook 엔드포인트:

Provider별 1000회/분 → 추가 요청 대기열 처리

IP당 100회/분 → 의심 IP 차단

API 엔드포인트별:

일반 API: 테넌트별 1000회/분

Export API: 테넌트별 10회/시간

Import API: 테넌트별 5회/시간

구현:

Edge Middleware 또는 API Gateway에서 Rate Limiting 적용

Redis 기반 카운터 사용

Rate Limit 초과 시 429 Too Many Requests 응답

→ 운영 안정성을 위한 필수 정책

이상 탐지

결제 실패 비율 급증

특정 테넌트에서의 비정상 출결 폭주

비정상 수의 export 요청

이상 감지 시:

Slack/이메일/문자 알림

알림 내용에 KST 시간과 테넌트/사용자 정보 포함

19-10. 개인정보 라이프사이클
수집

서비스에 필수적인 정보만 수집

이용

약관/정책에서 정의한 목적 내에서만 사용

보존/파기

학생 정보, 결제 정보 등 항목별 보존기간 정책 수립

만료 데이터 파기 배치:

매일 02:30 KST 실행

내보내기/삭제 요청 처리

사용자 또는 테넌트가 요청 시:

해당 테넌트 범위에서 데이터 export/삭제 수행

audit.events에 기록 (KST 시각과 함께)

국외 이전 동의 관리:

⚠️ 주의: 아래는 외부 PostgreSQL 솔루션을 사용하여 Multi-Region을 구성한 경우에만 해당됩니다.

Supabase 단독 사용 시에는 Cross-Region 복제가 불가능합니다 (PART 1의 "Supabase Multi-Region 제약 요약" 섹션 참조).

외부 DB 솔루션 사용 시: 데이터가 Secondary Region 등 국외 인프라로 복제될 수 있는 경우, 최초 가입 시 국외 이전 동의 플로우(체크박스 + 약관 링크)를 제공하고, 동의 여부와 시각(KST)을 audit.events에 기록한다.

동의 로그 저장:

CREATE TABLE audit.data_transfer_consents (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid,
  user_id uuid,
  consent_type text,  -- 'overseas_transfer', 'secondary_region' 등
  consented boolean,
  consented_at timestamptz,  -- UTC 저장, 표시는 KST
  ip_address text,
  user_agent text
);

→ 법무/컴플라이언스 관점의 필수 요구사항

19-11. 보안 체크리스트 (운영 전 필수 점검)

 모든 도메인 테이블: tenant_id NOT NULL, 인덱스, RLS ENABLE

 RLS 규칙: tenant_id 조건 검사 (표준 패턴 3-2 참조)
   - 옵션 1 (권장): tenant_id = (auth.jwt() -> 'tenant_id')::uuid (Transaction Pooling 호환)
   - 옵션 2: tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid (Session Pooling 또는 전용 커넥션 전용)

 Service Role Key 프론트 미노출, Edge Functions에서만 사용

 Webhook 서명/HMAC 검증, 타임 윈도우(KST 기준), 멱등성 처리 완료

 Public Gateway/키오스크: CSRF/CSP/Frame 방어 적용

 PII 카탈로그 정의, 암호화 & 마스킹 로직 구현

 audit 스키마 이벤트 로깅, 보존/파기 배치 설정

 SUPER-ADMIN 콘솔: MFA/SSO/세션 타임아웃 설정

 레이트 리밋 및 이상 탐지 규칙 구현

 모든 배치/크론/리포트 스케줄 문서에 “KST 기준 시각” 명시

📘 PART 6
Tenant Custom Domain Mapping

20. 개요

이 모듈은 학원·매장 등 각 테넌트가 원하는 개별 도메인을 연결해
자기 브랜드의 독립 SaaS처럼 사용할 수 있게 한다.

예시:

myacademy.dearsaas.com (기본 서브도메인)

academy-blue.com (고객이 등록한 자체 도메인)

pay.academy-blue.com (결제용 커스텀 도메인)

커스텀 도메인은 Vercel + Supabase 조합에서 DNS → 라우팅 → 테넌트 매핑 → RLS 순으로 동작한다.

21. 핵심 구조
21-1. 필요 테이블: tenant_domains
CREATE TABLE public.tenant_domains (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id uuid NOT NULL,
  domain text NOT NULL,            -- customers domain, e.g. 'www.abcacademy.com'
  is_primary boolean DEFAULT false,
  status text NOT NULL DEFAULT 'pending',
  verified_at timestamptz,
  created_at timestamptz DEFAULT now(),
  UNIQUE(domain)
);

⚠️ 중요: tenant_domains.domain은 항상 소문자로 normalize 후 저장해야 합니다.

DNS 입력은 대소문자 구분이 없지만, 문자열 비교는 구분하기 때문에 충돌 가능성이 있습니다.

예시:
- 입력: 'WWW.ABCACADEMY.COM' → 저장: 'www.abcacademy.com'
- 입력: 'www.AbcAcademy.com' → 저장: 'www.abcacademy.com'

→ 도메인 등록/조회 시점에 toLowerCase()를 적용하여 일관성을 보장합니다.

ALTER TABLE tenant_domains
  ADD CONSTRAINT chk_tenant_domains_status
  CHECK (status IN ('pending','verifying','active','error'));

→ tenants.status와 동일한 패턴으로 데이터 무결성 보장

도메인 충돌 검증:

domain UNIQUE constraint 충돌 시, 기존 테넌트에 속한 도메인이므로 등록 거부.

동일 도메인을 여러 테넌트가 등록하려는 경우:

기존 tenant_domains에 active 상태인 도메인 존재 시 → 등록 거부

pending/verifying 상태인 도메인도 충돌로 간주하여 등록 거부

21-1-2. tenant_domains UNIQUE 제약 충돌 처리 규칙 (Critical)

기존 테넌트 소유 도메인과 충돌 시:

UI에서 명확한 error message 표시: "이 도메인은 이미 다른 테넌트에서 사용 중입니다."

대기중(pending) 상태 도메인 자동 제거 정책:

pending 상태로 7일 이상 유지된 도메인은 자동으로 'abandoned' 상태로 변경

abandoned 상태 도메인은 30일 후 자동 삭제 (또는 수동 정리)

충돌 검증 로직:

```sql
-- 도메인 등록 시 충돌 검증
SELECT COUNT(*) FROM tenant_domains
WHERE domain = :domain
  AND status IN ('pending', 'verifying', 'active');
-- 결과가 0이 아니면 등록 거부
```

21-1-1. tenant_domains RLS 규칙 (Critical)

ALTER TABLE public.tenant_domains ENABLE ROW LEVEL SECURITY;

-- 일반 테넌트: 자기 것만 조회
CREATE POLICY tenant_domains_isolation ON public.tenant_domains
FOR ALL TO authenticated
USING (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
)
WITH CHECK (
  tenant_id = NULLIF(current_setting('app.current_tenant_id', true), '')::uuid
);

-- SUPER-ADMIN 롤: 전체 조회 허용 (별도 역할 전제)
CREATE POLICY tenant_domains_superadmin ON public.tenant_domains
FOR SELECT TO role_superadmin
USING (true);

→ 다른 테넌트 도메인을 못 보게 막는 보안 정책

→ role_superadmin은 기본적으로 SELECT 전용이며, UPDATE/DELETE는 별도 수동 SQL/운영 절차로만 수행한다. 필요 시 role_superadmin에 UPDATE/DELETE용 별도 POLICY를 추가할 수 있다.

상태값 정의
status	의미
pending	DNS 아직 검증 전
verifying	DNS 검증 진행 중
active	사용 가능
error	인증 문제 발생
22. DNS 요구사항 (고객 안내)

22. DNS 요구사항 (고객 안내)

22-1. Custom Domain DNS Propagation 지연 고려사항 (Critical)

Custom Domain 활성화 후 DNS Propagation은 수분~최대 1시간까지 지연될 수 있으며, 이 동안 SSL 발급/라우팅이 일시적으로 실패할 수 있다.

운영 대응:

DNS Propagation 상태 모니터링

SSL 발급 실패 시 자동 재시도 (최대 3회, 10분 간격)

사용자에게 "도메인 설정 완료까지 수분~최대 1시간 소요" 안내

→ 운영자가 당황하지 않도록 반드시 명시해야 함

📘 PART 7
Custom Domain 운영 가이드 (Critical)

⚠️ 중요: Custom Domain은 실제 SaaS 운영에서 매우 빈번한 장애 유형이므로, 자동화 및 장애 대응 정책이 필수입니다.

8-1. Custom Domain 수천 개 규모에서 SSL 자동 발급 한계 (Critical)

Vercel은 수천 개 SSL도 가능하지만, 다음 제약사항이 존재:

Let's Encrypt Rate Limit:

도메인당 주당 50개 인증서 발급 제한

Wildcard SSL 불가:

Vercel은 wildcard SSL을 부분 지원하지만, 모든 케이스에서 완벽하지 않음

대량 커스텀 도메인 서비스 정책 변경 가능:

Vercel의 무료 구간 제한 및 유료 플랜 정책 변경 가능성

→ 대규모 도메인 지원 시 Vercel Pro 플랜 필수, 또는 별도 SSL 관리 솔루션 검토 필요

⚠️ 중요: Custom Domain 규모 제한 및 대응 전략

Custom Domain 5,000개 이상 시 다음 위험이 발생할 수 있습니다:

Vercel SSL 발급 한계: Let's Encrypt rate limit 도달 가능

도메인 수가 3,000~5,000개 넘어가면 인증 대기열 길어짐

SSL 발급 지연으로 인한 서비스 중단 가능성

📌 권고: Custom Domain 5,000개 이상 시 자체 SSL 프록시 고려

예: Cloudflare API 기반 자동 인증

또는 별도 SSL 관리 솔루션(예: AWS Certificate Manager, Cloudflare SSL) 도입 검토

→ 운영 단계에서 Custom Domain 수가 증가하면 사전에 SSL 관리 전략을 수립해야 합니다.

고객이 DNS에서 다음 중 하나를 설정:

(A) CNAME 방식 (권장)
www.abcacademy.com → cname.app.dearsaas.com

(B) Apex domain(A 레코드) 필요 시

Vercel의 ALIAS/ANAME 가이드 사용:

abcacademy.com → 76.76.21.21 (Vercel recommended IP)


이후 인증은 자동으로 진행된다.

23. 인증 및 자동 SSL 발급
23-1. 인증 방식

Vercel은 다음 방식으로 도메인 소유권을 자동 검증한다:

DNS TXT record

CNAME 벨리데이션

HTTP challenge 등

등록 흐름:

Admin UI → “커스텀 도메인 연결”

도메인 입력

Vercel API로 domain attach

Vercel이 DNS 상태 확인

SSL 자동 발급

tenant_domains.status = 'active'

24. 런타임 라우팅 구조 (가장 중요)

Next.js Middleware 또는 Edge Middleware에서 실행:

24-1. 요청 도메인 → 테넌트 조회
export async function middleware(req: NextRequest) {
  const host = req.headers.get("host");  // domain

  const tenant = await findTenantByDomain(host);

  if (tenant) {
    // 테넌트 정보를 헤더로 전달
    // 주의: Next.js 13+ 기준으로 req.headers는 불변이므로 새 Headers 인스턴스 생성 필요
    const requestHeaders = new Headers(req.headers);
    requestHeaders.set("x-tenant-id", tenant.id);

    // Supabase API 호출 시 전달
    return NextResponse.next({
      request: { headers: requestHeaders }
    });
  }

  return NextResponse.rewrite("/errors/domain-not-found");
}

24-2. 도메인 → 테넌트 매핑 캐시 레이어 추가

const key = `td:${host}`;
let t = await kv.get(key);
if (!t) {
  t = await db.findTenantByDomain(host); // domain UNIQUE index 전제
  if (t?.status === 'active') await kv.set(key, t, { ex: 180 });
}
if (!t) return rewrite('/errors/domain-not-found');
// 주의: Next.js 13+ 기준으로 req.headers는 불변이므로 새 Headers 인스턴스 생성 필요
const requestHeaders = new Headers(req.headers);
requestHeaders.set('x-tenant-id', t.tenant_id);


Edge KV / Redis 캐시 1차 조회 → DB 폴백

TTL : active 180s / inactive 30s

tenant_domains.domain 컬럼 인덱스 필수

24-3. Middleware domain routing fallback (Optional)

KV·DB 조회 실패 시 기본 도메인으로 degrade

운영 안정성 향상을 위한 fallback 전략:

Step 1: KV 캐시 조회 실패 → DB 조회

Step 2: DB 조회 실패 → 기본 도메인(dearsaas.com)으로 라우팅

Step 3: 기본 도메인에서도 테넌트 식별 불가 시 → 404 에러 페이지

fallback 시 기본 도메인은 항상 app.dearsaas.com 으로 리다이렉트한다. (또는 프로젝트 기본 도메인)

예시 코드:

const tenant = await findTenantByDomain(host)
  || await findTenantByDefaultDomain()
  || null;

if (!tenant) return rewrite('/errors/domain-not-found');

25. Supabase RLS와의 연결

프론트엔드에서 넘어온 x-tenant-id 헤더는 Edge Function에서
⚠️ Deprecated: Edge Function에서 set_config 사용은 더 이상 권장하지 않습니다.

✅ 대신: JWT claim 기반 RLS를 사용하세요 (PART 1의 3-1-1 섹션 참조)

❌ 금지 예시:
```sql
-- Edge Function에서 set_config 사용 (더 이상 사용하지 않음)
SELECT set_config('app.current_tenant_id', :tenantId, true);
```

✅ 권장 예시:
- 프론트엔드에서 넘어온 x-tenant-id 헤더를 검증하여 JWT에 tenant_id를 claim으로 포함
- Edge Function에서 별도 set_config 호출 불필요


→ 결과:
커스텀 도메인으로 접근해도 테넌트 데이터는 완전히 격리됨.

26. 테넌트 설정 연동
테넌트별 설정 구조에서 확장:

tenant_settings 예시:

{
  "domain": "academy.dearsaas.com",
  "custom_domains": [
    "abcacademy.com",
    "www.abcacademy.com"
  ],
  "theme": "dark",
  "brand": {
    "logo": "https://cdn.../logo.png",
    "primary_color": "#0066ff"
  }
}

27. SEO / 퍼블릭 페이지 정책

커스텀 도메인을 사용할 때:

robots.txt 테넌트별 출력

sitemap 테넌트별 자동 생성

OG Image 테넌트별 구성(브랜딩 반영)

모든 설정은 Public Gateway에서도 동일하게 작동한다.

28. 공용 결제 도메인과의 관계

일반적으로 결제/알림뱅킹 처리 페이지는 공용 도메인 사용을 권장한다:

pay.dearsaas.com/invoice/:id


하지만 테넌트가 원한다면 커스텀 도메인으로 결제 페이지도 가능:

예:

pay.abcacademy.com/invoice/123


이 경우도 동일 middleware → tenant_id 로직 적용.

28-1. PG/알림뱅킹 도메인 등록 정책 (Critical)

결제/알림뱅킹 연동 시, PG 측에는 공용 결제 도메인(pay.dearsaas.com)만 등록하고, 커스텀 도메인에서는 Public Gateway → 공용 도메인으로 프록시/리다이렉트하는 형태를 기본으로 한다.

⚠️ 중요: PG(효성FMS 포함)는 "결제 승인/취소/정산 webhook 도메인"도 별도 등록해야 한다.

→ 즉 결제 페이지뿐 아니라 웹훅 endpoint 도메인도 등록 필요

→ 테넌트 개별 도메인 무한정 허용 불가

결제는 반드시 공용 도메인(예: pay.dearsaas.com)으로 고정하는 것이 권장되며, 근거는 "Webhook 도메인은 PG사에 등록되어야 하기 때문"이다.

커스텀 도메인에서 직접 결제 플로우를 열고자 할 경우, PG 측에 추가 도메인 등록 절차가 필요하다.

→ 커스텀 도메인 무한정 증가 시에도 PG 측 관리 부담 최소화

28-2. Supabase Auth Redirect Whitelist 관리 (Critical)

Supabase Auth Redirect Whitelist에는 기본 도메인들(app.dearsaas.com 등)과 커스텀 도메인을 수집하여 주기적으로 동기화한다.

커스텀 도메인 연결 시, Auth Redirect 허용 목록에 자동 반영하는 배치/자동화가 필요하다.

구현:

커스텀 도메인 활성화 시 Edge Function에서 Supabase Auth 설정 API 호출

주기적 동기화 배치: 매일 01:00 KST에 tenant_domains.status = 'active'인 도메인 목록을 수집하여 Auth Redirect Whitelist 업데이트

28-2-1. Custom Domain 동기화/헬스체크/SSL 알람 자동화 (Phase 2+ 전용)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

MVP/Phase 1에서는 수동 모니터링으로 충분하며, Custom Domain 대량화 운영 시에만 자동화가 필요합니다.

Auth Redirect Allowlist 자동 동기화의 실패 복구/이탈 감지 (Phase 2+):

매시간 Vercel Domains ↔ tenant_domains 차집합 검사 → 불일치 시 경고

SSL 만료 알람 임계값:

30일 전 경고 (1차)

7일 전 경고 (2차)

1일 전 경고 (3차, Critical)

도메인 상태 헬스체크:

매일 02:00 KST에 모든 active 도메인 DNS/SSL 상태 확인

실패 시 tenant_domains.status = 'error' 업데이트 및 알림

DNS 전파 지연 UI 배너:

"DNS 전파 지연 중" 표준 컴포넌트 추가 (수분~최대 1시간 표시)

→ Custom Domain 대량화 운영 시 필수 자동화

→ MVP에서는 수동 점검으로 충분하며, Phase 2+에서 자동화를 도입합니다.

29. 커스텀 도메인 활성화 흐름 (전체 시퀀스)
[관리자] 도메인 입력
      ↓
[서버] tenant_domains에 pending 상태로 저장
      ↓
[Vercel API] domain attach 요청
      ↓
[고객 DNS 설정 완료]
      ↓
[Vercel] DNS 확인 → SSL 발급
      ↓
[Vercel] webhook → 시스템
      ↓
[Edge Function] tenant_domains.status = 'active'
      ↓
[middleware] 요청 도메인 → tenant_id 매핑
      ↓
[RLS] 데이터 완전 격리
      ↓
[브랜딩 렌더링] 테넌트 UI/로고 반영된 앱 표시

30. 보안

모든 커스텀 도메인 SSL 자동 발급

Middleware 기반 검증

RLS + tenant_id로 완전 격리

Webhook 서명 검증

로그(Audit)에 도메인 정보 함께 기록

31. 운영/모니터링

모니터링 지표:

도메인 인증 실패 로그

SSL 갱신 여부

커스텀 도메인 트래픽/성능

도메인 → 테넌트 라우팅 실패율

Edge Function에서 도메인 유지보수 배치:

1일 1회, 불필요한 도메인 정리

SSL 만료 30일 전 경고

32. Multi-tenant & Multi-domain 확장성 검증

이 구조는 다음을 지원한다:

테넌트 1개가 서브도메인 + 커스텀 도메인 여러 개 가질 수 있음

테넌트 수가 수만 개여도,

우리 플랫폼 도메인(예: *.dearsaas.com)은 wildcard SSL로 커버 가능하고,

고객 개별 커스텀 도메인은 Vercel + Let's Encrypt의 자동 발급·갱신 기능으로 운영 가능하다.

다만, Let's Encrypt rate limit·Vercel 정책은 실제 도메인 수가 커질수록 반드시 재검토해야 한다.

백엔드 DB는 단일 Supabase 그대로 운영 (변경 없음)

트래픽이 몰리는 페이지는 CDN + Edge 로 분산 처리

📘 PART 8
장애 복구 / 백업·복원 (DR & BCP, Supabase 단일-Primary 기반)

33. Supabase 백업 정책

자동 백업: 매일 1회

보관기간: 7~30일 (플랜에 따라)

PITR(Point-in-Time-Recovery) 지원

장애시 RPO: 최대 5분

RTO 목표: 15~30분

주의: 이 수치는 목표치이며, 실제 Supabase 플랜/계약 및 인프라 구성(멀티리전 옵션, 읽기 replica, connection limit)에 따라 조정될 수 있다.

예: Supabase Pro + Single DB + Single Replica 기준으로 실제 수치가 달라질 수 있음

33-1. RTO 계산 근거 및 검증 (Critical, 중장기 목표)

⚠️ 중요: 이 섹션의 DR 훈련은 중장기 목표입니다.

Phase 1에서는 문서 수준 설계 및 간단한 복원 테스트에 국한하고, 실제 분기별 DR Drill은 운영 조직이 갖춰지는 Phase 3 이후부터 수행합니다.

RTO 15~30분 목표 달성을 위한 각 단계별 예상 소요 시간:

DNS TTL: 1~5분 (Cloudflare Failover DNS)

Primary Region 장애 감지 시간: 2~3분 (Health Check 주기)

Secondary Promote-to-Primary 시간: 5~10분 (Supabase 내부 프로모션)

Supabase 내부 replication lag 해소: 3~5분

애플리케이션 레이어 재시작/라우팅 전환: 2~5분

총 예상 시간: 13~28분 (목표 범위 내)

결제 서비스 RTO는 5~10분, 나머지 비핵심 서비스는 15~30분을 목표로 한다.

DR 훈련 주기 (Phase 3+):

분기별 1회 DR 훈련 (실제 Failover 시뮬레이션)

연 1회 전체 Region 장애 시나리오 테스트

DR 테스트는 분기별 1회 정기 수행하며, 실제 Failover/Failback 시나리오를 모의 실행하여 RTO/RPO 목표 달성 여부를 검증한다.

분기 1회 전체 DR 훈련 외에, 34-0에서 기술한 '월 1회 미니 드릴(읽기 전용 전환 테스트)'을 함께 수행한다.

테스트 검증 항목:

DNS TTL이 실제로 이론과 다르게 동작하는지 확인

Region Promote-to-Primary 시간의 재현성 검증

Secondary Region 구성 요소와 Supabase 구성의 "숨은 의존성" 확인

애플리케이션 레이어의 환경변수/라우팅 전환이 문제없이 이루어지는지 검증

RTO 검증 프로세스:

매 훈련마다 실제 RTO 측정 및 기록

목표 대비 차이 발생 시 개선 계획 수립

→ Failover/Failback 시나리오의 실제 모의 훈련이 있어야 RTO/RPO는 현실이 됩니다.

→ Phase 1에서는 문서 수준 설계 및 간단한 복원 테스트에 국한합니다.

34. Region 장애 대비 (Phase 3+ 전용)

⚠️ 중요: 이 섹션은 Phase 3 (20k+ 테넌트) 이상에서 검토하는 기능입니다.

Phase 1-2에서는 단일 리전 운영으로 충분하며, Multi-Region DR은 현실적으로 운영 불가합니다.
→ Phase 3에서는 외부 DB(Aurora/Neon) 기반 Multi-Region DR 도입을 검토합니다.
→ Phase 4에서는 Multi-Region + 샤딩 통합 구조를 검토합니다 (현재 사업 목표를 넘어서는 초과 성장 시나리오).

아래 시나리오는 외부 PostgreSQL 솔루션(Neon, AWS RDS, Aurora)을 사용하는 경우에만 적용 가능합니다.

Supabase 단독 사용 시에는 Multi-Region DR이 불가능합니다 (PART 1의 "Supabase Multi-Region 제약 요약" 섹션 참조).

외부 DB 솔루션 사용 시나리오 (초대형 확장 단계 예시):

Primary Region: ap-northeast-2

Secondary Region: ap-southeast-1 (외부 DB 솔루션)

Read Replica 기반 Hot-Standby

Region 장애 시 운영팀이 수동으로 Failover를 트리거하면, Cloudflare + Failover DNS가 자동으로 트래픽을 새 Primary Region으로 전환한다.

→ DNS 전환은 자동이지만, DB Promote-to-Primary는 수동이며, 전체 DR 프로세스는 Semi-automated이다.

→ 초기 단계에서는 이 구조를 구현하려 하면 비용이 10배 증가하고 운영 난이도가 매우 높아집니다 (SRE 팀 필요).

→ MVP/Phase 1-2에서는 단일 리전 + 기본 백업/복원만으로 충분합니다.

34-0. Supabase Multi-Region DR 한계 명시 (Critical)

⚠️ 중요: Supabase는 Region 간 Active-Active 구조를 제공하지 않으므로, Failover는 자동이 아닌 "운영팀이 트리거하는 수동 프로세스"이다. DR 시나리오는 Semi-Automated이며 완전 자동 전환은 불가능하다.

→ 상세 제약사항은 PART 1의 "Supabase Multi-Region 제약 요약" 섹션 참조

→ Multi-Region DR이 필요한 경우 외부 PostgreSQL 솔루션(Neon, AWS RDS, Aurora) 사용 필수

DR 훈련:

월 1회 미니 드릴(테이블 읽기 전용 전환 + 복귀) 추가 권장

→ 경영진의 오해·위험한 기대치를 방지하기 위해 반드시 명시해야 함

34-1. Second Region 복제 시 개인정보 국외 이전 리스크 (Critical - Legal)

문제점: 한국에서 학생 정보, 결제 정보, 기본 신상 PII는 "국외 이전 동의" 필요

PII 복제 범위 정책:

⚠️ 주의: 아래는 외부 PostgreSQL 솔루션을 사용하여 Multi-Region을 구성한 경우에만 해당됩니다.

Supabase 단독 사용 시에는 Cross-Region 복제가 불가능합니다 (PART 1의 "Supabase Multi-Region 제약 요약" 섹션 참조).

외부 DB 솔루션 사용 시:

옵션 1: Secondary Region에는 비민감 데이터만 복제

옵션 2: 처음 가입 시 "데이터 국외 이전 동의" 체크박스 필수

권장 정책:

Secondary Region 복제 대상:

허용: 비민감 메타데이터, 집계 통계, 로그(개인정보 제외)

제한: PII(이름, 전화번호, 이메일, 주소)는 Primary Region에만 저장

또는: 사용자 동의 시에만 Secondary Region 복제 허용

법적 요구사항:

개인정보보호법 준수

국외 이전 시 고지 및 동의 절차 필수

Secondary Region 위치에 따른 추가 규제 확인 (GDPR 등)

35. Edge Function 장애 대응

35-1. Webhook Queue 재처리 절차 (Critical)

Webhook 처리 실패 시 재처리 전략:

Step 1: 실패한 Webhook을 재처리 큐에 추가

Step 2: 재시도 스케줄 적용 (5s → 30s → 2m → 10m → 30m, 최대 5회)

Step 3: 최대 재시도 횟수 초과 시 Dead Letter Queue(DLQ)로 이동

Step 4: DLQ에 쌓인 Webhook은 수동 조사 및 재처리

구현:

audit.webhook_events 테이블에 상태 추적

재처리 스크립트: 매시간 실행하여 실패한 Webhook 재시도

DLQ 모니터링: DLQ 크기 증가 시 즉시 알림

35-2. 결제 reconciliation(정합성 검증) 절차

⚠️ 중요: 결제 정산 불일치 감지 및 조정 상세 정책은 "14-2-1-1. 결제/알림뱅킹 운영 정책" 섹션의 "3. Settlement Mismatch Reconciliation (정산 불일치 조정)" 및 "5. 회계적 정합성 검증"을 참조하세요.

일일 정합성 검증:

매일 04:00 KST에 전날 결제 데이터 정합성 검증

검증 항목:

결제 요청 수 vs Webhook 수 일치 여부

결제 금액 합계 일치 여부

invoice 상태와 payment 상태 일치 여부

불일치 발견 시:

자동으로 audit.events에 기록

Slack/이메일 알림 발송

수동 조사 및 수정 절차 시작

→ 상세 정책은 14-2-1-1 섹션 참조

35-3. Audit 로그 기반 재처리

장애 복구 후 데이터 재처리:

audit.events를 기반으로 누락된 작업 식별

재처리 스크립트 실행

재처리 완료 후 검증

→ 결제 시스템 안정성을 위한 필수 절차

36. 테넌트 단위 복원

특정 테넌트만 Export/Restore 필요 시

→ 테넌트별 Prefix 기반 데이터 추출

36-0. 테넌트 백업/복원 상세 정책 (Critical)

⚠️ 중요: 테넌트 단위 백업/복원은 대규모 운영에서 필수 기능입니다.

백업 범위:

테이블 데이터 (tenant_id 기반 필터링)

RLS 정책 (테넌트별 정책 포함)

Foreign Key 관계 (관련 테이블 포함)

인덱스 (테넌트별 인덱스 포함)

Storage Object (Supabase Storage 파일)

복원 절차:

Step 1: 테이블 데이터 복원
- tenant_id 기반 데이터 추출 및 복원
- Foreign Key 관계 유지
- 트랜잭션 단위로 원자성 보장

Step 2: RLS 정책 복원
- 테넌트별 RLS 정책 확인
- 정책 이름 충돌 방지 (tenant_isolation_<table> 형식 유지)

Step 3: 인덱스 복원
- 테넌트별 인덱스 재생성
- 인덱스 성능 확인

Step 4: Storage Object 복원
- Supabase Storage 파일 복원
- 파일 권한 설정
- 폴더 구조 복원 ({tenant_id}/{module}/{file_id})

Step 5: 데이터 무결성 검증
- Foreign Key 제약조건 확인
- RLS 정책 동작 확인
- 인덱스 성능 확인

복원 시 주의사항:

기존 테넌트 데이터와 충돌 방지 (tenant_id 중복 확인)

RLS 정책 충돌 방지 (정책 이름 고유성 보장)

Storage Object 권한 설정 확인

멱등성 보장 (동일 백업으로 여러 번 복원 가능)

→ 상세 복원 절차는 운영 매뉴얼에 별도 문서화 필요

36-1. DR 복구 후 Backfill 정책 (Critical, Phase 2+ 전용)

Region Failback 시 analytics/daily_metrics는 Backfill 스크립트를 통해 DR 전후 기간의 정합성을 검증한다.

시나리오:

Secondary Region에서 며칠간 운영 후 Primary Region으로 복귀

analytics/events 등 일부 집계 테이블 불일치 가능

Backfill 절차:

Step 1: DR 기간 동안의 이벤트 데이터 재집계

Step 2: daily_metrics, monthly_revenue 정합성 검증

Step 3: 불일치 발견 시 자동 보정 또는 수동 조정

구현:

SELECT analytics.fn_backfill_daily_metrics(
  start_date => dr_start_date,
  end_date => dr_end_date
);

→ 실제 운영에서 반드시 발생하는 문제이므로 필수 정책

36-2. 데이터 마이그레이션 전략 (Critical)

⚠️ 중요: 스키마 변경, 데이터 마이그레이션, DB 버전업은 반드시 체계적인 전략이 필요합니다.

마이그레이션 프로세스:

Step 1: 리뷰 및 계획
- 마이그레이션 스크립트 작성
- 롤백 계획 수립
- 영향 범위 분석 (테이블, 인덱스, RLS 정책)

Step 2: 마이그레이션 스크립트 작성
- SQL 마이그레이션 파일 (예: migrations/20250115_add_region_id.sql)
- 테스트 환경에서 먼저 실행
- 롤백 스크립트 준비

Step 3: 배포 순서
- 개발 환경 → Staging 환경 → Production 환경
- 각 환경에서 검증 후 다음 단계 진행

Zero-downtime 마이그레이션 전략:

옵션 1: 단계적 마이그레이션 (권장)

Step 1: 새 컬럼 추가 (NULL 허용)
ALTER TABLE students ADD COLUMN region_id uuid NULL;

Step 2: 데이터 마이그레이션 (백그라운드)
-- 배치 작업으로 기존 데이터에 region_id 채우기

Step 3: NOT NULL 제약조건 추가 (데이터 마이그레이션 완료 후)
ALTER TABLE students ALTER COLUMN region_id SET NOT NULL;

옵션 2: 테이블 복사 후 교체 (대규모 변경 시)

Step 1: 새 테이블 생성
CREATE TABLE students_new (...);

Step 2: 데이터 복사 (백그라운드)
INSERT INTO students_new SELECT * FROM students;

Step 3: 테이블 교체 (트랜잭션)
BEGIN;
ALTER TABLE students RENAME TO students_old;
ALTER TABLE students_new RENAME TO students;
COMMIT;

마이그레이션 검증:

- 데이터 정합성 검증
- RLS 정책 동작 확인
- 인덱스 성능 확인
- 애플리케이션 동작 확인

롤백 계획:

- 롤백 스크립트 준비
- 롤백 시점 결정 기준
- 데이터 백업 확인

36-3. DB 버전업 전략

⚠️ 중요: PostgreSQL 버전업은 신중하게 계획해야 합니다.

버전업 프로세스:

Step 1: Supabase 공지 확인
- Supabase가 제공하는 버전업 일정 확인
- Breaking changes 확인

Step 2: 테스트 환경에서 검증
- Staging 환경에서 먼저 버전업 테스트
- 애플리케이션 호환성 확인

Step 3: Production 버전업
- 유지보수 시간대에 진행
- 롤백 계획 준비

→ 상세 버전업 절차는 Supabase 공식 문서를 참조합니다.

대규모 스키마 변경 마이그레이션 절차:

Step 1: 사전 검증

Staging 환경에서 마이그레이션 스크립트 테스트

데이터 백업 (PITR 시점 기록)

마이그레이션 예상 소요 시간 측정

Step 2: Zero-downtime 마이그레이션 전략

옵션 1: Dual-write 패턴

기존 컬럼과 새 컬럼 동시에 쓰기

마이그레이션 완료 후 읽기 전환

기존 컬럼 제거 (보관 기간 후)

옵션 2: 점진적 마이그레이션

새 데이터만 새 스키마 사용

기존 데이터는 배치로 점진적 마이그레이션

Step 3: 롤백 계획

마이그레이션 실패 시 즉시 롤백 가능하도록 준비

롤백 스크립트 사전 검증

롤백 시 데이터 손실 최소화 전략

Step 4: 데이터 검증

마이그레이션 후 데이터 무결성 검증

레코드 수 일치 확인

중요 필드 값 일치 확인

비즈니스 로직 검증 (샘플 데이터로 테스트)

마이그레이션 체크리스트:

백업 완료 확인

롤백 스크립트 준비 완료

검증 스크립트 준비 완료

모니터링 대시보드 준비

온콜 엔지니어 대기

→ 운영 안정성을 위한 필수 마이그레이션 절차

📘 PART 9
Data Lifecycle / Storage 비용 최적화

37-0. Supabase Storage 업로드 정책 (Critical, Phase 2+ 권장)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

MVP/Phase 1에서는 파일 크기 제한, 확장자 whitelist, PII 파일 업로드 금지(또는 관리자 전용) 정도까지만 적용합니다.

Storage Virus Scan / PII 파일 암호화는 보안 관점에서 중요하지만, Phase 2 보안 강화 작업으로 미루고, Phase 1에서는 용량/형식 제한 + PII 업로드 최소화만 적용합니다.

디렉토리 구조 표준:

테넌트별 분리: <tenant_id>/<resource_type>/<file_id>

예: {tenant_id}/invoices/{invoice_id}/receipt.pdf

업종별 분리 (선택): <industry_type>/<tenant_id>/<resource_type>/<file_id>

확장자 whitelist:

허용 확장자: .pdf, .jpg, .jpeg, .png, .gif, .xlsx, .xls, .csv

금지 확장자: .exe, .bat, .sh, .js, .html 등 실행 가능한 파일

파일 크기 제한:

일반 파일: 최대 10MB

이미지 파일: 최대 5MB

대용량 파일: 최대 50MB (특수 승인 필요)

Virus scanning (Phase 2+):

⚠️ 중요: Supabase Storage 자체는 Virus scan 없음, Lambda hook 불가, Object-level event trigger 없음

→ Supabase Storage direct upload는 스캔 불가능

해결책: 업로드 → API → 스캔 후 Storage 저장 방식 사용 (Phase 2+)

구현 방법 (Phase 2+):

1. 클라이언트에서 파일을 API 엔드포인트로 업로드

2. API에서 ClamAV 또는 AWS GuardDuty로 스캔

3. 스캔 통과 후 Supabase Storage에 저장

4. 악성 파일 감지 시 즉시 차단 및 알림

→ Phase 1에서는 Supabase Storage direct upload를 허용하되, Phase 2+에서는 반드시 API를 통한 업로드만 허용

개인정보 사진 파일 암호화 (Phase 2+):

PII 포함 파일(신분증, 계약서 등)은 애플리케이션 레벨에서 암호화 후 저장 (Phase 2+)

암호화 키는 Supabase Secret/KMS에 저장

구현 예시 (Phase 2+):

```typescript
// 파일 업로드 전 검증
const allowedExtensions = ['.pdf', '.jpg', '.jpeg', '.png'];
const maxSize = 10 * 1024 * 1024; // 10MB

if (!allowedExtensions.includes(ext)) {
  throw new Error('허용되지 않은 파일 형식');
}
if (file.size > maxSize) {
  throw new Error('파일 크기 초과');
}

// Virus scan (비동기, Phase 2+)
await scanFile(file);

// PII 파일 암호화 (Phase 2+)
if (isPIIFile(file)) {
  const encrypted = await encryptFile(file, keyVersion);
  await uploadToStorage(encrypted);
}
```

→ Phase 1에서는 PII 파일 업로드를 관리자 전용으로 제한하거나 금지합니다.

37. 테이블별 TTL 정책

테이블	TTL	정책
attendance_logs	2년	이후 cold-storage 이동
audit.events	1년	결제 관련은 3년
analytics.events	180일	집계 후 삭제

38. 아카이브 전략

오래된 로그 → Storage(S3) CSV 로 아카이브

검색 필요없는 cold data는 별도 bucket 보관

39. Storage 비용 정책

이미지: WebP 강제

동영상: 720p 제한

Thumbnail 자동 생성 및 원본 자동 파기 정책 옵션

📘 PART 10
Testing 전략 (E2E / Integration / Load Test)

40. RLS 테스트 자동화

tenant_id mismatch → MUST FAIL

app.current_tenant_id 누락 → MUST FAIL (401/403 응답)

tenant 바인딩 누락 시 401/403 케이스 추가

SECURITY DEFINER 함수 → MUST LOG

41. Edge Function 테스트

Webhook signature 테스트

멱등성 재처리 테스트

결제 흐름 end-to-end 테스트

42. Industry Layer 테스트

학원/미용/부동산 모델이 서로 데이터를 침범하면 FAIL

업종별 템플릿/매핑 테스트

43. Load Test 기준

출결 체크 TPS 2000 sustained

결제 webhook 1000 CPM 처리

Multi-domain routing 10,000 RPM 처리

로드 테스트 수집 지표:

pg_connections / pgbouncer stats 동시 수집

RLS 정책 평가 비용 모니터링

쿼리 플랜 캡처 및 분석

43-1. Supabase Scale Limit 기반 현실적 보정

Supabase 제약사항 고려:

Connection limit: 테넌트 수만개 + TPS 2,000 sustained 시 connection pool 관리 필수

CPU: RLS 정책 증가 시 CPU 비용 증가

RLS 비용: 테넌트 수 증가에 따라 RLS 정책 평가 비용 증가

테스트 전략:

로컬 환경에서는 소규모 테넌트(100~1,000개)로 RLS 테스트

대규모 부하 테스트는 Staging 환경에서 실제 Supabase 인스턴스 사용

Connection pool 크기 모니터링 및 튜닝

RLS 정책 최적화 (불필요한 정책 제거, 인덱스 활용)

→ Supabase의 scale limit을 고려하여 현실적인 테스트 전략 수립

📘 PART 11
비용 모델 / Scale-out 기준

44. DB Scale 기준

CPU 70% 이상 지속 → Replica 추가

IOPS 80% 초과 → 파티셔닝 + 쿼리 튜닝

테이블 단일 파티션 100M rows 초과 → 분리

45. Edge Function 비용 최적화

Public Gateway 정적 캐싱

Webhook throttling

업종별 cache layer 적용

📘 PART 12
Observability / 로그 / 지표 / 트레이싱 통합

46. 로그 표준

JSON structured logging

level: debug/info/warn/error/fatal

TraceID: Frontend → Edge → Service → Supabase 로 관통

47. 지표 표준(Metrics)

필수 메트릭:

RLS 실패율

테넌트별 DB 쿼리 QPS

Edge Function latency(p50/p95/p99)

Payment success rate

Domain routing 실패율

캐시 히트율

47-1. 모니터링 알람 임계값 (Critical)

각 메트릭별 경고(Warning) 및 Critical 임계값:

⚠️ **아래 임계값은 예시이며, 실제 운영 환경에서 조정 가능합니다.**

RLS 실패율:

- 경고: **1% 초과** → RLS 정책 점검 필요
- Critical: **5% 초과** → 즉시 조사 및 수정

Edge Function latency:

- 경고: **P95 500ms 초과** → 성능 최적화 검토
- Critical: **P95 1초 초과** → 즉시 조사

Payment success rate:

- 경고: **99% 미만** → 결제 플로우 점검
- Critical: **95% 미만** → 즉시 조사 및 결제 중단 고려

Domain routing 실패율:

- 경고: **0.1% 초과** → 도메인 매핑 로직 점검
- Critical: **1% 초과** → 즉시 조사

캐시 히트율:

- 경고: **80% 미만** → 캐시 전략 재검토
- Critical: **60% 미만** → 캐시 시스템 점검

DB 쿼리 QPS:

- 경고: 테넌트별 평균 **QPS 1000 초과** → 쿼리 최적화 검토
- Critical: 테넌트별 평균 **QPS 5000 초과** → 즉시 조사

알람 채널:

경고: Slack 채널 알림

Critical: Slack + 이메일 + SMS (온콜 엔지니어)

알람 응답 시간:

경고: 1시간 이내 확인

Critical: 15분 이내 조사 시작

→ 운영 안정성을 위한 필수 모니터링 정책

47-2. SLA 목표 (중장기 목표)

⚠️ 중요: 이 섹션은 중장기 목표로, 실제로는 API Gateway + APM 설치가 필요합니다.

초기 SaaS 팀에서는 무리이므로, Phase 2+에서 도입을 검토합니다.

주의: Supabase가 SLA를 제공하지 않기 때문에 이는 플랫폼 내부 운영 목표치이지 외부 보장이 아니다.

⚠️ **아래 수치는 예시 목표치이며, 실제 플랜/시점 기준으로 재검토 필요합니다.**

가용성 목표 (Phase 2+):

- 일반 서비스: **99.9%** (월 43분 다운타임 허용)
- 결제 서비스: **99.99%** (월 4.3분 다운타임 허용) - 결제 핵심 플로우에만 적용

주의: 이 SLA 수치는 목표치이며, 실제 Supabase 플랜/계약 및 인프라 구성에 따라 조정될 수 있다.

API 응답 시간 (Phase 2+):

- 일반 API: **P95 200ms 이하**
- 결제 API: **P95 500ms 이하**
- Export API: **P95 5초 이하** (대용량 데이터)

→ MVP에서는 기본 모니터링만으로 충분하며, SLA 목표는 Phase 2+에서 설정합니다.

데이터 복구 시간:

RPO: 최대 5분 (Point-in-Time Recovery)

RTO: 15~30분 (Recovery Time Objective)

결제 처리:

- 결제 요청 처리: **99.5% 성공률**
- Webhook 처리: **99.9% 성공률** (재시도 포함)

SLA 모니터링:

월별 SLA 달성률 측정 및 리포트

SLA 미달 시 개선 계획 수립

→ 고객 신뢰를 위한 필수 SLA 정책

48. Tracing (중장기 목표)

⚠️ 중요: 이 섹션은 중장기 목표로, 실제로는 API Gateway + APM 설치(Sentry, Datadog, NewRelic 등)가 필요합니다.

초기 SaaS 팀에서는 무리이므로, Phase 2+에서 도입을 검토합니다.

OpenTelemetry 기반

Edge → DB 쿼리 전체 트레이스 ID 연결

→ MVP에서는 기본 로깅만으로 충분하며, Tracing은 Phase 2+에서 도입합니다.

📘 PART 13
캐시 일관성(Cache Invalidation) 정책

49. 캐시 유형

tenant_settings 캐시

tenant_domains 캐시

feature flag 캐시

public-gateway token 캐시

50. invalidation 규칙

설정 업데이트 시:

→ Edge Config / KV 자동 purge

Tenant 전역 변경 시:

→ "tenant::<id>*" prefix purge

50-1. Critical Path 캐시 무효화 (Optional)

플랜 변경·쿼터 변경 등 Critical Path에서 즉시 캐시 무효화 필요:

플랜 변경 시:

tenant_features 캐시 즉시 무효화

해당 테넌트의 모든 feature flag 캐시 purge

50-2. 마스터 데이터 변경 시 업종별 캐시 invalidation 규칙 (Phase 2+ 전용)

⚠️ 중요: 이 섹션은 Phase 2 (1~3k 테넌트) 이상에서 도입하는 기능입니다.

MVP/Phase 1에서는 단순 캐시만으로 충분하며, multi-app 환경에서 캐시 무효화 정책은 Phase 2+에서 도입합니다.

multi-app 환경에서 캐시 무효화 정책이 매우 중요 (Phase 2+):

학생 → Guardian 관계 변경:

guardian::<guardian_id>* 캐시 무효화

student::<student_id>* 캐시 무효화

반(Class) 명 변경:

class::<class_id>* 캐시 무효화

해당 반 학생 목록 캐시 무효화

결제 항목 템플릿 변경:

invoice_template::<template_id>* 캐시 무효화

해당 템플릿을 사용하는 모든 테넌트의 invoice 관련 캐시 무효화

구현 예시:

```typescript
async function invalidateMasterDataCache(type: string, id: string) {
  const patterns = {
    'student': [`student::${id}*`, `guardian::*`],
    'class': [`class::${id}*`, `student::*`],
    'template': [`invoice_template::${id}*`, `tenant::*::invoice*`]
  };

  for (const pattern of patterns[type] || []) {
    await kv.deletePattern(pattern);
  }
}
```

→ MVP에서는 단순 캐시만으로 충분하며, Phase 2+에서 고급 캐시 무효화를 도입합니다.

쿼터 변경 시:

tenant_settings 캐시 무효화

사용량 제한 관련 캐시 즉시 갱신

구현 예시:

// 플랜 변경 시
await invalidateCache(`tenant::${tenantId}::features`);
await invalidateCache(`tenant::${tenantId}::settings`);


→ Critical Path에서의 캐시 일관성 보장

📘 PART 14
CI/CD 정책 & 브랜치 전략

51. 브랜치 전략

main: 안정 배포

develop: 다음 릴리즈

feature/*: 기능 단위

52. 배포 파이프라인

PR → 테스트 자동 실행

Staging 자동 배포

Production 수동 승인

DB migration 검증 후 적용

53. Edge Function 분리 배포

functions/* 단위로 독립 배포

payment-webhook 은 안전하게 수동 승인

📘 PART 15
데이터 Export/Import 정책

54. Export 제공 범위

테넌트 데이터 전체 Export

CSV / Excel 지원

개인정보 항목 암호화 유지

55. Import 정책

동일 Industry Type만 Import 가능

테넌트 간 복제 금지

📘 PART 16
Search Layer (core-search)

56. 검색 방식

Postgres FTS(full-text search)

Trigram index(text similarity 검색)

tenant_id + industry_type 기반 필터

57. 검색 성능 최적화

백엔드 최적화:
- to_tsvector 저장 컬럼화(materialized vector)
- title/description 우선 가중치
- Search log 기반 추천 키워드

프론트엔드 최적화:
- [불변 규칙] SchemaFilter 컴포넌트에서 검색 필드(search, query, keyword 등)는 자동으로 디바운싱(300ms) 적용
- 검색 필드가 아닌 필터(select, date 등)는 즉시 적용
- React Query 캐시 최적화: staleTime 30초, gcTime 5분
- 검색 필드 자동 감지: 필드 이름이 'search', 'query', 'keyword', 'q', 'term'이거나 kind가 'text'이고 이름에 'search'가 포함된 경우

57-1. Full Text Search 외부화 Option (Optional)

Early stage: PostgreSQL FTS로 충분

중장기적: 검색량 증가 시 OpenSearch/Meilisearch 사용 준비

마이그레이션 전략:

PostgreSQL FTS → OpenSearch/Meilisearch 점진적 전환

외부 검색 엔진 전환 기준:

⚠️ **아래 기준은 예시 Threshold이며 실제 운영 환경에서 조정 가능합니다.**

외부 검색 엔진 전환 기준은:
- ① 일일 검색 쿼리 **100만 건 이상**
- ② 검색 응답 **P95 200ms 초과**
- ③ Supabase CPU 사용량의 **60% 이상**이 검색 쿼리인 경우

→ 모든 검색 쿼리는 tenant_id 기반 필터링을 필수로 적용하며, 전체 테넌트 풀스캔 쿼리는 금지

외부화 시 고려사항:

동기화 지연 최소화 (실시간 또는 near-real-time)

tenant_id 기반 인덱스 분리 유지

비용 최적화 (검색량에 따른 스케일링)

📘 PART 17
알림 템플릿 관리 (Template Engine)

58. 버전 관리

템플릿은 versioned 저장:

template_key

version

content

updated_at

59. 업종별 override

"academy.invoice.reminder"

"salon.reservation.confirmation"

60. 미리보기 & 테스트 발송

Dummy 데이터 기반 렌더링

관리자가 즉시 테스트 발송 가능

---

📘 PART 18
Phase별 구현 요약 및 검증 체크리스트

61. Phase별 핵심 기능 요약

Phase 1 (MVP, 100~300 테넌트) - 필수 기능:

✅ 멀티테넌트 RLS 모델 (tenant_id + NULLIF 패턴)
✅ Billing/Payments/알림뱅킹 (멱등성 + 서명 검증)
✅ Public Gateway Token 검증
✅ 커스텀 도메인 기본 기능 (수동 관리)
✅ 기본 Analytics (Supabase Edge Function)
✅ 지역 기반 통계 (기본 기능: 지역순위, 지역 평균 대비 비교, 기본 히트맵)
✅ AI 분석 기능 (기본 인사이트: 상담일지 요약, 출결 이상 탐지, 기본 리포트)
✅ 기본 모니터링/알람
✅ 기본 DR/백업 정책

❌ 제외 항목 (MVP/Phase 1에 절대 들어가면 안 됨):

- PII AEAD 암호화 + 키 회전
  → Phase 3에서만 필요
  → 모바일 학원 SaaS 수준에서는 초기 필요 없음

- Shard 재조정 / 자동 샤딩
  → 대기업/수십만 테넌트 규모에서나 필요
  → Phase 4 이상에서만 검토

- Multi-Region DR
  → Supabase 단일 프로젝트에서는 불가능
  → 외부 DB 사용 시에만 의미 있음
  → Phase 3에서 외부 DB 기반 DR 도입, Phase 4에서 Multi-Region + 샤딩 통합 구조 검토

- CDC 기반 샤딩 자동화
- WebAuthn/Passkey
- 외부 검색 엔진
- 이중 파티셔닝
- Webhook Ordering Guarantee (멱등성만)
- Tracing + SLA 목표 (기본 모니터링만)

→ 이들이 Phase 3~4에 배치되어 있으므로 문서 전체로는 문제 없음.

Phase 2 (1~3k 테넌트) - 확장성 기능:

✅ Analytics 외부 워커 (Lambda/Workers)
✅ Edge Function Role 분리
✅ Custom Domain 자동화 (헬스체크, SSL 알람)
✅ Critical Path 캐시 무효화
✅ 마스터 데이터 변경 시 캐시 invalidation
✅ PII 마스킹 강화
✅ 지역 기반 통계 고급 기능 (고급 히트맵, 다중 지역 비교, AI 인사이트 고도화)
✅ 지도 기반 매장 분포 시각화 (고급)

Phase 3 (20k+ 테넌트) - 대규모 최적화:

✅ Hot Tenant 수직 분리 (수동)
✅ PII AEAD 암호화
✅ KMS 키 회전
✅ 업종별 스키마 분리 검토
✅ 이중 파티셔닝 검토

Phase 4 (수십만 테넌트) - 초고급 기능:

✅ WebAuthn/Passkey
✅ Shard 재조정
✅ Multi-Region DR (외부 DB 사용 시)

62. 검증 완료 항목 (오버스펙 아님)

다음 항목들은 Phase 1에서도 필수이므로 유지:

✅ RLS + tenant_id 격리 (표준 패턴)
✅ 기본 결제/알림뱅킹 연동
✅ Webhook 멱등성 처리
✅ Public Gateway 토큰 검증
✅ 기본 Analytics 집계
✅ 기본 모니터링/알람
✅ 기본 DR/백업 정책
✅ 커스텀 도메인 + Middleware 라우팅 구조
✅ 테넌트 프로비저닝 + Industry Layer 구조

63. 오버스펙 제거 효과

오버스펙 항목을 Phase별로 분리함으로써:

- 개발 시간: 약 40~50% 단축 예상
- 초기 복잡도: 약 60% 감소
- 유지보수 부담: 약 50% 감소
- MVP 출시 시간: 3~6개월 단축 가능

→ 실제 SaaS 운영에 필요한 핵심 기능에 집중하여 빠른 MVP 출시가 가능합니다.
